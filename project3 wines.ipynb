{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57257751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00840116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a979bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "#import scikitplot as skplt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0681fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_models( models,parameters):\n",
    "    #ορίζουμε pca\n",
    "        pca = PCA()   \n",
    "    #split χωςρις να εχουμε κανει dimentionality reduction\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42, \n",
    "                                                            shuffle=True,stratify=y1)\n",
    "    #το number του iteration βασει του οποιου θα ταιραξει classifier & parameters\n",
    "        i=0\n",
    "    #το πινακακι που θα εχω τα αποτελεσματα του καθε classifier\n",
    "        global results3\n",
    "        results3=pd.DataFrame(columns=[\"Methodology\",\"Score\",])  \n",
    "    #for loop\n",
    "        for classifier in models:\n",
    "    #πρώτα τρ΄΄΄εχω το pipeline με  steps    \n",
    "            pipe = Pipeline(steps=[(\"pca\", pca), ('classifier', classifier) ])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_true, y_pred = y_test , pipe.predict(X_test)\n",
    "    #https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html\n",
    "    #δεν το χρησιμοποιηση με τον ίδιο τροπο και δεν ειμαι σιγουρος αν ειναι σωστο\n",
    "            #X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "     #κάνω grid search για τα parameters του pipeline       \n",
    "            \n",
    "            grid = GridSearchCV(pipe, parameters[i] ,scoring='balanced_accuracy').fit(X_train, y_train)\n",
    "    #βρισκω τους καλυτερους παραμετρους του pipe\n",
    "            best_params = grid.best_params_\n",
    "            optimised_pipe = grid.best_estimator_\n",
    "            print(optimised_pipe)\n",
    "    #ξανατρέχω το optimised pipe\n",
    "            pipe1 = Pipeline([ ( 'pipe', optimised_pipe ) ])\n",
    "            optimised_pipe.fit(X_train, y_train)\n",
    "    ########έχει παρει το dimentionality reduction (PCA απο το optimised pipe)?\n",
    "            y_true1, y_pred1 = y_test , optimised_pipe.predict(X_test)\n",
    "            print(pd.DataFrame(X_test).head(1))\n",
    "            print(pd.DataFrame(X_train).head(1))\n",
    "    #cross validate        \n",
    "            scores = cross_validate(optimised_pipe, X1, y1, cv=10,\n",
    "                    scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                    return_train_score=True)\n",
    "     # το πινακακι με τα results   \n",
    "            results3 = results3.append({\n",
    "                'Methodology': 'PCA Grind'+str(classifier).split('(')[0],\n",
    "                'Score': format(optimised_pipe.score(X_test, y_test),'.2f'),\n",
    "                'precision 1': format(precision_score(y_true1, y_pred1,  pos_label=1 , average='binary'),'.2f'),\n",
    "                'Precision 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][0],'.2f'),\n",
    "                'Precision 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][1],'.2f'),\n",
    "                'F1 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][0],'.2f'),\n",
    "                'F1 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][1],'.2f'),\n",
    "                'Recal 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][0],'.2f'),\n",
    "                'Recal 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][1],'.2f'),\n",
    "                'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "                'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "                'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f'),\n",
    "                'best params': best_params,\n",
    "                },ignore_index=True)\n",
    "            i+=1\n",
    "        return results3  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_no_dim( models,parameters):\n",
    "       \n",
    "    #split χωςρις να εχουμε κανει dimentionality reduction\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42, \n",
    "                                                            shuffle=True,stratify=y1)\n",
    "    #το number του iteration βασει του οποιου θα ταιραξει classifier & parameters\n",
    "        i=0\n",
    "    #το πινακακι που θα εχω τα αποτελεσματα του καθε classifier\n",
    "        global results4\n",
    "        results4=pd.DataFrame(columns=[\"Methodology\",\"Score\",])  \n",
    "    #for loop\n",
    "        for classifier in models:\n",
    "    #πρώτα τρ΄΄΄εχω το pipeline με  steps    \n",
    "            pipe = Pipeline([('classifier', classifier) ])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_true, y_pred = y_test , pipe.predict(X_test)\n",
    "    #https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html\n",
    "    #δεν το χρησιμοποιηση με τον ίδιο τροπο και δεν ειμαι σιγουρος αν ειναι σωστο\n",
    "            #X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "     #κάνω grid search για τα parameters του pipeline       \n",
    "            \n",
    "            grid = GridSearchCV(pipe, parameters[i] ,scoring='balanced_accuracy').fit(X_train, y_train)\n",
    "    #βρισκω τους καλυτερους παραμετρους του pipe\n",
    "            best_params = grid.best_params_\n",
    "            optimised_pipe = grid.best_estimator_\n",
    "            print(optimised_pipe)\n",
    "    #ξανατρέχω το optimised pipe\n",
    "            optimised_pipe.fit(X_train, y_train)\n",
    "\n",
    "            y_true1, y_pred1 = y_test , optimised_pipe.predict(X_test)\n",
    "    #cross validate        \n",
    "            scores = cross_validate(optimised_pipe, X1, y1, cv=10,\n",
    "                    scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                    return_train_score=True)\n",
    "     # το πινακακι με τα results   \n",
    "            results4 = results4.append({\n",
    "                'Methodology': 'Grind'+str(classifier).split('(')[0],\n",
    "                'Score': format(optimised_pipe.score(X_test, y_test),'.2f'),\n",
    "                'precision 1': format(precision_score(y_true1, y_pred1,  pos_label=1 , average='binary'),'.2f'),\n",
    "                'Precision 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][0],'.2f'),\n",
    "                'Precision 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][1],'.2f'),\n",
    "                'F1 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][0],'.2f'),\n",
    "                'F1 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][1],'.2f'),\n",
    "                'Recal 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][0],'.2f'),\n",
    "                'Recal 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][1],'.2f'),\n",
    "                'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "                'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "                'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f'),\n",
    "                'best params': best_params,\n",
    "                },ignore_index=True)\n",
    "            i+=1\n",
    "        return results4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_models_method( models,parameters,method_details):\n",
    "    #ορίζουμε pca\n",
    "        pca = PCA()   \n",
    "    #split χωςρις να εχουμε κανει dimentionality reduction\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42, \n",
    "                                                            shuffle=True,stratify=y1)\n",
    "    #το number του iteration βασει του οποιου θα ταιραξει classifier & parameters\n",
    "        i=0\n",
    "    #το πινακακι που θα εχω τα αποτελεσματα του καθε classifier\n",
    "        global results5\n",
    "        results5=pd.DataFrame(columns=[\"Methodology\",\"Score\",])  \n",
    "    #for loop\n",
    "        for classifier in models:\n",
    "    #πρώτα τρ΄΄΄εχω το pipeline με  steps    \n",
    "            pipe = Pipeline(steps=[(\"pca\", pca), ('classifier', classifier) ])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_true, y_pred = y_test , pipe.predict(X_test)\n",
    "    #https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html\n",
    "    #δεν το χρησιμοποιηση με τον ίδιο τροπο και δεν ειμαι σιγουρος αν ειναι σωστο\n",
    "            #X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "     #κάνω grid search για τα parameters του pipeline       \n",
    "            \n",
    "            grid = GridSearchCV(pipe, parameters[i] ,scoring='balanced_accuracy').fit(X_train, y_train)\n",
    "    #βρισκω τους καλυτερους παραμετρους του pipe\n",
    "            best_params = grid.best_params_\n",
    "            optimised_pipe = grid.best_estimator_\n",
    "    #ξανατρέχω το optimised pipe\n",
    "            pipe1 = Pipeline([ ( 'pipe', optimised_pipe ) ])\n",
    "            optimised_pipe.fit(X_train, y_train)\n",
    "    ########έχει παρει το dimentionality reduction (PCA απο το optimised pipe)?\n",
    "            y_true1, y_pred1 = y_test , optimised_pipe.predict(X_test)\n",
    "    #cross validate        \n",
    "            scores = cross_validate(optimised_pipe, X1, y1, cv=10,\n",
    "                    scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                    return_train_score=True)\n",
    "     # το πινακακι με τα results   \n",
    "            results5 = results5.append({\n",
    "                'Methodology': 'PCA Grind'+method_details+str(classifier).split('(')[0],\n",
    "                'Score': format(optimised_pipe.score(X_test, y_test),'.2f'),\n",
    "                'precision 1': format(precision_score(y_true1, y_pred1,  pos_label=1 , average='binary'),'.2f'),\n",
    "                'Precision 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][0],'.2f'),\n",
    "                'Precision 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][1],'.2f'),\n",
    "                'F1 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][0],'.2f'),\n",
    "                'F1 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][1],'.2f'),\n",
    "                'Recal 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][0],'.2f'),\n",
    "                'Recal 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][1],'.2f'),\n",
    "                'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "                'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "                'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f'),\n",
    "                'best params': best_params,\n",
    "                },ignore_index=True)\n",
    "            i+=1\n",
    "        return results5  \n",
    "    \n",
    "\n",
    "    #ειναι σωστο το function? παιρνει τα pca?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_no_dim_method( models,parameters,method_details):\n",
    "\n",
    "    #split χωςρις να εχουμε κανει dimentionality reduction\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42, \n",
    "                                                            shuffle=True,stratify=y1)\n",
    "    #το number του iteration βασει του οποιου θα ταιραξει classifier & parameters\n",
    "        i=0\n",
    "    #το πινακακι που θα εχω τα αποτελεσματα του καθε classifier\n",
    "        global results6\n",
    "        results6=pd.DataFrame(columns=[\"Methodology\",\"Score\",])  \n",
    "    #for loop\n",
    "        for classifier in models:\n",
    "    #πρώτα τρ΄΄΄εχω το pipeline με  steps    \n",
    "            pipe = Pipeline([('classifier', classifier) ])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_true, y_pred = y_test , pipe.predict(X_test)\n",
    "    #https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html\n",
    "    #δεν το χρησιμοποιηση με τον ίδιο τροπο και δεν ειμαι σιγουρος αν ειναι σωστο\n",
    "            #X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "     #κάνω grid search για τα parameters του pipeline       \n",
    "            \n",
    "            grid = GridSearchCV(pipe, parameters[i] ,scoring='balanced_accuracy').fit(X_train, y_train)\n",
    "    #βρισκω τους καλυτερους παραμετρους του pipe\n",
    "            best_params = grid.best_params_\n",
    "            optimised_pipe = grid.best_estimator_\n",
    "            print(optimised_pipe)\n",
    "    #ξανατρέχω το optimised pipe\n",
    "            optimised_pipe.fit(X_train, y_train)\n",
    "    ########έχει παρει το dimentionality reduction (PCA απο το optimised pipe)?\n",
    "            y_true1, y_pred1 = y_test , optimised_pipe.predict(X_test)\n",
    "    #cross validate        \n",
    "            scores = cross_validate(optimised_pipe, X1, y1, cv=10,\n",
    "                    scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                    return_train_score=True)\n",
    "     # το πινακακι με τα results   \n",
    "            results6 = results4.append({\n",
    "                'Methodology': 'Grind'+method_details+str(classifier).split('(')[0],\n",
    "                'Score': format(optimised_pipe.score(X_test, y_test),'.2f'),\n",
    "                'precision 1': format(precision_score(y_true1, y_pred1,  pos_label=1 , average='binary'),'.2f'),\n",
    "                'Precision 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][0],'.2f'),\n",
    "                'Precision 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[0][1],'.2f'),\n",
    "                'F1 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][0],'.2f'),\n",
    "                'F1 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[2][1],'.2f'),\n",
    "                'Recal 0':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][0],'.2f'),\n",
    "                'Recal 1':format(precision_recall_fscore_support(y_true1, y_pred1, average=None)[1][1],'.2f'),\n",
    "                'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "                'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "                'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f'),\n",
    "                'best params': best_params,\n",
    "                },ignore_index=True)\n",
    "            i+=1\n",
    "        return results6 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50a406",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "Relevant Papers:\n",
    "\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties.\n",
    "In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7066f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\c.logaras\\christos-logaras-exercises\\winequality-white (1).csv\",sep=';', low_memory=False)\n",
    "data['Sratio']=data['free sulfur dioxide']/data['total sulfur dioxide']\n",
    "quality_complete=data['quality'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284653ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quality'].replace(to_replace =[7, 8, 9],  value =1,inplace=True)\n",
    "data['quality'].replace(to_replace =[6, 5,  4, 3,], value =0 ,inplace=True)\n",
    "data=data[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol',  'Sratio','quality']]\n",
    "data['free sulfur dioxide' ]=data['free sulfur dioxide' ]/100\n",
    "data['total sulfur dioxide'  ]=data['total sulfur dioxide'  ]/100\n",
    "data['fixed acidity'  ]=data['fixed acidity'  ]/10\n",
    "data['residual sugar'  ]=data['residual sugar'  ]/100\n",
    "data['alcohol'  ]=data['alcohol']/10\n",
    "data['residual sugar']=data['residual sugar']*10\n",
    "data['chlorides']=data['chlorides']*10\n",
    "data['pH']=data['pH']/10\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b808061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# αν εβαζα λευκα και κοκκινα μαζι\n",
    "#data2=pd.read_csv(r\"C:\\Users\\c.logaras\\christos-logaras-exercises\\winequality-red.csv\", low_memory=False)\n",
    "#data['type']='white'\n",
    "#data2['type']='red'\n",
    "#data=pd.concat([data,data2])\n",
    "#cols = data.columns.tolist()\n",
    "#data = data[cols[-1:] + cols[:-1]]\n",
    "#data.replace(to_replace='red',value=1,inplace= True)\n",
    "#data.replace(to_replace='white',value=0,inplace= True)\n",
    "#data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dd70ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  Sratio                4898 non-null   float64\n",
      " 12  quality               4898 non-null   int64  \n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 497.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99bbb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#παρατηρω οτι η ταξη μεγεθους της καθε μεταβλητης ειναι διαφορετική - ίσως επιρρεάσει το μοντέλο \n",
    "# να κανω καποια γραμμική μετατροπή (πχ /10) ή μετασχηματισμο οπως normalisation/log κτλ\n",
    "#π΄ρ'ωτα πρέπει να καταλάβω τις μεταβήτές\n",
    "#επέισης και 50% και το 75% των παρατηρήσεων μας είναι στο 6- να κανουμε δική μας κατηγοριοποίηση; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1bc33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>Sratio</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4893           0.62              0.21         0.29            0.16       0.39   \n",
       "4894           0.66              0.32         0.36            0.80       0.47   \n",
       "4895           0.65              0.24         0.19            0.12       0.41   \n",
       "4896           0.55              0.29         0.30            0.11       0.22   \n",
       "4897           0.60              0.21         0.38            0.08       0.20   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
       "4893                 0.24                  0.92  0.99114  0.327       0.50   \n",
       "4894                 0.57                  1.68  0.99490  0.315       0.46   \n",
       "4895                 0.30                  1.11  0.99254  0.299       0.46   \n",
       "4896                 0.20                  1.10  0.98869  0.334       0.38   \n",
       "4897                 0.22                  0.98  0.98941  0.326       0.32   \n",
       "\n",
       "      alcohol    Sratio  quality  \n",
       "4893     1.12  0.260870        0  \n",
       "4894     0.96  0.339286        0  \n",
       "4895     0.94  0.270270        0  \n",
       "4896     1.28  0.181818        1  \n",
       "4897     1.18  0.224490        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4237621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#οι περισσότερες (εξατρημενες/ανεξαρτητη) μεταβλητές έχουν παρόμοια κατανομή για κοκκινο/λευκό εκτός απο οτι εχει να κανει με acidity & sugar\n",
    "#τα κοκκινα κρασια φαίνονται να έχουν πιο πολλα outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b0ef0c",
   "metadata": {},
   "source": [
    "Sulphites feature in most wines; whites more than reds, and sweet wines significantly more than both. They prevent oxidation (that is, they stop the juice turning brown), they keep wines stable (important when they have to travel) and they preserve their bright, fresh fruit flavours. The downside is that higher levels can, in some people, provoke headaches and breathing difficulties, though headache can of course also be triggered by the amount you drink."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cd251",
   "metadata": {},
   "source": [
    "Even if a wine has no added sulphur (often referred to on the label as NAS), it may well contain some naturally occurring or “free sulphur” as a result of the fermentation process. It’s really the total level you need to be concerned about, which, under EU regulations, can be up to 400mg per litre in the case of sweet wines (200mg per litre is the maximum for whites and 150mg for reds). Natural wine bars will generally stock wines that are a good deal lower than that – in the case of Plateau in Brighton, for example, they aim for 30mg per litre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f466a1",
   "metadata": {},
   "source": [
    "https://www.decanter.com/learn/wine-terminology/sulfites-in-wine-friend-or-foe-295931/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53912d06",
   "metadata": {},
   "source": [
    "Wine ranges from about 5 mg/L (5 parts per million) to about 200 mg/L. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40b402",
   "metadata": {},
   "source": [
    "μπορούμε να μετατρέψουμε γραμμικά καποιες μεταβλητες πχ  τις 'free sulfur dioxide' &\t'total sulfur dioxide'  αντι mg/L σε cg/L, για να ειναι πιο κοντά στις μοναδες μετρησης των υπολοιπων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc2e97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.boxplot(figsize=[18,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd93ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0423cce",
   "metadata": {},
   "source": [
    "τα total και το free sulfur έχουν μεγαλη συσχετιση. 1. να γίνουν δεικτης 2. να γινει καποιο drop. Χρειαζεται να καταλαβουμε καλυτερα σε βαθος τι σημαινουν"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c12bc6",
   "metadata": {},
   "source": [
    "https://www.wineshopathome.com/understanding-sulfur-levels-wine/\n",
    "\n",
    "\n",
    "https://www.extension.iastate.edu/wine/total-sulfur-dioxide-why-it-matters-too/\n",
    "Another insight that TSO2 can provide, in conjunction with FSO2, is a sense of how “clean” a wine is. A wine with high TSO2 has usually had many SO2 additions made over its lifetime, usually because the FSO2 keeps dropping. When we see a wine where the FSO2 is an unusually small percentage of the TSO2, it’s often an indication that there’s something making the wine chemically and/or microbially unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446258bb",
   "metadata": {},
   "source": [
    "άρα θέλω το ratio f/total supphur  και σκετο το total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd189b72",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbfb1a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.quality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "066e7791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21641486320947326"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['quality']==1].shape[0]/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b91ca97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa162_row0_col0, #T_aa162_row1_col1, #T_aa162_row2_col2, #T_aa162_row3_col3, #T_aa162_row4_col4, #T_aa162_row5_col5, #T_aa162_row6_col6, #T_aa162_row7_col7, #T_aa162_row8_col8, #T_aa162_row9_col9, #T_aa162_row10_col10, #T_aa162_row11_col11, #T_aa162_row12_col12 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row0_col1, #T_aa162_row9_col11 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row0_col2 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row0_col3, #T_aa162_row0_col6, #T_aa162_row1_col6, #T_aa162_row4_col3 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row0_col4, #T_aa162_row1_col0 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row0_col5, #T_aa162_row3_col8 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row0_col7, #T_aa162_row3_col6, #T_aa162_row6_col3 {\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row0_col8, #T_aa162_row1_col9, #T_aa162_row1_col11, #T_aa162_row7_col10, #T_aa162_row7_col12, #T_aa162_row8_col0, #T_aa162_row8_col2, #T_aa162_row10_col3, #T_aa162_row10_col4, #T_aa162_row10_col5, #T_aa162_row10_col6, #T_aa162_row10_col7, #T_aa162_row11_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row0_col9, #T_aa162_row10_col9 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row0_col10 {\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row0_col11, #T_aa162_row4_col9 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row0_col12 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row1_col2, #T_aa162_row11_col9 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row1_col3 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row1_col4, #T_aa162_row11_col12 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row1_col5 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row1_col7, #T_aa162_row7_col4 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row1_col8, #T_aa162_row2_col5, #T_aa162_row9_col4 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row1_col10, #T_aa162_row11_col10 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row1_col12 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row2_col0 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row2_col1 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row2_col3 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row2_col4 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row2_col6 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row2_col7, #T_aa162_row10_col12 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row2_col8, #T_aa162_row3_col10, #T_aa162_row6_col10, #T_aa162_row7_col1, #T_aa162_row8_col9 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row2_col9, #T_aa162_row6_col12 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row2_col10 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row2_col11, #T_aa162_row8_col3 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row2_col12, #T_aa162_row9_col2 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row3_col0, #T_aa162_row6_col0 {\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row3_col1, #T_aa162_row10_col11 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row3_col2, #T_aa162_row5_col2, #T_aa162_row10_col1 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row3_col4 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row3_col5 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row3_col7 {\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row3_col9 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row3_col11 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row3_col12, #T_aa162_row12_col4 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row4_col0 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row4_col1 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row4_col2, #T_aa162_row6_col1, #T_aa162_row11_col4, #T_aa162_row12_col0 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row4_col5, #T_aa162_row12_col7 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row4_col6 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row4_col7 {\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row4_col8, #T_aa162_row4_col10 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row4_col11, #T_aa162_row9_col1 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row4_col12, #T_aa162_row12_col9 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row5_col0 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row5_col1 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row5_col3 {\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row5_col4 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row5_col6, #T_aa162_row6_col7 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row5_col7 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row5_col8, #T_aa162_row5_col10, #T_aa162_row6_col8, #T_aa162_row11_col6, #T_aa162_row11_col8 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row5_col9 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row5_col11 {\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row5_col12, #T_aa162_row8_col5, #T_aa162_row11_col0 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row6_col2 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row6_col4 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row6_col5 {\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row6_col9, #T_aa162_row8_col11 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row6_col11, #T_aa162_row11_col2 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row7_col0 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row7_col2, #T_aa162_row12_col11 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row7_col3 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row7_col5 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row7_col6 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row7_col8 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row7_col9, #T_aa162_row7_col11, #T_aa162_row12_col1 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row8_col1 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row8_col4, #T_aa162_row12_col6 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row8_col6 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row8_col7, #T_aa162_row10_col8 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row8_col10 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row8_col12 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col0 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col3 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col5 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col6 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col7 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col8 {\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col10 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row9_col12 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row10_col0 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row10_col2 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row11_col3 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row11_col5 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row11_col7 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row12_col2 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row12_col3 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row12_col5 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa162_row12_col8 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa162_row12_col10 {\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa162_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fixed acidity</th>\n",
       "      <th class=\"col_heading level0 col1\" >volatile acidity</th>\n",
       "      <th class=\"col_heading level0 col2\" >citric acid</th>\n",
       "      <th class=\"col_heading level0 col3\" >residual sugar</th>\n",
       "      <th class=\"col_heading level0 col4\" >chlorides</th>\n",
       "      <th class=\"col_heading level0 col5\" >free sulfur dioxide</th>\n",
       "      <th class=\"col_heading level0 col6\" >total sulfur dioxide</th>\n",
       "      <th class=\"col_heading level0 col7\" >density</th>\n",
       "      <th class=\"col_heading level0 col8\" >pH</th>\n",
       "      <th class=\"col_heading level0 col9\" >sulphates</th>\n",
       "      <th class=\"col_heading level0 col10\" >alcohol</th>\n",
       "      <th class=\"col_heading level0 col11\" >Sratio</th>\n",
       "      <th class=\"col_heading level0 col12\" >quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row0\" class=\"row_heading level0 row0\" >fixed acidity</th>\n",
       "      <td id=\"T_aa162_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row0_col1\" class=\"data row0 col1\" >-0.022697</td>\n",
       "      <td id=\"T_aa162_row0_col2\" class=\"data row0 col2\" >0.289181</td>\n",
       "      <td id=\"T_aa162_row0_col3\" class=\"data row0 col3\" >0.089021</td>\n",
       "      <td id=\"T_aa162_row0_col4\" class=\"data row0 col4\" >0.023086</td>\n",
       "      <td id=\"T_aa162_row0_col5\" class=\"data row0 col5\" >-0.049396</td>\n",
       "      <td id=\"T_aa162_row0_col6\" class=\"data row0 col6\" >0.091070</td>\n",
       "      <td id=\"T_aa162_row0_col7\" class=\"data row0 col7\" >0.265331</td>\n",
       "      <td id=\"T_aa162_row0_col8\" class=\"data row0 col8\" >-0.425858</td>\n",
       "      <td id=\"T_aa162_row0_col9\" class=\"data row0 col9\" >-0.017143</td>\n",
       "      <td id=\"T_aa162_row0_col10\" class=\"data row0 col10\" >-0.120881</td>\n",
       "      <td id=\"T_aa162_row0_col11\" class=\"data row0 col11\" >-0.139459</td>\n",
       "      <td id=\"T_aa162_row0_col12\" class=\"data row0 col12\" >-0.080748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row1\" class=\"row_heading level0 row1\" >volatile acidity</th>\n",
       "      <td id=\"T_aa162_row1_col0\" class=\"data row1 col0\" >-0.022697</td>\n",
       "      <td id=\"T_aa162_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row1_col2\" class=\"data row1 col2\" >-0.149472</td>\n",
       "      <td id=\"T_aa162_row1_col3\" class=\"data row1 col3\" >0.064286</td>\n",
       "      <td id=\"T_aa162_row1_col4\" class=\"data row1 col4\" >0.070512</td>\n",
       "      <td id=\"T_aa162_row1_col5\" class=\"data row1 col5\" >-0.097012</td>\n",
       "      <td id=\"T_aa162_row1_col6\" class=\"data row1 col6\" >0.089261</td>\n",
       "      <td id=\"T_aa162_row1_col7\" class=\"data row1 col7\" >0.027114</td>\n",
       "      <td id=\"T_aa162_row1_col8\" class=\"data row1 col8\" >-0.031915</td>\n",
       "      <td id=\"T_aa162_row1_col9\" class=\"data row1 col9\" >-0.035728</td>\n",
       "      <td id=\"T_aa162_row1_col10\" class=\"data row1 col10\" >0.067718</td>\n",
       "      <td id=\"T_aa162_row1_col11\" class=\"data row1 col11\" >-0.196161</td>\n",
       "      <td id=\"T_aa162_row1_col12\" class=\"data row1 col12\" >-0.067225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row2\" class=\"row_heading level0 row2\" >citric acid</th>\n",
       "      <td id=\"T_aa162_row2_col0\" class=\"data row2 col0\" >0.289181</td>\n",
       "      <td id=\"T_aa162_row2_col1\" class=\"data row2 col1\" >-0.149472</td>\n",
       "      <td id=\"T_aa162_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row2_col3\" class=\"data row2 col3\" >0.094212</td>\n",
       "      <td id=\"T_aa162_row2_col4\" class=\"data row2 col4\" >0.114364</td>\n",
       "      <td id=\"T_aa162_row2_col5\" class=\"data row2 col5\" >0.094077</td>\n",
       "      <td id=\"T_aa162_row2_col6\" class=\"data row2 col6\" >0.121131</td>\n",
       "      <td id=\"T_aa162_row2_col7\" class=\"data row2 col7\" >0.149503</td>\n",
       "      <td id=\"T_aa162_row2_col8\" class=\"data row2 col8\" >-0.163748</td>\n",
       "      <td id=\"T_aa162_row2_col9\" class=\"data row2 col9\" >0.062331</td>\n",
       "      <td id=\"T_aa162_row2_col10\" class=\"data row2 col10\" >-0.075729</td>\n",
       "      <td id=\"T_aa162_row2_col11\" class=\"data row2 col11\" >0.016241</td>\n",
       "      <td id=\"T_aa162_row2_col12\" class=\"data row2 col12\" >-0.035330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row3\" class=\"row_heading level0 row3\" >residual sugar</th>\n",
       "      <td id=\"T_aa162_row3_col0\" class=\"data row3 col0\" >0.089021</td>\n",
       "      <td id=\"T_aa162_row3_col1\" class=\"data row3 col1\" >0.064286</td>\n",
       "      <td id=\"T_aa162_row3_col2\" class=\"data row3 col2\" >0.094212</td>\n",
       "      <td id=\"T_aa162_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row3_col4\" class=\"data row3 col4\" >0.088685</td>\n",
       "      <td id=\"T_aa162_row3_col5\" class=\"data row3 col5\" >0.299098</td>\n",
       "      <td id=\"T_aa162_row3_col6\" class=\"data row3 col6\" >0.401439</td>\n",
       "      <td id=\"T_aa162_row3_col7\" class=\"data row3 col7\" >0.838966</td>\n",
       "      <td id=\"T_aa162_row3_col8\" class=\"data row3 col8\" >-0.194133</td>\n",
       "      <td id=\"T_aa162_row3_col9\" class=\"data row3 col9\" >-0.026664</td>\n",
       "      <td id=\"T_aa162_row3_col10\" class=\"data row3 col10\" >-0.450631</td>\n",
       "      <td id=\"T_aa162_row3_col11\" class=\"data row3 col11\" >0.051430</td>\n",
       "      <td id=\"T_aa162_row3_col12\" class=\"data row3 col12\" >-0.117085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row4\" class=\"row_heading level0 row4\" >chlorides</th>\n",
       "      <td id=\"T_aa162_row4_col0\" class=\"data row4 col0\" >0.023086</td>\n",
       "      <td id=\"T_aa162_row4_col1\" class=\"data row4 col1\" >0.070512</td>\n",
       "      <td id=\"T_aa162_row4_col2\" class=\"data row4 col2\" >0.114364</td>\n",
       "      <td id=\"T_aa162_row4_col3\" class=\"data row4 col3\" >0.088685</td>\n",
       "      <td id=\"T_aa162_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row4_col5\" class=\"data row4 col5\" >0.101392</td>\n",
       "      <td id=\"T_aa162_row4_col6\" class=\"data row4 col6\" >0.198910</td>\n",
       "      <td id=\"T_aa162_row4_col7\" class=\"data row4 col7\" >0.257211</td>\n",
       "      <td id=\"T_aa162_row4_col8\" class=\"data row4 col8\" >-0.090439</td>\n",
       "      <td id=\"T_aa162_row4_col9\" class=\"data row4 col9\" >0.016763</td>\n",
       "      <td id=\"T_aa162_row4_col10\" class=\"data row4 col10\" >-0.360189</td>\n",
       "      <td id=\"T_aa162_row4_col11\" class=\"data row4 col11\" >-0.033218</td>\n",
       "      <td id=\"T_aa162_row4_col12\" class=\"data row4 col12\" >-0.183118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row5\" class=\"row_heading level0 row5\" >free sulfur dioxide</th>\n",
       "      <td id=\"T_aa162_row5_col0\" class=\"data row5 col0\" >-0.049396</td>\n",
       "      <td id=\"T_aa162_row5_col1\" class=\"data row5 col1\" >-0.097012</td>\n",
       "      <td id=\"T_aa162_row5_col2\" class=\"data row5 col2\" >0.094077</td>\n",
       "      <td id=\"T_aa162_row5_col3\" class=\"data row5 col3\" >0.299098</td>\n",
       "      <td id=\"T_aa162_row5_col4\" class=\"data row5 col4\" >0.101392</td>\n",
       "      <td id=\"T_aa162_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row5_col6\" class=\"data row5 col6\" >0.615501</td>\n",
       "      <td id=\"T_aa162_row5_col7\" class=\"data row5 col7\" >0.294210</td>\n",
       "      <td id=\"T_aa162_row5_col8\" class=\"data row5 col8\" >-0.000618</td>\n",
       "      <td id=\"T_aa162_row5_col9\" class=\"data row5 col9\" >0.059217</td>\n",
       "      <td id=\"T_aa162_row5_col10\" class=\"data row5 col10\" >-0.250104</td>\n",
       "      <td id=\"T_aa162_row5_col11\" class=\"data row5 col11\" >0.738632</td>\n",
       "      <td id=\"T_aa162_row5_col12\" class=\"data row5 col12\" >-0.023413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row6\" class=\"row_heading level0 row6\" >total sulfur dioxide</th>\n",
       "      <td id=\"T_aa162_row6_col0\" class=\"data row6 col0\" >0.091070</td>\n",
       "      <td id=\"T_aa162_row6_col1\" class=\"data row6 col1\" >0.089261</td>\n",
       "      <td id=\"T_aa162_row6_col2\" class=\"data row6 col2\" >0.121131</td>\n",
       "      <td id=\"T_aa162_row6_col3\" class=\"data row6 col3\" >0.401439</td>\n",
       "      <td id=\"T_aa162_row6_col4\" class=\"data row6 col4\" >0.198910</td>\n",
       "      <td id=\"T_aa162_row6_col5\" class=\"data row6 col5\" >0.615501</td>\n",
       "      <td id=\"T_aa162_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row6_col7\" class=\"data row6 col7\" >0.529881</td>\n",
       "      <td id=\"T_aa162_row6_col8\" class=\"data row6 col8\" >0.002321</td>\n",
       "      <td id=\"T_aa162_row6_col9\" class=\"data row6 col9\" >0.134562</td>\n",
       "      <td id=\"T_aa162_row6_col10\" class=\"data row6 col10\" >-0.448892</td>\n",
       "      <td id=\"T_aa162_row6_col11\" class=\"data row6 col11\" >-0.013448</td>\n",
       "      <td id=\"T_aa162_row6_col12\" class=\"data row6 col12\" >-0.162202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row7\" class=\"row_heading level0 row7\" >density</th>\n",
       "      <td id=\"T_aa162_row7_col0\" class=\"data row7 col0\" >0.265331</td>\n",
       "      <td id=\"T_aa162_row7_col1\" class=\"data row7 col1\" >0.027114</td>\n",
       "      <td id=\"T_aa162_row7_col2\" class=\"data row7 col2\" >0.149503</td>\n",
       "      <td id=\"T_aa162_row7_col3\" class=\"data row7 col3\" >0.838966</td>\n",
       "      <td id=\"T_aa162_row7_col4\" class=\"data row7 col4\" >0.257211</td>\n",
       "      <td id=\"T_aa162_row7_col5\" class=\"data row7 col5\" >0.294210</td>\n",
       "      <td id=\"T_aa162_row7_col6\" class=\"data row7 col6\" >0.529881</td>\n",
       "      <td id=\"T_aa162_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row7_col8\" class=\"data row7 col8\" >-0.093591</td>\n",
       "      <td id=\"T_aa162_row7_col9\" class=\"data row7 col9\" >0.074493</td>\n",
       "      <td id=\"T_aa162_row7_col10\" class=\"data row7 col10\" >-0.780138</td>\n",
       "      <td id=\"T_aa162_row7_col11\" class=\"data row7 col11\" >-0.065525</td>\n",
       "      <td id=\"T_aa162_row7_col12\" class=\"data row7 col12\" >-0.283871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row8\" class=\"row_heading level0 row8\" >pH</th>\n",
       "      <td id=\"T_aa162_row8_col0\" class=\"data row8 col0\" >-0.425858</td>\n",
       "      <td id=\"T_aa162_row8_col1\" class=\"data row8 col1\" >-0.031915</td>\n",
       "      <td id=\"T_aa162_row8_col2\" class=\"data row8 col2\" >-0.163748</td>\n",
       "      <td id=\"T_aa162_row8_col3\" class=\"data row8 col3\" >-0.194133</td>\n",
       "      <td id=\"T_aa162_row8_col4\" class=\"data row8 col4\" >-0.090439</td>\n",
       "      <td id=\"T_aa162_row8_col5\" class=\"data row8 col5\" >-0.000618</td>\n",
       "      <td id=\"T_aa162_row8_col6\" class=\"data row8 col6\" >0.002321</td>\n",
       "      <td id=\"T_aa162_row8_col7\" class=\"data row8 col7\" >-0.093591</td>\n",
       "      <td id=\"T_aa162_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row8_col9\" class=\"data row8 col9\" >0.155951</td>\n",
       "      <td id=\"T_aa162_row8_col10\" class=\"data row8 col10\" >0.121432</td>\n",
       "      <td id=\"T_aa162_row8_col11\" class=\"data row8 col11\" >0.000801</td>\n",
       "      <td id=\"T_aa162_row8_col12\" class=\"data row8 col12\" >0.093510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row9\" class=\"row_heading level0 row9\" >sulphates</th>\n",
       "      <td id=\"T_aa162_row9_col0\" class=\"data row9 col0\" >-0.017143</td>\n",
       "      <td id=\"T_aa162_row9_col1\" class=\"data row9 col1\" >-0.035728</td>\n",
       "      <td id=\"T_aa162_row9_col2\" class=\"data row9 col2\" >0.062331</td>\n",
       "      <td id=\"T_aa162_row9_col3\" class=\"data row9 col3\" >-0.026664</td>\n",
       "      <td id=\"T_aa162_row9_col4\" class=\"data row9 col4\" >0.016763</td>\n",
       "      <td id=\"T_aa162_row9_col5\" class=\"data row9 col5\" >0.059217</td>\n",
       "      <td id=\"T_aa162_row9_col6\" class=\"data row9 col6\" >0.134562</td>\n",
       "      <td id=\"T_aa162_row9_col7\" class=\"data row9 col7\" >0.074493</td>\n",
       "      <td id=\"T_aa162_row9_col8\" class=\"data row9 col8\" >0.155951</td>\n",
       "      <td id=\"T_aa162_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row9_col10\" class=\"data row9 col10\" >-0.017433</td>\n",
       "      <td id=\"T_aa162_row9_col11\" class=\"data row9 col11\" >-0.022362</td>\n",
       "      <td id=\"T_aa162_row9_col12\" class=\"data row9 col12\" >0.047410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row10\" class=\"row_heading level0 row10\" >alcohol</th>\n",
       "      <td id=\"T_aa162_row10_col0\" class=\"data row10 col0\" >-0.120881</td>\n",
       "      <td id=\"T_aa162_row10_col1\" class=\"data row10 col1\" >0.067718</td>\n",
       "      <td id=\"T_aa162_row10_col2\" class=\"data row10 col2\" >-0.075729</td>\n",
       "      <td id=\"T_aa162_row10_col3\" class=\"data row10 col3\" >-0.450631</td>\n",
       "      <td id=\"T_aa162_row10_col4\" class=\"data row10 col4\" >-0.360189</td>\n",
       "      <td id=\"T_aa162_row10_col5\" class=\"data row10 col5\" >-0.250104</td>\n",
       "      <td id=\"T_aa162_row10_col6\" class=\"data row10 col6\" >-0.448892</td>\n",
       "      <td id=\"T_aa162_row10_col7\" class=\"data row10 col7\" >-0.780138</td>\n",
       "      <td id=\"T_aa162_row10_col8\" class=\"data row10 col8\" >0.121432</td>\n",
       "      <td id=\"T_aa162_row10_col9\" class=\"data row10 col9\" >-0.017433</td>\n",
       "      <td id=\"T_aa162_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row10_col11\" class=\"data row10 col11\" >0.064466</td>\n",
       "      <td id=\"T_aa162_row10_col12\" class=\"data row10 col12\" >0.385132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row11\" class=\"row_heading level0 row11\" >Sratio</th>\n",
       "      <td id=\"T_aa162_row11_col0\" class=\"data row11 col0\" >-0.139459</td>\n",
       "      <td id=\"T_aa162_row11_col1\" class=\"data row11 col1\" >-0.196161</td>\n",
       "      <td id=\"T_aa162_row11_col2\" class=\"data row11 col2\" >0.016241</td>\n",
       "      <td id=\"T_aa162_row11_col3\" class=\"data row11 col3\" >0.051430</td>\n",
       "      <td id=\"T_aa162_row11_col4\" class=\"data row11 col4\" >-0.033218</td>\n",
       "      <td id=\"T_aa162_row11_col5\" class=\"data row11 col5\" >0.738632</td>\n",
       "      <td id=\"T_aa162_row11_col6\" class=\"data row11 col6\" >-0.013448</td>\n",
       "      <td id=\"T_aa162_row11_col7\" class=\"data row11 col7\" >-0.065525</td>\n",
       "      <td id=\"T_aa162_row11_col8\" class=\"data row11 col8\" >0.000801</td>\n",
       "      <td id=\"T_aa162_row11_col9\" class=\"data row11 col9\" >-0.022362</td>\n",
       "      <td id=\"T_aa162_row11_col10\" class=\"data row11 col10\" >0.064466</td>\n",
       "      <td id=\"T_aa162_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "      <td id=\"T_aa162_row11_col12\" class=\"data row11 col12\" >0.125211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa162_level0_row12\" class=\"row_heading level0 row12\" >quality</th>\n",
       "      <td id=\"T_aa162_row12_col0\" class=\"data row12 col0\" >-0.080748</td>\n",
       "      <td id=\"T_aa162_row12_col1\" class=\"data row12 col1\" >-0.067225</td>\n",
       "      <td id=\"T_aa162_row12_col2\" class=\"data row12 col2\" >-0.035330</td>\n",
       "      <td id=\"T_aa162_row12_col3\" class=\"data row12 col3\" >-0.117085</td>\n",
       "      <td id=\"T_aa162_row12_col4\" class=\"data row12 col4\" >-0.183118</td>\n",
       "      <td id=\"T_aa162_row12_col5\" class=\"data row12 col5\" >-0.023413</td>\n",
       "      <td id=\"T_aa162_row12_col6\" class=\"data row12 col6\" >-0.162202</td>\n",
       "      <td id=\"T_aa162_row12_col7\" class=\"data row12 col7\" >-0.283871</td>\n",
       "      <td id=\"T_aa162_row12_col8\" class=\"data row12 col8\" >0.093510</td>\n",
       "      <td id=\"T_aa162_row12_col9\" class=\"data row12 col9\" >0.047410</td>\n",
       "      <td id=\"T_aa162_row12_col10\" class=\"data row12 col10\" >0.385132</td>\n",
       "      <td id=\"T_aa162_row12_col11\" class=\"data row12 col11\" >0.125211</td>\n",
       "      <td id=\"T_aa162_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29957160408>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc2b24",
   "metadata": {},
   "source": [
    "1. θα κανω split\n",
    "2. stratified το test\n",
    "3. θα ξεκινήσω να τρέχω αλγόριθμους"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be325ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = data.drop('quality', axis=1)\n",
    "y_original = data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c6c5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_original, y_original, test_size=0.2, random_state=42, shuffle=True,stratify=y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0966e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "lr = lr.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, lr.predict(X_test)\n",
    "\n",
    "scores = cross_validate(lr, X_original, y_original, cv=10,\n",
    "                        scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "records=pd.DataFrame(columns=[\"Methodology\",\"Score\",])\n",
    "records = records.append(\n",
    "    {\n",
    "        'Methodology': 'Logistic Stratified',\n",
    "        'Score': format(lr.score(X_test, y_true),'.2f'),\n",
    "        'Precision 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][0],'.2f'),\n",
    "        'Precision 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][1],'.2f'),\n",
    "        'precision 1': format(precision_score(y_true, y_pred,  pos_label=1 , average='binary'),'.2f'),\n",
    "        #δεν ξέρω αν ειναι σωστο\n",
    "        'Recal 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][0],'.2f'),\n",
    "        'Recal 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][1],'.2f'),\n",
    "        'F1 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][0],'.2f'),\n",
    "        'F1 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][1],'.2f'),\n",
    "        'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "        'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "        'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f'),\n",
    "    },\n",
    "    ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04aeb6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Methodology Score  F1 0  F1 1 Precision 0 Precision 1 Recal 0  \\\n",
       "0  Logistic Stratified  0.80  0.88  0.31        0.81        0.59    0.96   \n",
       "\n",
       "  Recal 1 precision 1 test_average_precision test_balanced_accuracy  \\\n",
       "0    0.21        0.59                   0.54                   0.59   \n",
       "\n",
       "  test_roc_auc  \n",
       "0         0.79  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a422b042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABtPUlEQVR4nO2dd3hURReH30noHUJAeodAGgQCgiK9mCCiIkWlKl1QBEFRELFQBSkiYAMEBCvCJ0ovSi8CIr1GIEAgAVIIKXu+P+7uJpu6CUk2CfM+z32yc+/cO2cvyz135sz8jhIRNBqNRqNJDidHG6DRaDSa7I12FBqNRqNJEe0oNBqNRpMi2lFoNBqNJkW0o9BoNBpNimhHodFoNJoU0Y5Co9FoNCmiHYUmx6OUuqiUuqeUClNKXVNKLVZKFUlQp5lSaotSKlQpdUcptVYpVS9BnWJKqU+VUgHma501l0sn065SSo1QSh1TSoUrpS4rpX5QSnlm5vfVaLIa7Sg0uYWnRKQIUB9oALxtOaCUagpsAH4FygPVgCPATqVUdXOdfMBmwB3oCBQDmgG3gMbJtDkbeA0YAZQCagOrAf+0Gq+UypPWczSarEI7Ck2uQkSuAesxHIaFacBSEZktIqEiEiwi7wJ7gInmOr2BysAzInJcREwickNEPhCRdQnbUUrVAoYBPUVki4jcF5EIEVkuIlPMdbYppV6Jd05fpdRf8cqilBqmlDoDnFFKLVBKzUjQzq9KqTfMn8srpX5SSgUppS4opUbEq9dYKXVAKXVXKXVdKTUz/XdRo7FFOwpNrkIpVRF4EjhrLhfC6Bn8kET174F25s9tgT9EJMzOptoAl0Vk34NZTBegCVAPWAF0V0opAKVUSaA9sFIp5QSsxegJVTC3/7pSqoP5OrOB2SJSDKhh/m4aTYagHYUmt7BaKRUK/AfcAN4z7y+F8TsPTOKcQMASf3BJpk5ypLV+ckw293DuAX8CAjQ3H+sK7BaRq4Av4Coik0QkSkTOA18APcx1o4GaSqnSIhImInsywDaNBtCOQpN76CIiRYGWgBtxDiAEMAHlkjinHHDT/PlWMnWSI631k+M/ywcxFDpXAj3Nu14Alps/VwHKK6VuWzZgHFDWfPxljBjJSaXUfqVUpwywTaMBtKPQ5DJEZDuwGJhhLocDu4Hnk6jeDSOADbAJ6KCUKmxnU5uBikqpRinUCQcKxSs/kpTJCcrfAV2VUlUwhqR+Mu//D7ggIiXibUVFxA9ARM6ISE+gDDAV+DEN30WjSRHtKDS5kU+Bdkqp+ubyW0Af81TWokqpkkqpD4GmwPvmOt9iPIx/Ukq5KaWclFIuSqlxSim/hA2IyBlgPvCdUqqlUiqfUqqAUqqHUuotc7XDwLNKqUJKqZoYb/0pIiJ/A0HAl8B6EbltPrQPuKuUGquUKqiUclZKeSilfAGUUi8ppVxFxARYzom1835pNCmiHYUm1yEiQcBSYLy5/BfQAXgWI65wCWMK7ePmBz4ich8joH0S2AjcxXg4lwb2JtPUCGAe8BnGw/kc8AxG0BlgFhAFXAeWEDeMlBrfmW1ZEe87xQJPYczmuoAxZPYlUNxcpSPwr1IqDCOw3UNEIu1sT6NJEaUTF2k0Go0mJXSPQqPRaDQpoh2FRqPRaFJEOwqNRqPRpIh2FBqNRqNJkRwnRFa6dGmpWrWqo83QaDSaHMXBgwdviohres7NcY6iatWqHDhwwNFmaDQaTY5CKXUpvefqoSeNRqPRpIh2FBqNRqNJEe0oNBqNRpMi2lFoNBqNJkW0o9BoNBpNimhHodFoNJoUybTpsUqpr4FOwA0R8UjiuMJQufQDIoC+InIos+zRaDSa3MDt25FEREQTHR1LdLSJcuWKULhwvkT17t+PYcuWCxnSZmauo1iMIcG8NJnjTwK1zFsT4HPzX41Go3moEBGCgiI4/9pGzv3vHJWdnWieNy980hJ6275nd+/+Ixs2nLOWfy9WlI758kHQqzb1QkIi8fOzKNXHPJB9meYoRGSHUqpqClWeBpaa0z/uUUqVUEqVE5GMyEOs0Wg0DiUiIpo1a05x4kQQ4eHRRJwJ4f2LEbheDQcvV9jc3VrXx6c3hw/XtJb75s9P87x5GThwEF9c3mX7Cn3nBYystwbR5kwRarOyNSC4CDAa2AM82GCNI1dmVyBevmDgsnlfIkehlBoIDASoXLlylhin0Wg0dtFmFRwNshYbhkzjUOx/QAGM5IpxvFqiOK558nDw0EEaqR7xjlQD4hzF+VhzcsKRJB5nyWObuDA6UTbdhJTFSJqYfhwZzFZJ7EvyG4vIIhFpJCKNXF3TJVWi0Wg0GYq/vz9KKQ4eOphMjUgoc8NmT4T5CdcwT2UjS7tl+yLcpt45k8mm7Ofih7QRpI3wstsLPPJIESo5OVHDyYkCyniUWo4H1A5g/un53Gpzg44da9LR81GeyPPGA31XR/YoLgOV4pUrAlcdZItGo9FY8ff3Z926dQzI34xFRXsCMDFiHe9H/J7quY8//hiPfHqXdbfWwSf/we9lrMfCk3v7LxEOBe9DuRAoF8KV8sH4vZ2XdQ12sihB1S+/7JzkJWJiYpgzZw4TJkwgPDwcDw8Pfv/9RetxpT5J1fbkcKSjWAO8qpRaidG5uqPjExrNQ0SCIRs2dQPvMonrHbkBbb+PKycY37fhjS3w7fG4chLBYCuu84y/b/rCmCZW55Ac5Z2Ks7CIMVw0KGwl4EKDBh05eq8G566E8VS+fBRUCoZiOAmA5ieo5lqeIR69KBR8nxoL/4EqxWBGS6SlbfCZrsk2nSp79+5l0KBBHDlyBIDnnnuO6tWrp/+CCcjM6bHfAS2B0kqpy8B7QF4AEVkArMOYGnsWY3psv8yyRaN5qMjsB6uFBLNsrCw9BqO2xZV71YOZrVMxOvNIzgFI6bnGh+n7Yfp+fuNJFH8A1YE6uLrW4nCRagTcjqWyszMDCzxm1K9SjIEHvuO1135nzpx99OcatWqVovWulylYuhBzNg8HjOGi397+zbbRyRl7H0JCQhg3bhwLFy5ERKhatSrz5s3D398/Q9vJzFlPPVM5LsCwzGpfo8mV2PsWrgFg4MBBrLu/y66652NvUrduH06cqAJAUBAEBYUQUqI41ik05t4AQOvW1ZgzZx8AZ84E06XLSjZt6m293m/1EziJTOD9999nwYIF5MmTh9GjRzN+/HgKFSqU4e3kuHwUGk2OYVsAjN4Gl+7G7cshb+G5DT8/P377zXhwm0zCli0XuNhtLVWdnY0KVYpRfUZnDjQuR50687h8Oe7fLPy356BZpUTXbNGiKk5OCpPJiDvs3PkfffqshgEkPVUng4iJiSFPHuPR/e6773LhwgU++ugjPDyS6QlmANpRaDSZRUInobElueGwhHiXSd7BJmRma9SsNoDFOdgGg2NjTfTs+RM//HCcH398nqrP1bM5vRAweXIbevX6xbovPDwqyaZKlCjAkCGNCA2NonDhvJQqVZDtXvMzzUlERkYydepUVq9ezd69e8mXLx+lS5fm119/zZwG46EdhUaTFJbeQPH86R/fd5STSOOD1e6ei73X7O2RfJwjg0gt8AxYexAWRIShQ3/jhx+OJ3MG+B/2Z13Z3+GFVlD7KpQKo33EZNh8P+kTnkl6t5+LX4q2pZXNmzczZMgQzpw5A8D69et56qmnMrSNlNCOQqNJyJEb8Pwa47PXA6zbsTxYp+01AqYZgb1v4bkIe5xCQvz8Ej+oly//h0WLbFcoiwhKxXUB1t1aZ6wu678lXbaCOYidQfGJ69evM2rUKJYvXw5A3bp1+fzzz2nRokWGXN9etKPQPFykJxg8bS+MeQAZsjFNUj8/C97CszPpdQYJew3378dw8uRNvL0fSVS/U6falC5diJs3IwBYuvQoLVtWxcUlcfBX2qS22jnzWbZsGcOHD+f27dsUKFCACRMmMGrUKPLlSywAmNlomXGNJiWOBsH3pxxtRY7CsmI5LVtqTsLPzw8RsdksTiIiIpo5c/bSq9cvFCjwER07LseYVGlLiRIFmDzZiF/kLR7DmqeHU/pwYdRmZd2yEyaTidu3b9OxY0f+/fdf3n77bYc4CdA9Ck1uIuEso4yYORRvOmQi0jK+n8tJT48gIUn1EOxhy5YLvPbaH9bytWthnD8fQo0apRLV7d+/AW9/vYybPX+AKjeTtiOD4wv2EhYWxu7du2nXrh0AvXr1onz58rRp08ZmeMwRaEehyT2M3gaRDyanDKQtGPwQk5JzSO9DPz106lSbGTPaMXr0Ruu+DRvO0bVrflxdC9vUdXJS3Jw0C1TGxhIelNWrVzN8+HCCgoI4duwYNWvWRClF27ZtHW0aoB2FJjfRrQ48Uth2PUJCHsJgcEaRWq8hs52DiBAYGEb58kUTHRs1qhlXroQya9YeACZN2kHfvvWTvpD55Tw7OIlLly4xYsQI1qwxJk80atSI+/eTmWHlQLSj0OQsUpKRGNPEWLimsQtHDhfdvx9DQMAdAIKCIrh79z4dO9ZMsu6gQWvZuvUiN29GcP9+LMHBY8ifP/Gjq3//Bri6FqJy5eL4+9emYMG8abYrq4iOjubTTz9l4sSJREREULRoUT7++GOGDBmCs2URYDZCOwpN7sMSV2ipc5dYyAinAKk7hlu3Ijh7NpiQkEjCw6OoXr0kDRqUS1Tv3LkQ3N3nW8vNmlVK1lEEBoZx5kywtbx792VatqyaqJ6HRxk8PFKeweZ/OGM1kNLLiBEjWLBgAQDdunVj1qxZlC9f3sFWJY92FJrsQ/wFbGZFzzTzkE8zTYqMjiVcvx5GyZIFyZcv8ZvvlCl/MWPGbmt5+PDGSTqKtFCqVEGb8saN5xI5Cv/D/nGKrXbgqIC1hddff53t27czc+ZMOnbs6FBb7EE7Ck32o2whI9ZgGUbSD/4HwuIkknMKd+5Esn37JUqUKMATT1RJ8hr9+/9KQMAdAgLucOZMMBcuvEbVqiUS1atSxXZfcvIXaaFkyQLWzwUK5CE8PDpRnbQ6iayMT4gIy5YtY926daxYsQKlFHXq1OHYsWM4OeWMFQraUWiyH9cj4gLSVYrZOgo9GylJ0ippcfnyXUaP3sCZM8EcOXKN2Fjh+efrJesoduy4xLlzIanaUblycZtyUg91gHz5nKlZM276avXqJQkPj6Jw4cTrBEaNasbAgQ0pVaogLi6FyJMn+YdrdlgoF59Tp04xZMgQtm7dChhTXi2rxnOKkwDtKDRZRcI1DvYMLaW0huEhJm3xhrxAdCJJi3LlinD9ejiHDtmXK6xQIfsCwzVqlMTbuyyuroUpUiQfvr5Jj7vXrFmKM2eG23XNihWL2VUvO3Hv3j0mT57M1KlTiYqKwsXFhU8++YQnn3zS0aalC+0oNBmLxSF81dFWGiOhkur6i8YGcVNW9QI2u0gt3nDhQgi//HKSf/+9wc8/n+T48aGUK2c7pdTZ2YmlS7vg7b2AkJDIVNuM/6bv7Kxwckp6AZi7exkOHx6chm+TdtIaj8hqNm3axODBgzl37hwAL7/8MlOnTsXFxcXBlqUf7Sg0GUNSuRfi81W8gN20fbDhovG5Ss57W3QESfUikpKpADh9+hajRm2wlhcuPMjEiS0T1atUqTiffebHCy/8TNGi+VKcMTR9ejsiIqKt9YoWzZ++L5IBJOckHB2gtrBr1y7OnTuHu7s7CxYs4PHHH3e0SQ+MSu7Hll1p1KiRHDhwwNFmaBLSaKmtk9jUDdZfSDy8FF9JVU9jtRtDwsEZqAF4UKhQbZYu7cVzCfIpAPz1VwDNm39jLT/ySBEuXXo90SwlEeHcuRBiY01Ur16SvHkzd/5+RvcEsks8IjY2lrNnz1KnTh0A7t+/z1dffcUrr7ziMG2mpFBKHRSRRuk5V/coNBlD8fxxktxHg4xew6ngxI7CHiVVjQ1x+Y8HAcZbf0QENlnY4pMwniAinD8fgptbaZv9SilrQDm7D+ckJLv0Hv7++28GDx7M+fPnOXXqFKVKlSJ//vwMHTrU0aZlKNpRaOwnfrrOhMFoS5xh2l7DUZwK1oHoNCIiNG/ejZ07f0zyeNWqJi5ejCvfuBGeZL3y5Yvy2mtNKFw4L3XqlKZr13qJnIejHEN20ld6EEJDQ5kwYQJz5szBZDJRoUIFzp07R6lSiYUIcwPaUWjSx7VwY4Ec2AagdY8hEdHRsdy9e59SpQpaVUBtYw71zVtJwAP4HbB1An5+frz77jiaNfvaui8oKCJRW1YHEC/5WZ/diaolSW55iGcmIsLPP//Ma6+9xpUrV3BycmLkyJG8//77FC2aWIMqt6AdhSYOi46SPVNXLSuodTA6SUwm4d9/bzB//n6+/fYo4eHR3Lv3DgUKGP/lbAPTJYGq1lKDBs9w6NC3ia4pIjRqVJ5GjcrRrZs7DRsmnnqanRee5QZef/115syZA4Cvry8LFy6kQYMGDrYq89GOQpOY6fvjAs4pLXDT6xySxP+wP+uu/wGd3oGYuABxwa0FIZ9ZBn1TvBMWA8viin9XuJ18Ep0pcABYYAJSyK6aXQK9uY1nnnmGJUuW8PHHHzNo0KBsKeCXGWhHoUmehL2Fh1xHKdG4/mUXOFIFalwDt6u2lfMAFW/CxbJpa8TJBHkfLKdGdgn05gb++usvtm7dyvjx4wFo2bIlAQEBFCv2cPWktaN4mEi41uGTlsk/+HVvwQYbJ7HicVjWAqLMAeK+WxI5CtfzrgRdDALiHMW9VvesQ0/xOV8thEv9b+PkpKhb15UyZQonqqPJWm7dusXYsWP56quvAGjTpg3NmjUDeOicBGhH8XCR0oI40DpKSZCwF+Hn4keLOuMYGxU3dvRBjQ94t80TNueptgq4jItLZT78sCf9+zdIUm0VDJ2j6tVLZor9mrQhIixdupTRo0dz8+ZN8ubNy1tvvfVQxCFSQjuKh4ludYzZSpZAtCYRIsLjy7qza98lYwjI/5D1mCX4u3Cv7YLP8ePHM378jiSutoebN+2ccqRxOCdOnGDIkCFs374dgFatWjF//nzc3NwcbJnj0Y7iYWJMk7gprRor1l5DVB7wexdwN7Zq18H/kM3sIGNaawDQFTAB18xbYhIK8WmyNzNnzmT79u24uroyc+ZMXnzxRet05ocd7ShyI5ZYRLc6SU9z1dIZNliHlqKdoc4VOFUBgEfu1SCwjeDv749aF/+B4Qx8DESZhfhOZbXJmgzizp07FC9uSKNPnjyZwoULM2HChFy7cC69aK2n3IhFd8kiqQFxK6cfYkwmITIyhsjIGEqWLIBSyiYGIW2Epk2/Ys+ey/HOeh+w/T+S3jzRmuzD1atXGTlyJEePHuXIkSPZSpMps9BaTxpbLt2F9lW1Qms8Xn/9D2bP3gtAy5ZVKTTre9uprnstAeiXgUrmnbsAJyBWO4dcQmxsLPPnz+edd94hNDSUQoUKcejQIR599FFHm5at0Y4iN/KmL3SoFucocvE014iIaM6fDyEoKBwRqFKlODVqJCF0d7U9YExv3LbtIvx+GhqbL7IXeMdyxfWAAq7i59eB3357sDUNmuzDwYMHGTRoEAcPHgSgc+fOzJ07l8qV9RBsamSqo1BKdQRmYwzqfikiUxIcL46xJrWy2ZYZIvJNogtpkib+uohN3eISBY1pAkduGJ+rFMvVsYiyXu8Sdq5Q3I4ef8IrmxNXzJcgJeei9hBzHiaYjN6C6N5CbmbixIl88MEHmEwmKlWqxNy5c3n66acdbVaOIdOStiqlnIHPgCeBekBPpVRC8fxhwHER8QZaAp8opXL/YGFGsC0Anl+T8rqIXLhozv+wP2qzsm5hdf9N+YS9QFuovb86APnzO1OiRAHq5K/LoU6XERE9pPQQUL16dZRSjBo1iuPHj2snkUYys0fRGDgrIucBlFIrgaeB+JP4BSiqjDloRYBgQPf17WH0NtvytH2wvFNc2bsMHOidpSZlBYlE73wuwP9848orzRvxgs7jIDbWhFLJp/DU5C7Onz/P/v376d7dmMTRq1cvmjRpYk0upEkbmekoKgD/xStfBhLO1ZwHrAGuAkWB7iJiSnghpdRAYCCgxxMtJEwUZIlH5DL8Dvnz+9e34C83GLkWKpoPtLXUuAiEAHcx1jWEGOclCD47O2da51mTjYiKimLGjBl88MEHiAgNGzakZs2aKKW0k3gAMtNRJPXqlnAubgfgMNAaI8fjRqXUnyJiM54iIouARWBMj814U7Mx8eMQverF5X6Inyjozv1cN8QEcO9eNL+PKgTbzFHn+4a2kut5V4IIAkAk6eQ9moePHTt2MHjwYE6cOAHAiy+++FDqMmUGmfmadZm4eYZgvAsmkNikH/CzGJwFLgB6vbwFe+IQY5oYQ0y5LGAtIlTvPBq2xYkWPv7t49AWggYaTkKvfNYA3Lx5k379+tGiRQtOnDhBrVq12LRpE8uWLaNMmTKONi9XkJmOYj9QSylVzRyg7oExzBSfAKANgFKqLFAHOJ+JNuUsEsYhHhKNJv/D/jj9XIRrR21/nn/9FZeAQa9r0FgYPHgwixcvJn/+/Lz//vscPXqUNm3aONqsXEWmDT2JSIxS6lWMienOwNci8q9SarD5+ALgA2CxUuofjKGqsSJyM7NsynGM8In7PGqbo6zIEhLleigBzPuSYhOGcPdkYSAKuKcdhAYAk8mEk5PxIvHRRx9x7949Pv30U2rVquVgy3InWsIjO5CaNtO0vfD9qVylzxQTYyIk5B5hYVHcuBHOo3cqg3Pcb9EixNehw1Ns2FAA2AbcJKf9XjUZS0REBB988AGHDx9m3bp1WrQvDWgJj5yOJVidXArSMU1Sz2GdQ7D2HE5UgOEDjJ1eF2FSfigSaU3hmViIT8ckHnZ+++03Xn31VS5evIhSin379tGkSe74f5Hd0XMGswPdEkzby+HaTDExJjZsOMf772/jn3+uA3EL5azDSwXirZQ+WhVG9qN1bNwiqHXr4iUL8vPTC+MeYi5fvsxzzz1Hp06duHjxIt7e3uzatUs7iSxE9yiyA2OaxPUkIEdPdf3llxMMH/47V66EAjDx9mjodNCmjut5V4IGRtmeeKEsWzrkQ1EAuG/drYeaHm7mz5/P2LFjCQsLo3DhwnzwwQcMHz6cPHn0oysr0Xc7K4m/JiKpfNU5OE+EdUhpUxO48mTcgcB4KT7N4nvGGojCQAQQDYRhTHY7RnwnoYeaNDdv3iQsLIxnnnmG2bNnU6lSpdRP0mQ42lFkFZY1EcmRg/NV28xYqhVoe3BVSViV+Bw/vxb89tvUzDdOk6O4ffs2J0+etMp+jx07lsaNG9OxY0cHW/Zwo2MUWUVS2kw5GBFJHHfYC4y8RtwC/LP4+ORDRBJtOt6giY+IsHLlSurWrUvnzp0JDg4GIH/+/NpJZAN0jyKreKJi3Odvj8P1CMfZkk6io2M5cyaYzZvP062be6LEP0ZOhyjgZ554ohbbt//kGEM1OYqzZ88ybNgwNmzYAECzZs24c+eOTkeajdCOIquwaDRN25tj5b8fndebQ2/UhoL3GfHjJ+DtC56XYGAQIHoxnCZN3L9/n2nTpvHRRx9x//59SpYsybRp0+jfv791MZ0me2C3o1BKFRatwGY/lsB18fy2+apz4JoIawyilAtQG+7lhx3uxgY0aHCGQ4eWOdZITY6je/fu/PrrrwD07t2b6dOna22mbEqqblsp1UwpdRw4YS57K6XmZ7plOR3L7KYcTKIYRLkQyBM/XUgU7u4XtJPQpIvXX38dNzc3tmzZwpIlS7STyMbY07+bhSEHfgtARI4AT2SmUbmC+E5i2l7H2ZEOQkLuER4elTgG0cEEMRcpXfoOb731GBcvvsmxY4sdZaYmB2Eymfjyyy8ZNWqUdV/Lli05duwYrVq1cqBlGnuwa+hJRP5LoKkSmznm5EKOBhlbDhluOnPmFl5enxAZuRs2Gfv8ZsZlitNo0so///zD4MGD2bVrF2AMM3l7ewPg7OzsSNM0dmJPj+I/pVQzQJRS+ZRSozEPQ2lyFxcv3sbHZxGRkfkhbzO4WRRAB6g16SI8PJwxY8bQoEEDdu3axSOPPMLKlSvx8vJytGmaNGJPj2IwMBsjtellYAMwNDONyhVs6uZoC9KEv78/69aFYSQbBKLzwTet8ZsSneJ5Gk1SrF27lldffZWAgACUUgwbNoyPPvqI4sWLO9o0TTqwx1HUEZEX4+9QSj0G7Mwck3IJ3jkrMLdu3ToYWwSmtwST0dEsdbMG//Oe4VjDNDmS1atXExAQQIMGDVi4cCG+vr6ONknzANgz9DTXzn0PL9sCoNFScJ2XowLX/v7+KKVQHysjHtEuDB49DUD+0lHs//5drfevsYuYmBguXbpkLU+dOpW5c+eyb98+7SRyAcn2KJRSTYFmgKtS6o14h4phZKzTWLBMhW1fFTpUgyM3jP3ZtFdhDDPFm9EUL87+6Csm+vftRI8eHhQtmj/rjdPkOPbs2cPgwYO5f/8+R44cIV++fJQuXZpXX825+mUaW1IaesoHFDHXKRpv/12ga2YalePoVgfWX4QN5g2M1dcHejvQqORZt+53jH/aMFwXuZrVXLEmDdJo7CEkJIRx48axcOFCRISqVaty8eJFateu7WjTNBlMso5CRLYD25VSi0XkUnL1NBhTX9dfjCtnY4mO1q2fAYYBm+iwtwbrQ40ZTX4uWtJbYx8iwnfffcfIkSO5ceMGefLk4c033+Tdd9+lUKFCjjZPkwnYE8yOUEpNB9yBApadItI606zKqeSAfBJbt0YDpYEerH88BuqUwXfYPX5r852jTdPkEF588UW++874vTRv3pzPP/8cd3d3B1ulyUzsCWYvB04C1YD3gYvA/pROeCjZ3N0YasqmTsIIXOcB3OJ2RueBY1VY3maew+zS5Dw6duyIi4sLX3/9Ndu2bdNO4iFApZZqUil1UEQaKqWOioiXed92EWmRJRYmoFGjRnLgwAFHNJ2jMWYvFQI6opQHIuZ3hHmLkGFXHGmaJpuzadMmzp07x6BBgwBj6CkkJETLgOcwzM/yRuk5156hJ8uKq0CllD9wFaiYQv3cTfx0pgC96hl/Z2bfkTh/f3/zpwhEfqL1+i5s/SYcnE34PVbfkaZpsjHXr1/njTfeYMWKFeTPn5+2bdtSo0YNlFLaSTxk2OMoPlRKFQdGYayfKAa8nplGZWsSqsJ+e9z4m40dhWUqrCUH9dY8v8IAI4D9W30tz6GxxWQysWjRIt566y3u3LlDgQIFmDBhgs5X/RCTqqMQkf+ZP94BWoF1ZfbDyQifuM/T9hmZ6qoUc5w9aSChZpN2EpqEHDlyhEGDBrF3r7Fw9Mknn2TevHlUr17dwZZpHEmywWyllLNSqqdSarRSysO8r5NSahfw8EY/e3sY27XwOCeRzabCWldcmzeNxl7GjBnD3r17KV++PD/88AO//fabdhKaFHsUXwGVgH3AHKXUJaAp8JaIrM4C27IH8WMSQfFWmmbjTHXGUFNtoD5wBjiOn18bwEhGpNFYEBEiIiIoXLgwAHPmzGHBggW8//77FCuWM3rKmswnJUfRCPASEZNSqgBwE6gpIteyxrRswLYAeH6No61IE3GBazegnnl7mj17CrJ8+VHWPWKOV+gFdg89ly5dYvjw4YSHh7Np0yaUUtSpU4dZs2Y52jRNNiOldRRRImICEJFI4PRD5STA6EnEJxsL/lmGmyyB6+rVH7E5Hhx8j5eC43oTOj7x8BIdHc20adOoV68ea9euZf/+/Zw5c8bRZmmyMSk5Cjel1FHz9k+88j9KqaNZZaBDSZjz+vtTjrEjGdq06YJSxWwcBBizm159tW9cxTyx8MIOqHvZOK57Ew8tO3fuxMfHh7FjxxIREUH37t05efKk1mfSpEhKQ091s8yK7IolJjFtr+EkslHQetGig2zZ4glEAusB8/TXj2DdrXWsO3EEXqoN5YPh0dP4VWvFb/W16N/DzPDhw5k3z5iHUr16dT777DM6duzoYKs0OYGURAG1EKCFbBS4NiTCrwGdMf753ImJWYezsxP+h/1Zd8vcs6h7xdjQ6yU0Bq6uruTNm5exY8cybtw4ChYs6GiTNDmEVCU8HujiSnXESKPqDHwpIlOSqNMS+BTIC9xMTRrkYZfwUKoIxnrHvNZ9Tb44wd5qq6xl7Rg0ACdPniQgIID27dsDcP/+fS5cuICbm1sqZ2pyIw8i4WGPKGC6UEo5A58BT2JMvemplKqXoE4JYD7QWUTcgeczy540YclYt/SYoy1JgrJATFzROZa9l+NCRtpJaO7du8f48ePx8vLipZdeIjg4GID8+fNrJ6FJF3Y5CqVUQaVUnTReuzFwVkTOi0gUsBJ4OkGdF4CfRSQAQERupLGNjMcyJTZhINvBWGY1wXlgJgz/DSrcgv5boPkJ/Fz8kDaincRDzoYNG/D09OTDDz8kOjqazp0760WXmgcmVQkPpdRTwAyMjHfVlFL1gUki0jmVUysA/8UrX8Ym6SZgrArLq5TahpFFb7aILLXP9EwiqSmx2SA+EX9Wk+uiEgRV3w+dDnC/ZTT58unMtA87gYGBjBw5klWrjCFId3d3FixYwOOPP+5gyzS5AXt6FBMxege3AUTkMFDVjvOSeo1JGBDJAzQE/IEOwHilVKJ5ekqpgUqpA0qpA0FBQXY0/QB0qxOnCDtqW7abEisiBFU37oFfmSe1k9AA8Oyzz7Jq1SoKFizI1KlT+fvvv7WT0GQY9jiKGBG5k45rX8aQALFQEUOiPGGdP0QkXERuAjsA74QXEpFFItJIRBq5urqmw5Q0kLD3kI2mxCZEDzM93MSfiDJlyhQ6derE8ePHGTNmDHnz5k3hTI0mbdjjKI4ppV4AnJVStZRSc4Fddpy3H6illKqmlMoH9AAS6mH8CjRXSuVRShXCGJo6kQb7M48qxeCHzg7PWHftWhhPPNEVPgI2gdqsx5sfdkJDQxk5cqQ1kRBAixYtWLt2LVWrVnWcYZpciz35KIYD7wD3gRUYq7s+TO0kEYlRSr1qru8MfC0i/yqlBpuPLxCRE0qpP4CjgAljCm3WTTWyCP51q2Pbk8hGuSXmzNnLn396QmgRiNoHzU4ZCYf06uqHDhHh559/5rXXXuPKlSvkyZOHcePGaeegyXTsSYXaQET+ziJ7UiXD1lHEF/zzijectbn7g187g4iJMVGx4kyuXw+37vvmm6fp27e+44zSOIQLFy7w6quvWic1NG7cmAULFtCgQQMHW6bJKWT2OoqZSqmTSqkPlFK5J4t6/NlNR4OM7c59h5mTFIsWHbRxEhS8z/PP10v+BE2uQ0SYOnUq7u7urFu3juLFizN//nx27dqlnYQmy0jVUYhIK6AlEAQsMosCvpvZhmU6X3WETd2MzUI2C1z37u3N4MEN43Y0P0HhwvkcZ5Amy1FKcfr0ae7du0fPnj05efIkQ4YMwdlZz3bTZB12LbgTkWsiMgcYDBwGJmSmUVmCdxljW38h2wSuE9K9+zMsWPAUfLwMql6n9Wgt6vcwcPPmTY4diwvVTZ06lQ0bNrBixQoeeeSRFM7UaDIHe2IUdYHuQFfgFsYK658ctYo6t2o9GWJ/62x3fkTcEkWTQtqZstosTRYiIixZsoTRo0fj6urKkSNHyJdP9yA1GUNmxyi+AUKA9iLSQkQ+zxZSG+nFouN0JHt9hUROAmzWsfu5Ppl1xmiynBMnTtCyZUv69evHrVu3KF++PCEhIY42S6MB7JgeKyKPZoUhWYYl/3W2JA9XrgRTvnxRIG7NhLTRQ065lYiICD766COmT59OdHQ0rq6uzJw5kxdffFFrNGmyDcn2KJRS35v//hMv013Oz3AX30lkk9SmRp7rBsC7bNx4jujoWPwP+6d2miaHIyK0bt2ajz/+mOjoaAYNGsSpU6d46aWXtJPQZCtS6lG8Zv7bKSsMyXKm7YMNF7OJ4N9xoC8Affv+yrBh6wh3LwljC+JXvZVDbdNkHkophg4dSkREBAsXLqRp06aONkmjSZJkexQiEmj+OFRELsXfgKFZY14msuGioy2IJx0uQJR1f3h4NFwvDkUjtZ5TLiI2Npa5c+cyc+ZM675evXpx8OBB7SQ02Rp7gtntktiXcyOrXq62WxZjcQ5KqXgB7Ev4+l7A2dk83FDpJkz4XgewcxEHDhygSZMmjBgxgnHjxnH1qqGPqZTSAn6abE+yQ09KqSEYPYfqCWISRYGdmW1YpuFgiY6Es5v8/Pz47Tej1+A9qQ9Hd96FN1cjbXUAOzdw584d3n33XT777DNEhEqVKjF37lzKly/vaNM0GrtJKUaxAvgdmAy8FW9/qIgEZ6pVDwFJrV85+thSaAZ+pbXgX05HRPjhhx94/fXXCQwMxNnZmZEjR/Lee+9RpEgRR5un0aSJlByFiMhFpdSwhAeUUqW0s0gv5YAamEyCk5Mx1OR/2J91t8w9DaXzTOQWFi5cSGBgII8++igLFizA2ztRqhWNJkeQWo+iE3AQI9oaf76eANUz0a5cydq1p4BXgF84deompUoVpGTJgnFOArR8eA7m/v373L59m7Jly6KUYv78+Wzbto0BAwbg5GSXWo5Gky1JVcIju5FuCY83ttiWszjnxL170VSvPodr18Js9g8c6MOibkb6cb2wLueyfft2Bg8eTPny5dm0aZNeB6HJdjyIhEeqK7OVUo8Bh0UkXCn1EuADfCoiAelp0CFsC4Bvj9vuy2JH8csvJxM5CR+fcpzu/HWW2qHJWIKCgnjzzTdZsmQJYEyBvX79uhbv0+Qq7OkPfw5EKKW8gTHAJeDbTLUqo4mfe8JB9Ozpga/vSYzbBxWfDuLQ1EFsK7Aa0ENOOQ2TycRXX32Fm5sbS5YsIX/+/Lz//vscPXpUOwlNrsOeVKgxIiJKqaeB2SLylVKqT2YblqGM8In7PG0fFLDna2csSin2718JQPFR3lx+9Kw16uPn4qcD2DkIEaFDhw5s2rQJgLZt2zJ//nxq1arlYMs0mszBnidmqFLqbaAX0Fwp5QzkrBVCvT2Mv9P2Gk7CAQmK/A/7g/Fc4Q5HAO0gcipKKZo3b84///zDrFmz6NGjh45JaHI19uSjeAR4AdgvIn8qpSoDLUVkaVYYmJCcmo/CogRrQTuJnMVvv/1GdHQ0Xbp0AYwZTvfu3aNEiRIOtUujsZdMDWaLyDWl1HLAVynVCdjnKCeRK2ib9GI7Tfbk8uXLvPbaa/z888+ULl2aJ554glKlSpE/f37y58/vaPM0miwh1WC2UqobsA94HugG7FVKdc1sw3IL/of9E/UmNNmfmJgYZs2aRd26dfn5558pXLgw48aNo1ixYo42TaPJcuyJUbwD+Fqy2imlXDFG23/MTMNyC/EX05E90l9oUmHfvn0MGjSIw4cPA/DMM88we/ZsKlWq5FjDNBoHYY+jcEqQ+vQW9k2rzR64zrMtB72a9TbM8aPIlscJCwsBYlix4h9eeMEz6+3QpIrJZKJfv34cP36cypUrM2/ePJ566ilHm6XROBR7HMUfSqn1wHfmcncgiQTPmmS5l4+wsCigMABRUbGOtUdjg4hw//59ChQogJOTE5999hm///47EyZMoHDhwo42T6NxOPYEs99USj0LPI4x83+RiPyS6ZblcGyE/qJsb3MBB6zj0CTN2bNnGTp0KJUqVeKrr74CoGXLlrRs2dKxhmk02YiUcmbXUkr9qpQ6hhHI/kRERmonkTo2TgIoQwWb49pROJ779+8zadIkPDw82LhxI6tXr+bWrVuONkujyZYku45CKfUnsBTYATwFNBORZ7PQtiTJCesoLLOcLGsloqJiiYyMoXhxFyAPYWE3KFw4n2ONfIjZsmULQ4YM4fTp0wD06dOH6dOn4+qa9RkPNZqsIrPWURQVkS/Mn08ppQ6lp4GHGcuCunz5nMmXzxkIB9BOwkHExsbSr18/vv3WkCqrU6cOCxYs0MNMGk0qpOQoCiilGhCXh6Jg/LKIaMcRj4TDTZrsh7OzM3ny5KFAgQK8++67jB49Wi+a02jsIKWhp60pnCcikrU63WbsGnraFmAoxnarA2OaZIld9kh0WPSA9MrsrOOff/4hMjISX19fAG7dusXt27epUaOGgy3TaLKWTBl6EpFW6TfJwYzeBpEx8EhhWHrM2GcRBswgkutBWJIPiQixsSacnXPOkpPcRHh4OBMnTmTWrFnUqlWLI0eOkC9fPlxcXHBxcXG0eRpNjiJ3Tr+5dNf4O2qb8bdKsQx3FEk5CUtOiXPngqlZcy5OTorXX29Cw4bl6dbNPUPb1yTPmjVrGD58OAEBASilaNu2LdHR0eTLp2NDGk16yFRHoZTqCMwGnIEvRWRKMvV8gT1AdxHJeGmQTJQVT5i+NCwsiqZNjfn4JpMwc+YeSpYsQM+eGeuoNIkJCAhgxIgR/PrrrwD4+PiwcOFCGjVKV29bo9GYyTRHYc5b8RnQDrgM7FdKrRGR40nUmwqsz7DGe9WzLbesnGGXTi1ofeTINe7ft1153bFjTZ2vIJOJjY2lZcuWXLhwgaJFi/Lhhx8ydOhQ8uTJnZ1mjSYrsScfhQJeBKqLyCRzPopHRGRfKuc1BSaKSAdz+W0AEZmcoN7rQDTgC/wvtR6Fo9dRxA9aJ5dT4vLluwwZ8hv/+99p4DbwNXDXelwHszMOEbE64aVLl7J27Vo+/fRTKlSokMqZGs3DRabmowDmAyagNTAJCAV+wniwp0QF4L945cuAzRQkpVQF4BnztZO9nlJqIDAQoHLljOsdPAgJh5ziU7FiMdas6YGTkztwFsMPGvj56dzYGUFISAhvv/02lSpV4p133gGgV69e9O7d28GWaTS5D3scRRMR8VFK/Q0gIiFKKXuigkmNtSR8un4KjBWR2JSGZkRkEbAIjB6FHW07HOP7nAB0DyIjERFWrFjBG2+8wY0bNyhatCivvvoqxYsX18N7Gk0mYc/czWhzHEHAmo/CZMd5l4H4Av4VgasJ6jQCViqlLgJdgflKqS52XDtLsSQf0gmIHMvp06dp164dL730Ejdu3KB58+bs3r2b4sWLO9o0jSZXY0+PYg7wC1BGKfURxgP9XTvO2w/UUkpVA64APTByb1sRkWqWz0qpxRgxitV2WZ4FJBe4tkyD1WQNMTExfPjhh0yePJmoqChcXFyYPn06ffv21b0IjSYLsEdmfLlS6iDQBmM4qYuInLDjvBil1KsYs5mcga9F5F+l1GDz8QUPZnoytFllW97cPd2Xiu8kkgtcazIfZ2dn/vzzT6Kioujfvz9Tp06ldOnSjjZLo3loSNVRmGc5RQBr4+8TkYDUzhWRdSRIcpScgxCRvqldzy6OBmXIZeKTUuDawvz5+zGZhEaNyuPtXZauXbtkuB0PE9evXycyMpIqVaqglGLBggUEBgbyxBNPONo0jeahw56hp98w4hMKKABUA04BuXqpsf9h/zTV/+ST3Zw/HwKAs7MiNvYgoGc5pRWTycSiRYt46623aNSoERs3bkQpRa1atahVq5ajzdNoHkrsGXqySe6slPIBBmWaRdkEy7CTPfGI4OB7VicBEBsbg5FaHH77TQ9X2cvhw4cZPHgwe/fuBSBfvnyEhYVRtGhRB1um0TzcpHnZqogcMktuZE82dcvQy9kTlzh4MOFkriAgRvcm7CQ0NJT33nuP2bNnYzKZKF++PLNnz+a5557TwWqNJhtgT4zijXhFJ8AH40mYPfEuk+VN1qrlwvTp7Thw4CqrVv0JXNVrJ+wkKioKHx8fzp49i5OTE6+99hqTJk2iWLFijjZNo9GYsadHEb/fH4MRs/gpc8zJHqQ1PlG1aglGj24GwKpVz5P0WkNNUuTLl49evXqxdu1aFixYQMOGDR1tkkajSUCKWk/mhXZTROTNrDMpZbJC6ylhzus0nauTE6VIdHQ0s2bNonLlyvTo0QMwehXOzs44Ozs72DqNJveSKVpPSqk85rUQPuk3LWej101kLDt37mTw4MEcO3YMV1dXOnXqRJEiRXSeCI0mm5OShIdFHfawUmqNUqqXUupZy5YVxjmCtAw73b4dyddf/83x49k3ZJMdCA4OZsCAATz++OMcO3aM6tWr8+2331KkSBFHm6bRaOzAnhhFKYy5nq2JW08hwM+ZaFf6OXLDtpyG4HZ8yY7UpsVu2HCOrl2/JzQ0innznqRePdc0m5rbERG+/fZbRo0axc2bN8mbNy9jx45l3LhxFCxY0NHmaTQaO0nJUZQxz3g6RpyDsJB9B+Dbfm9bDnrVrtMSOomUhp1Wrz5Jt24/EB1taCPeuBGePltzANHR0Vy+fJnIyMg0nysiVKhQgW+//Zb8+fPj4uJC3rx5uXjxYsYbqtFoAChQoAAVK1Ykb968GXbNlByFM1AE++TCczz2OgmAXbv+szoJgKCgiEy1zZFcvnyZokWLUrVqVbvWNJhMJkwmkzWzXKVKlbh//z4uLi56TYRGk8mICLdu3eLy5ctUq1Yt9RPsJCVHESgikzKspWxM/LiEPQHsjz5qzZ9/BrBnz2UAChXKOM+d3YiMjLTbSdy5c4eAgACrYwEoWrSoXlmt0WQRSilcXFwICsrYuGlKjiJnvv55pT1WkBa5DoC8eZ1ZtaorPj4LmTq1LS+/nLsnhqXmJKKiovjvv/8ICTFkTJycnIiNjdXTXTUaB5AZPfeUHEWbDG8tK0ijrHhaexMWKlcuzsmTr1K6dKE0tZebEBGCgoK4cuUKsbGxODk5Ub58ecqUKYOTkz05sTQaTU4g2f/NIhKclYY4ipR6EyaTsH//lWTPfZidhMlk4uTJkwQEBBAbG0vx4sVxd3fnkUceyXAn4ezsTP369fHw8OCpp57i9u3b1mP//vsvrVu3pnbt2tSqVYsPPvjAZrHj77//TqNGjahbty5ubm6MHj06Q23LTHr27ImXlxezZs2yq35mTTcWEUaMGEHNmjXx8vLi0KFDydZr3bo1d+/ezRQ7MoIlS5ZYlYiXLFmSZJ2RI0dSv3596tevT+3atSlRooT1WEBAAO3bt6du3brUq1fPOjGjR48enDlzJgu+gYMQkRy1NWzYUDIKv7/9hE0Im0jy+KpVxwQmir//cjly5Jpd18QI9GeYjY7m+PHjyR67cOGCHDlyRIKDg8VkMmWaDYULF7Z+7t27t3z44YciIhIRESHVq1eX9evXi4hIeHi4dOzYUebNmyciIv/8849Ur15dTpw4ISIi0dHR8tlnn2WobdHR0Rl6PQuBgYFSuXLlNJ0T/z5lJL/99pt07NhRTCaT7N69Wxo3bpxkvf/973/y+uuvp+naMTExGWGiXdy6dUuqVasmt27dkuDgYKlWrZoEBweneM6cOXOkX79+1nKLFi1kw4YNIiISGhoq4eHhIiKybds2eeWVVzLP+DSS1P9b4ICk87nr8Ad/WreMchTxnYTf336JjkdEREmNGrMFJgpMFKUmyrx5e1O9bm51FCaTyfrdMnpLjfgPwM8//1yGDBkiIiJffvml9OrVy6bu2bNnpWLFiiIi0qtXL/nqq69SvX5oaKj07dtXPDw8xNPTU3788cdE7f7www/Sp08fERHp06ePjBw5Ulq2bCmvv/66VKlSRUJCQqx1a9SoIdeuXZMbN27Is88+K40aNZJGjRrJX3/9lajte/fuWduuX7++bNmyRUREPD09pUCBAuLt7S07duywOefatWvSpUsX8fLyEi8vL9m5c6eNvaGhodK6dWtp0KCBeHh4yOrVq0VEJCwsTPz8/MTLy0vc3d1l5cqVIiIyduxYqVu3rnh6esqoUaMS2Thw4EBZsWKFtVy7dm25evVqono9e/aUrVu3WstPP/20+Pj4SL169WThwoXW/YULF5bx48dL48aN5c8//5Rvv/1WfH19xdvbWwYOHGh1HoMHD5aGDRtKvXr1ZMKECYnaSysrVqyQgQMHJvu9kqJp06ZWx/Dvv//KY489lmS92NhYqVq1aqa9OKSVjHYUaZYZzy2kNh32jTfWc+5cXI4JJydF27bVU7ymv3/axARzCvfv3ycgINWEhplObGwsmzdv5uWXXwaMYaeEIoI1atQgLCyMu3fvcuzYMUaNGpXqdT/44AOKFy/OP//8A2ANyqfE6dOn2bRpE87OzphMJn755Rf69evH3r17qVq1KmXLluWFF15g5MiRPP744wQEBNChQwdOnLDNIvzZZ58B8M8//3Dy5Enat2/P6dOnWbNmDZ06deLw4cOJ2h4xYgQtWrTgl19+ITY2lrCwMJvjBQoU4JdffqFYsWLcvHmTRx99lM6dO/PHH39Qvnx5a46UO3fuEBwczC+//MLJkydRStkM61m4cuUKlSpVspYrVqzIlStXKFeunE29nTt3snDhQmv566+/plSpUty7dw9fX1+ee+45XFxcCA8Px8PDg0mTJnHixAmmTp3Kzp07yZs3L0OHDmX58uX07t2bjz76iFKlShEbG0ubNm04evQoXl5eNm1Onz6d5cuXJ7L5iSeeYM6cOXZ9j+S4dOkSFy5coHXr1oDxb16iRAmeffZZLly4QNu2bZkyZQrOzs44OTlRs2ZNjhw5kiuFLXOXo3hji215ZutUT0kugN2xY02OHQvir7+MB2T//g2oUyflPM3r1pmdTy7JQxEVFcWdO3f4999/MZlMHDp0iAoVKuDq6pqlayLu3btH/fr1uXjxIg0bNqRdu3aA0RtOzo602Ldp0yZWrlxpLZcsWTLVc55//nnrrK7u3bszadIk+vXrx8qVK+nevbv1usePH7eec/fuXUJDQ22mC//1118MHz4cADc3N6pUqcLp06dTlFnfsmULS5cuBYz4TfHixW2Oiwjjxo1jx44dODk5ceXKFa5fv46npyejR49m7NixdOrUiebNmxMTE0OBAgV45ZVX8Pf3p1OnTonak3gxHwtJ3d/g4GCb7zZnzhx++eUXAP777z/OnDmDi4sLzs7OPPfccwBs3ryZgwcP4utrpLi5d+8eZcoYagrff/89ixYtIiYmhsDAQI4fP57IUbz55pu8+aZ9mqX2fg8LK1eupGvXrtZ/55iYGP7880/+/vtvKleuTPfu3Vm8eLH1xaVMmTJcvXo1VzqK3DU15dvjttsD8PTTbvz5Zz/27n2Fl19uwJQpbe0+Nzdktfvzzz9p0KABt2/fxmQyUapUKTw8PChTpkyWL5wrWLAghw8f5tKlS0RFRVnfwt3d3UmoJHz+/HmKFClC0aJFcXd35+DBg6lePzmHE39fwpXphQsXtn5u2rQpZ8+eJSgoiNWrV/Pss4YUmslkYvfu3Rw+fJjDhw9z5cqVRGtKknp4PSjLly8nKCiIgwcPcvjwYcqWLUtkZCS1a9fm4MGDeHp68vbbbzNp0iTy5MnDvn37eO6551i9ejUdO3ZMdL2KFSvy33//WcuXL1+mfPnyierlyZMHk8lYiLpt2zY2bdrE7t27OXLkCA0aNLDewwIFClgfviJCnz59rPfo1KlTTJw4kQsXLjBjxgw2b97M0aNH8ff3T1IdYPr06dbAc/xtxIgR6f4eFlauXEnPnj1tzm/QoAHVq1cnT548dOnSxSawHxkZmWulaXKXo8gEGjeuwJdfdqZUqdz5A0iKe/fu0bVrV44fP06ePHmoXbs21atXz1BJgPRQvHhx5syZw4wZM4iOjubFF1/kr7/+YtOmTVa7R4wYwZgxYwDjbfPjjz/m9OnTgPHgnjlzZqLrtm/fnnnz5lnLlqGnsmXLcuLECevQUnIopXjmmWd44403qFu3Li4uLkleN6lhpCeeeMI6dHL69GkCAgKoU6dOivehTZs2fP7554AxHJdwltGdO3coU6YMefPmZevWrVy6dAmAq1evUqhQIV566SVGjx7NoUOHCAsL486dO/j5+fHpp58maWPnzp1ZunQpIsKePXsoXrx4omEngDp16nD+/HmrDSVLlqRQoUKcPHmSPXv2JPtdfvzxR27cMDTagoODuXTpEnfv3qVw4cIUL16c69ev8/vvvyd5/ptvvml1MvG3hMNOAB06dGDDhg2EhIQQEhLChg0b6NChQ5LXPXXqFCEhITRt2tS6z9fXl5CQEOtiti1btlCvXj3r8dOnT+Pu7p7k9XI62lFoAOPNLiYmBjDe4GfOnMmECRMoX758tso216BBA7y9vVm5ciUFCxbk119/5cMPP6ROnTp4enri6+vLq68a+l5eXl58+umn9OzZk7p16+Lh4UFgYGCia7777ruEhITg4eGBt7c3W7duBWDKlCl06tSJ1q1bJ/lgjE/37t1ZtmyZddgJjKGXAwcO4OXlRb169ViwYEGi84YOHUpsbCyenp7WoYz8+fOn2Nbs2bPZunUrnp6eNGzYkH///dfm+IsvvsiBAwdo1KgRy5cvx83NDTDiII0bN6Z+/fp89NFHvPvuu4SGhtKpUye8vLxo0aJFklNx/fz8qF69OjVr1mTAgAHMnz8/Sbv8/f3Ztm0bAB07diQmJgYvLy/Gjx/Po48+muQ59erV48MPP6R9+/Z4eXnRrl07AgMD8fb2pkGDBri7u9O/f38ee+yxFO+JPZQqVYrx48fj6+uLr68vEyZMoFSpUgBMmDCBNWvWWOt+99139OjRw6ZX6ezszIwZM2jTpg2enp6ICAMGDADg+vXrFCxYMNXfSU4lxcRF2ZEUExctPWZb7u2R7HUsyYmkjfH9g4Pv8dVXhxg9ulm6h1ZyatKi48ePM3jwYNq1a8f48eNtjp04cYK6des6yDJNTiIwMJDevXuzceNGR5uS5cyaNYtixYpZ4xWOJqn/t5mSuChHkoJjSImNG8/xwgs/c/NmBE2bVuLxxytnsGHZk4iICD788EOmT59OTEwMly5dYsyYMam+0Wo0SVGuXDkGDBjA3bt3s1UvNCsoUaIEvXr1crQZmcbDPfQUmZcBA9bQvv0ybt40FGCXLDnsWJuyiN9//x0PDw8mT55MTEwMgwYN4vDhw9pJaB6Ibt26PXROAqBfv35WxeTcyMPtKARu3LCVCF+16l8iIqIdZFDmEx4ezvPPP4+fnx8XLlzAy8uLXbt2sWDBArumhWo0moePh85R+B/2t8YnKBjNzz9344034gJtw4b54uSUM4Vz7aFQoUIEBwdTuHBhZsyYwcGDB21mdmg0Gk1Ccm9fKRksK7LBWJXt7OzEjBntiY0VmjSpQM+eng60LnM4cOAAJUqUoGbNmiil+PLLL3F2dqZy5YcjFqPRaB6Mh65HYUHaiHVVtlKKTz/tmC4n4e/vj1IqW2Zvu3PnDsOHD6dx48YMHjzYOhurWrVq2kloNBq7yV2OwnWe7ZaA+LknMgqLbIeF7CDfISKsWrUKNzc35s2bh5OTEz4+PtZ1EjkNLTPuWJnxkydP0rRpU/Lnz8+MGTOSrSeiZcZzLelVE3TUlqJ6bOm5tls8UlOLTS9kM7XYs2fPSocOHax2NW3aVI4cOZLu66UkM55VaJlx+8gsmfHr16/Lvn37ZNy4cTJ9+vRk62mZ8dwrM567ehQpYIlNNLv2PB12TCAoKNzuc+MPLyXcshOhoaE0atSI9evXU6JECRYuXMhff/2VSEgtvajNKlO2tNC0aVOr4ueKFSt47LHHaN++PWAE6ufNm8eUKVMAmDZtGu+88451ZXKePHkYOnRoomuGhYXRr18/PD098fLy4qeffgJs39B//PFH+vbtC0Dfvn154403aNWqFW+++SZVq1a16eXUrFmT69evExQUxHPPPWddCbxz585EbUdGRlrbbtCggXVVePv27blx4wb169fnzz//tDnn+vXrPPPMM3h7e+Pt7c2uXbsSfZ82bdrg4+ODp6cnv/76K2DMePP398fb2xsPDw9WrVoFwFtvvUW9evXw8vJKssdVpkwZfH19U5VwWb58OU8//bS13KVLFxo2bIi7uzuLFi2y7i9SpAgTJkygSZMm7N69m2XLlllXjA8aNIjY2FgAhgwZQqNGjXB3d+e9995LsW17WL9+Pe3ataNUqVKULFmSdu3a8ccff6R4znfffWfVezp+/DgxMTFWUcoiRYpQqJCRvKx58+Zs2rQpx/baUyNTg9lKqY7AbMAZ+FJEpiQ4/iIw1lwMA4aIyJHMtKnWxhd4bckfjBq1AX//Wowb15zGjSukeE7C4aWEZIfhJoCiRYsycuRIzp49y4wZM6wqnLkFLTNukNUy4/aiZca1zHiaUUo5A58B7YDLwH6l1BoRiS/regFoISIhSqkngUVAk3Q3GvSqTdH/sL/NLCdCCrNkieGHYmJM/PrrKYYO9bX78pLNpDmCgoJ48803adOmjXVV6Pjx4zOtp2ORO8lqtMy4LVktM24vWmZcy4ynh8bAWRE5LyJRwErg6fgVRGSXiFhe3/YAFTOq8UROAmh88ykKFYrrPleoUJQ2baplVJNZhslk4ssvv6ROnTosWbKEd955h+hoY5FgdhsOywi0zHjayGiZcXvRMuNaZjw9VAD+i1e+bN6XHC8DSWoJK6UGKqUOKKUOWCR+UyN+BjtpI0gbYe/g79i5sz+VKhlva336eOPsnLPCNMeOHeOJJ55gwIABhISE0LZtWzZv3uxwCfCsQMuMG2S1zLi9aJnx3Csznmmzk4DnMeISlnIvYG4ydVsBJwCX1K6bWs7s+LOb2JT0bKRr10JlwIA1Eh4eleK1LJANZjZFRETImDFjJE+ePAJI2bJlZcWKFWIymTK13ew260lEpFOnTrJ06VIRETl69Ki0aNFCateuLTVq1JCJEyfa3JO1a9eKj4+PuLm5Sd26dWX06NGJrh8aGiq9e/cWd3d38fLykp9++klEjDzZ1atXlxYtWsiwYcNscmb/8MMPNtfYv3+/ALJ48WLrvqCgIOnWrZt4enpK3bp1ZdCgQYnavnfvnvTp0ydRzuwLFy6Iu7t7kvfj2rVr0rlzZ/Hw8BBvb2/ZtWuXzX0KCgqSRx99VBo2bCgvv/yyuLm5yYULF+SPP/4QT09P8fb2lkaNGsn+/fvl6tWr4uvrK56enuLh4WFjv4XAwECpUKGCFC1aVIoXLy4VKlSQO3fuJKo3adIk+eKLL0REJDIyUjp27Cienp7StWtXadGihTWfdsJ/z5UrV4q3t7d4enqKj4+P7N6923qf3dzcxM/PT5555hn55ptvkrwfaeGrr76SGjVqSI0aNeTrr7+27h8/frz8+uuv1vJ7770nY8eOTXT+hg0brPeqT58+cv/+fREx/k18fX0f2L6MIqNnPWWmo2gKrI9Xfht4O4l6XsA5oLY9103WUWy9JNJwiQx4q1mGToP18/PLFo4iMjJS3NzcRCklQ4cOlZCQkCxpNzs4Ck3O4OrVq9K2bVtHm+EQZs6cKV9++aWjzbCS0Y4iM2c97QdqKaWqAVeAHsAL8SsopSoDPwO9ROT0A7U2ehtciuuCpyXw6u/vny1nNl2+fJlChQpRqlQp8ufPz+LFiwFo0iT98X6NJrPQMuNaZjzNiEgM8CqwHmNY6XsR+VcpNVgpNdhcbQLgAsxXSh1WSiWTkcgO4jmJ9354MvHhS7eTDBza6ySyMg92TEwMs2bNom7dujYzOpo0aaKdhCZbo2XGcyeZ+s1EZB2wLsG+BfE+vwK8kpFtTvzJj/IhxcHcyp07kQwc+D++//5f9u8fQKNGtrMcLE4iq51Bcuzdu5dBgwZx5IgxjffOnTvExMTk6h+hRqPJ3uSsKT8p8aYvi1rvNJyEmRMngmjW7Gu+/97IKbx48eFkT3e0k7h9+zZDhw6ladOmHDlyhCpVqrB27Vp+/PFH7SQ0Go1DyT2OYky8IZkqRtc3MDCM48fjptN+990x7t+PyXaKryEhIdStW5fPP/8cZ2dnxo4dy7///vtAi580Go0mo8h1r6rny9yk+ozOALRqVRVPzzL8848xR/v+/WAKFHAFbtuc42gJjpIlS/Lkk09y+vRpPv/8czw9c19ODI1Gk3PJFT0KS9a6QQNXUmPO+9DSyLWglOL1143sdd27uxMe/gkWJ+Hn52ed+pXVw073799n0qRJbN++3bpv3rx57NixQzuJdLJmzRqrGODDzOLFi3F1daV+/fq4ubklkihftGgRbm5uuLm50bhxY/766y/rsejoaN566y1q1aqFh4cHjRs3TnahmyN5/fXX2bFjh6PNSBbL6veaNWsyYsSIJCfRREdH06dPHzw9Palbty6TJ08GDGHP+CvMS5cuzeuvvw4Yz4hvvvkmK79KHOmdV+uozWYdxdZLEugxVQ74vpns2ol796Llp5+Oi8lkyhbrITZv3iy1a9cWQOrWrZulMsvpIdF87BSk3G1Y8o9tvZGbM9fQNGAymSQ2NtZh7WeWNLmIyDfffCPDhg0TEZGbN2+Ki4uLBAQEiEjc4sOgoCARETl48KBUqlRJAgMDRURk7Nix0rt3b4mMjBQRYxHZqlWrMtS+B/2937p1S5o0aZKmczLzfieFr6+v7Nq1S0wmk3Ts2FHWrVuXqM7y5cule/fuImLI41epUkUuXLiQqJ6Pj49s377dWq9+/fp22aBlxuMzehuPXCtEjEDHYv42WessFCiQh2efrevweMSNGzfo1asXbdq04fTp07i5uTF//nyr5o0maS5evIibmxuvvPIKHh4evPjii2zatInHHnuMWrVqsW/fPsB4k371VUMUMikZ7osXL1K3bl2GDh2Kj48P//33H2+++SYeHh54enpaJbcTsm/fPpo1a0aDBg1o1qwZp06dAoypyv/++6+1XsuWLTl48CDh4eH0798fX19fGjRoYJX4Xrx4Mc8//zxPPfUU7du3T1YKHAw1Wzc3N9q1a0fPnj2tyYLOnTtHx44dadiwIc2bN+fkyZMp3jsXFxdq1qxJYGAgAFOnTmX69OmULl0aAB8fH/r06cNnn31GREQEX3zxBXPnziV//vyAIWHSrVu3RNfdv38/zZo1w9vbm8aNGxMaGmpz/wE6derEtm3bAFtZ8Y8//tjmmtu2beOpp54CYMOGDTRt2hQfHx+ef/75RKq4YMi9x9ejmjRpEr6+vnh4eDBw4EDr23vLli0ZN24cLVq0YPbs2Rw8eJAWLVrQsGFDOnToYL0nX3zxBb6+vnh7e/Pcc88RERGR4j1NjcDAQO7evUvTpk1RStG7d29Wr16dqJ5SivDwcGJiYrh37x758uVLNK34zJkz3Lhxg+bNmwOGjH7VqlWtv/ksJb0exlGbTY+i9FwJc5kjLUu8K2+3WipXrtxN0cvigB5FbGysLFy4UEqUKCGAFChQQD788EPr0v/sjqN7FBcuXBBnZ2c5evSoxMbGio+Pj/Tr109MJpOsXr1ann76aRGxfZPu1q2bzJo1S0SMN9jbt2/LhQsXRClllYf48ccfpW3bthITEyPXrl2TSpUqydWrVxO1f+fOHesb6caNG+XZZ58VEWMl7oQJE0TEWJFcq1YtERF5++235dtvvxURkZCQEKlVq5aEhYXJN998IxUqVJBbt26JiPGWa5HBCAoKkho1aojJZJL9+/eLt7e3REREyN27d6VmzZrWZEGtW7eW06dPi4jInj17pFWrVonsjX8fLl26JN7e3nLv3j0RESlZsqTcvn3bpv7q1avlmWeekSNHjtj1tnr//n2pVq2a7Nu3z+b+xG9XRMTf398q2QFYeybR0dFSqVIlCQsLExGRwYMHy7fffitBQUHSvHlz6/4pU6bI+++/n6j93r17y5o1a6xly/0UEXnppZesx1q0aCFDhgwREZGoqChp2rSp3LhxQ0QMyRBLMqKbN29az3/nnXdkzpw5idrcsmWLeHt7J9qaNm2aqO7+/fulTZs21vKOHTvE398/Ub2oqCjp3r27lC5dWgoVKiQLFy5MVOf999+XUaNG2ez78MMPZcaMGYnqJiQnrczOdCJF8I0N5MTt/Gzbep4ZVT+lZ09PJkx4gho1SjnaPMBYB/HOO+9w+/ZtOnTowGeffUaNGjUcbVaOolq1atbYjbu7O23atEEphaenpzUVZXySkuEOCQmhSpUqPPqoEbP666+/6NmzJ87OzpQtW5YWLVqwf/9+OnfubHOtO3fu0KdPH86cOYNSyqrS261bN9q1a8f777/P999/z/PPPw8Yb8Vr1qyx9gIiIyMJCAgAsCbNgeSlwP/66y+efvppqwqp5W07LCyMXbt2WdsBI9aVFKtWrWLr1q2cOnWKL774ggIFCiR7b0WSl2pPilOnTlGuXDmrLLg9i+viy4rnyZOHjh07snbtWrp27cpvv/3GtGnT2L59O8ePH+exxx4DICoqykaQz0JgYCCurq7W8tatW5k2bRoREREEBwfj7u5uvWcWufdTp05x7Ngxqzx9bGws5cqVAwyRzXfffZfbt28TFhaWpEhgq1at7BZLlCTiEUnd33379uHs7MzVq1cJCQmhefPmtG3blurVq1vrrFy5km+//dbmvDJlyqTak8wMcrSj6O12mRM7C1nL0dEmtmy5wJQpbRxolZFJLE+ePOTPn5+SJUuyYMECYmNjef755x0+BPbAJMj5kSy9PYwtA7AMhQA4OTlZy05OTmnKKBZfGjyp/9BgJBL64osvAGMx5vjx42nVqhW//PILFy9epGXLlgBUqFABFxcXjh49yqpVq6wJe0SEn376KZEC7N69e23ajy8FnjdvXqpWrUpkZGSydplMJkqUKGHXA6t79+7MmzeP3bt34+/vz5NPPskjjzxCvXr1OHjwoDURD8ChQ4eoV68eNWvWJCAgIFG+jIQk51jiS4yDrSx7fFlxi32fffYZpUqVwtfXl6JFiyIitGvXju+++y7F71awYEHrtSMjIxk6dCgHDhygUqVKTJw40aZdy/0WEdzd3dm9e3ei6/Xt25fVq1fj7e3N4sWLrcNl8dm6dSsjR45MtL9QoUKJsgtWrFiRy5cvW8vJSZmvWLGCjh07kjdvXsqUKcNjjz3GgQMHrI7iyJEjxMTEJMpt4Sgp8xwdo/jh+e8o5hVgLdev/wh7975CuXLJ/9AzmzVr1lCvXj2mTZtm3ffcc8/RrVu3nO8kcgipyXCDIe+9atUqYmNjCQoKYseOHTRu3Jhhw4ZZparLly/PnTt3qFDBUMe3aG1Z6NGjB9OmTePOnTvWHk+HDh2YO3eu9YH/999/J2ljclLgjz/+OGvXriUyMpKwsDDrjLxixYpRrVo1fvjhB8B4+FlW7ydH06ZN6dWrF7NnzwZgzJgxjB07llu3bgGG7PnixYsZOnQohQoV4uWXX2bEiBFERUUBxtv7smXLbK7p5ubG1atX2b9/P2DM0omJiaFq1aocPnwYk8nEf//9l+I4esuWLTl06BBffPGF9a3/0UcfZefOnZw9exaAiIgIqzx8fOrWrWutY3EKpUuXJiwsjB9//DHJ9urUqUNQUJDVUURHR1vjS6GhoZQrV47o6OgkM+VBXI8i4ZbQSYChd1W0aFH27NmDiLB06VKb9LAWKleuzJYtWxARwsPD2bNnjzVlL9imYI3P6dOn8fDImBewtJBjHYX/YX/w+I+ar27kpHsFhnVxY8OGlyhf3jFOIiAggC5duvD0008TEBDA+vXrbd6wNFnH7Nmz2bp1K56enjRs2NAm6GzhmWeewcvLC29vb1q3bs20adN45JFHEtUbM2YMb7/9No899pg1l7OFrl27snLlSpvg7Pjx44mOjsbLywsPDw/Gjx+fpI0vvvgiBw4coFGjRixfvtz6kPD19aVz5854e3vz7LPP0qhRI2sGu+XLl/PVV1/h7e2Nu7u7TQA8OcaOHcs333xDaGgonTt3pn///jRr1gw3NzcGDBjAsmXLrMMwH374Ia6urtSrVw8PDw+6dOliM8wDkC9fPlatWsXw4cPx9vamXbt2REZG8thjj1mHCEePHo2Pj0+yNjk7O9OpUyd+//1366JSV1dXFi9eTM+ePfHy8uLRRx9NcojF39/f+tZfokQJBgwYgKenJ126dLEOhyUkX758/Pjjj4wdOxZvb2/q169vfch/8MEHNGnShHbt2tk8qB+Ezz//nFdeeYWaNWtSo0YNnnzS0J5bs2YNEyZMAGDYsGGEhYXh4eGBr68v/fr1s8ne9/333yfpKHbu3Enbtm0zxM40kd7ghqM2SzDbXinx+DLhZEIwOyoqSqZPny6FChUSQIoWLSqzZ8/O9tNe7UXLjGc9oaGhImJMh2zYsKEcPHjQwRZlLx577LEsk9nPThw6dEheeuklu+rqYHYCLNNh7VGBhYxdhX3z5k1r0ncw8ijPmjXLOlSh0aSHgQMHcvz4cSIjI+nTp0+Kb+cPI5988gkBAQGUKFHC0aZkKTdv3uSDDz5wSNs53lE4UibcxcWF0qVLU61aNebNm+dwKRBN7mDFihWONiFb87BK7VtmbTmCHOsofM5XAuDa+n/wca7Eodj/Ml0qXERYvnw5jRs3pnbt2iilWLZsGcWLF6dQoUKpX0Cj0WhyIDnSUeyat59J77xOfiB/EYWHszMlb43I1DZPnTrF0KFD2bJlC23atGHjxo0opayBQI1Go8mt5EhH0fG13wk1xc03X1+sKO0zqa3IyEgmT57MlClTiIqKwsXFhZdeeimTWtNoNJrsR45zFPfvx9g4CYBSmTQldtOmTQwZMsQ6b7t///5MmzYNFxeXTGlPo9FosiM5bh3FvXu2K3Fd8zjRYF7GB3muX79Op06dOHv2LPXq1WPHjh189dVX2klocgwXL16kYMGC1K9fn3r16tG7d2+rBAkYMiaNGze2yo4vWrTI5vylS5fi4eGBu7s79erVs8qSZCdWr17NpEmTHG1GsgQHB9OuXTtq1apFu3btCAkJSVTn1KlTNtLixYoV49NPP7Uenzt3LnXq1MHd3Z0xY8YA8M8//9C3b98s+hbkvHUUnp71hTd8hG7tBHrIRx/tsGtesT3ExsaKyWSylqdOnSqTJ0/OMQJ+mUHC+dgw0WZLjoULD9jUGzBgTbJ1HY0j17xkpuT5hQsXxN3dXUSM79iqVStZtmyZiIgEBgZKpUqVrGs0goKCxMfHR/73v/+JiMi6deukQYMGcuXKFRERuXfvnixatChD7csI+e+mTZtaZdOzqs208Oabb8rkyZNFRGTy5MkyZsyYFOvHxMRI2bJl5eLFiyJiCBK2adPGKv1+/fp1a902bdrIpUuXkrzOQy8zfinmPPgdgoEbgZWMG9c8Q657+PBhmjVrZiNZMGbMGN566y3y5cuXIW1o0o69MuPJyYHHxsYyevRoPD098fLyYu7cuQBUrVqVSZMm8fjjj/PDDz/w3Xff4enpiYeHB2PHjk3SluSkwceOHcv8+fOt9SZOnMgnn3wCwPTp0/H19cXLy4v33nvP+p0SSp4PGTKERo0a4e7ubq0Hht6Um5sbjz/+OCNGjLCuZE5Ozjw5nJ2dady4MVeuXAEMTau+ffta12iULl2aadOmWZM/TZ48mRkzZlh1igoUKMCAAQMSXTc5Sff4MhMzZsxg4sSJgK3890cffUTVqlWtCgYRERFUqlSJ6OhouyTVT58+Tf78+a2y6WvXrqVJkyY0aNCAtm3bcv36deu/x8CBA2nfvj29e/cmKCiI5557Dl9fX3x9fdm5cyeQ/G/oQfj111/p06cPAH369ElScjw+mzdvpkaNGlSpUgUwVnm/9dZbVn2zMmXKWOs+9dRTrFy58oFttIv0ehhHbdQ2VmTzUcassr57966MHDlSnJycBJD69evb9Coedhzdo7BXZjw5OfD58+fLs88+az1mkaWuUqWKTJ06VURErly5IpUqVZIbN25IdHS0tGrVSn755ZdEtiQnDX7o0CF54oknrPXq1q0rly5dkvXr18uAAQOsvQZ/f3/Zvn17Isnz+HbFxMRIixYt5MiRI3Lv3j2pWLGinD9/XkREevToYZWsTk7OPOG9s/Qo7t27Jy1btpQjR46IiMgzzzwjq1evtql/+/ZtKVmypIgkLUmeFMlJulvaFRGZPn26vPfeeyJiK/8tItK5c2fZsmWLiBjy3y+//LKI2Cep/vXXX8sbb7xhLQcHB1v/737xxRfWY++99574+PhIRESEiIj07NlT/vzzTxExpNjd3NxEJPnfUHzu3r2bpOS4t7e3/Pvvv4nqFy9e3KZcokSJRHXi069fP5k7N06+39vbWyZMmCCNGzeWJ554wirvLiLy119/SadOnZK8zkO/MrtyUEneWdQB1sEg0u9NRYTVq1czYsQILl++jJOTE6+99hqTJk3S4n3ZDHtkxpOTA9+0aRODBw8mTx7jp26R+YY4Ger9+/fTsmVLq67Riy++yI4dO+jSpYuNHSJJS4M3aNCAGzducPXqVYKCgihZsiSVK1dmzpw5bNiwgQYNGgBGj+TMmTNUrlzZRvIcDG2fRYsWERMTQ2BgIMePH8dkMlG9enWqVasGQM+ePa1xhOTkzOvWrWtj87lz56hfvz5nzpyha9euVj0hkaRVYNP6209O0j0lLPfd8nnVqlW0atWKlStXMnToULsl1RNKjl++fJnu3bsTGBhIVFSU9b4BdO7c2aq6umnTJo4fP249dvfuXUJDQ5P9DcWnaNGidkuOp5WoqCjWrFljTYsKEBMTQ0hICHv27GH//v1069aN8+fPo5SiTJkyXL16NVNsSUiOcxSuoUUYuOUxKAC/PpFYFdQebt68Sb9+/fjf//4HQKNGjVi4cKGWSrADkfdSrwQMHNiQgQMbpl7RDuyRGU9ODjy5ByLYylAnxd69exk0aBBgZFILDg5OUhocDIHAH3/8kWvXrtGjRw/rdd9++23rNSxcvHjRRnL8woULzJgxg/3791OyZEn69u2bouS45dpJyZknpEaNGhw+fJjAwEBatmzJmjVr6Ny5M+7u7hw4cMAm/8bBgwepV68eYDjkhJLk9pKS5DjYyr137tyZt99+m+DgYGt74eHhdkmqFyxYkDt37ljLw4cP54033qBz585s27bNOtyVsE2TycTu3bsTyXUPHz48yd9QfEJDQ60Z5xKyYsUK6/2zULZsWQIDAylXrhyBgYE2Q0cJ+f333/Hx8aFs2bLWfRUrVuTZZ59FKUXjxo1xcnLi5s2buLq6ZqnkeI6LUcQnvauwixYtytmzZylWrBjz5s1jz5492knkcJKTA2/fvj0LFiywOpTg4OBE5zZp0oTt27dz8+ZNYmNj+e6772jRogVNmjSxSkp37tw5WWlwMCTHV65cyY8//kjXrl0BQ3L866+/tqb0vHLlCjdu3EjU/t27dylcuDDFixfn+vXr/P7774Ah6X3+/Hlrryl+ulZ75cwtlCtXjilTpljfVocNG8bixYutD+Nbt24xduxY66yat99+mzFjxnDt2jXAeKOfM2dOousmJeletmxZbty4wa1bt7h//771hSwpihQpQuPGjXnttdfo1KkTzs7Odkuqx5ccB9vfwJIlS5Jts3379sybN89attyDlCTlLVh6FEltCZ0EGI7QYsuSJUuSlBy3kJS0eJcuXdiyZQtgxGSioqKsMZmslBzPcY7ijkk4GhPD7TRKeO/cudOqw58/f35WrlzJyZMnGTZsmM5bnQtITg78lVdeoXLlylZJ8aR0lMqVK8fkyZNp1aoV3t7e+Pj4JPkfOjlpcDDewENDQ6lQoYJ1tX779u154YUXaNq0KZ6ennTt2pXQ0NBE1/X29qZBgwa4u7vTv39/a5a3ggULMn/+fDp27Mjjjz9O2bJlrZLj9sqZx6dLly5ERETw559/Uq5cOZYtW8aAAQNwc3OjWbNm9O/f35odzs/Pj2HDhtG2bVvc3d1p2LBhkkmikpJ0z5s3rzVHdqdOnVKV7+7evTvLli2zGZKyR1L9iSee4O+//7Y6y4kTJ/L888/TvHlz68M0KebMmcOBAwfw8vKiXr16LFiwAEhZUj69vPXWW2zcuJFatWqxceNG3nrrLQCuXr1qow0XERHBxo0befbZZ23O79+/P+fPn8fDw4MePXqwZMkSaw9569at+Pv7Z4idqZLe4IajNignMFFqF307ySBOQm7evCmvvPKKANZAmcZ+tMy4Y7FIjptMJhkyZIjMnDnTwRZlL0aMGCEbN250tBlZTmRkpDRp0iTZ6b4P/fRYC491TVlBUkRYsmQJbm5ufPnll+TNm5fy5cunOO6r0WQ3vvjiC+rXr4+7uzt37txJFO942Bk3bhwRERGONiPLCQgIYMqUKdZJGplNjgtmW/DwSD4odPLkSQYPHsz27dsBY+72559/nmEZrDSarGLkyJFJ5mvWGJQtW9YmIP+wUKtWLWrVqpVl7eU8R1EwCvLcw8urbJKHL1++jLe3tzXo88knn9CrVy895fUBkBRmDmk0muxFZoyaqJw2FKPqKOEziG1twskp6YfXK6+8gpOTE1OmTLGZN69JOxcuXKBo0aK4uLhoZ6HRZHNEhFu3bhEaGmqzjgRAKXVQRBql57o501HMB2lj2B0YGMjIkSMZPHiwdd6zyWTCySnHhl+yFdHR0Vy+fDnRXHiNRpM9KVCgABUrViRv3rw2+x/EUeS4oaeG5ytxoMcYYq/F8vnnn/POO+9w9+5dzp49y/79+1FKaSeRgeTNmzfRm4lGo3m4yNQnqlKqo1LqlFLqrFLqrSSOK6XUHPPxo0opu1a9HYr5j0cffZThw4dz9+5dnnrqKX766Sc9NKLRaDSZQKYNPSmlnIHTQDvgMrAf6Ckix+PV8QOGA35AE2C2iKQ477WsU1G5KeGYECpWrMjcuXN5+umntZPQaDSaFHiQoafM7FE0Bs6KyHkRiQJWAgmXuz4NLDWvB9kDlFBKpZiEOlgiUCjeeOMNTpw4QZcuXbST0Gg0mkwkM2MUFYD/4pUvY/QaUqtTAQiMX0kpNRAYaC7eB47NnDmTmTNnZqjBOZDSwE1HG5FN0PciDn0v4tD3Io6UFSRTIDMdRVKv+QnHueypg4gsAhYBKKUOpLf7lNvQ9yIOfS/i0PciDn0v4lBKHUjvuZk59HQZqBSvXBFIKJ5uTx2NRqPROJDMdBT7gVpKqWpKqXxAD2BNgjprgN7m2U+PAndEJDDhhTQajUbjODJt6ElEYpRSrwLrAWfgaxH5Vyk12Hx8AbAOY8bTWSAC6GfHpRdlksk5EX0v4tD3Ig59L+LQ9yKOdN+LHLcyW6PRaDRZi17CrNFoNJoU0Y5Co9FoNCmSbR1FZsl/5ETsuBcvmu/BUaXULqWUtyPszApSuxfx6vkqpWKVUl2z0r6sxJ57oZRqqZQ6rJT6Vym1PattzCrs+D9SXCm1Vil1xHwv7ImH5jiUUl8rpW4opY4lczx9z830psbLzA0j+H0OqA7kA44A9RLU8QN+x1iL8Siw19F2O/BeNANKmj8/+TDfi3j1tmBMlujqaLsd+LsoARwHKpvLZRxttwPvxThgqvmzKxAM5HO07ZlwL54AfIBjyRxP13Mzu/YoMkX+I4eS6r0QkV0iEmIu7sFYj5Ibsed3AYZ+2E/Ajaw0Loux5168APwsIgEAIpJb74c990KAosrQ+ymC4ShistbMzEdEdmB8t+RI13MzuzqK5KQ90lonN5DW7/kyxhtDbiTVe6GUqgA8AyzIQrscgT2/i9pASaXUNqXUQaVU7yyzLmux517MA+piLOj9B3hNRExZY162Il3PzeyajyLD5D9yAXZ/T6VUKwxH8XimWuQ47LkXnwJjRSQ2l4tF2nMv8gANgTZAQWC3UmqPiJzObOOyGHvuRQfgMNAaqAFsVEr9KSJ3M9m27Ea6npvZ1VFo+Y847PqeSikv4EvgSRG5lUW2ZTX23ItGwEqzkygN+CmlYkRkdZZYmHXY+3/kpoiEA+FKqR2AN4b8f27CnnvRD5gixkD9WaXUBcAN2Jc1JmYb0vXczK5DT1r+I45U74VSqjLwM9ArF74txifVeyEi1USkqohUBX4EhuZCJwH2/R/5FWiulMqjlCqEod58IovtzArsuRcBGD0rlFJlMZRUz2epldmDdD03s2WPQjJP/iPHYee9mAC4APPNb9IxkgsVM+28Fw8F9twLETmhlPoDOAqYgC9FJMlpkzkZO38XHwCLlVL/YAy/jBWRXCc/rpT6DmgJlFZKXQbeA/LCgz03tYSHRqPRaFIkuw49aTQajSaboB2FRqPRaFJEOwqNRqPRpIh2FBqNRqNJEe0oNBqNRpMi2lFosiVm5dfD8baqKdQNy4D2FiulLpjbOqSUapqOa3yplKpn/jwuwbFdD2qj+TqW+3LMrIZaIpX69ZVSfhnRtubhRU+P1WRLlFJhIlIko+umcI3FwP9E5EelVHtghoh4PcD1Htim1K6rlFoCnBaRj1Ko3xdoJCKvZrQtmocH3aPQ5AiUUkWUUpvNb/v/KKUSqcYqpcoppXbEe+Nubt7fXim123zuD0qp1B7gO4Ca5nPfMF/rmFLqdfO+wkqp38y5DY4ppbqb929TSjVSSk0BCprtWG4+Fmb+uyr+G765J/OcUspZKTVdKbVfGXkCBtlxW3ZjFnRTSjVWRi6Sv81/65hXKU8Cuptt6W62/WtzO38ndR81mkQ4Wj9db3pLagNiMUTcDgO/YKgIFDMfK42xstTSIw4z/x0FvGP+7AwUNdfdARQ27x8LTEiivcWYc1cAzwN7MQT1/gEKY0hT/ws0AJ4Dvoh3bnHz320Yb+9Wm+LVsdj4DLDE/DkfhpJnQWAg8K55f37gAFAtCTvD4n2/H4CO5nIxII/5c1vgJ/PnvsC8eOd/DLxk/lwCQ/epsKP/vfWWvbdsKeGh0QD3RKS+paCUygt8rJR6AkOOogJQFrgW75z9wNfmuqtF5LBSqgVQD9hpljfJh/EmnhTTlVLvAkEYKrxtgF/EENVDKfUz0Bz4A5ihlJqKMVz1Zxq+1+/AHKVUfqAjsENE7pmHu7xUXEa+4kAt4EKC8wsqpQ4DVYGDwMZ49ZcopWphqIHmTab99kBnpdRoc7kAUJncqQGlySC0o9DkFF7EyEzWUESilVIXMR5yVkRkh9mR+APfKqWmAyHARhHpaUcbb4rIj5aCUqptUpVE5LRSqiGGZs5kpdQGEZlkz5cQkUil1DYM2evuwHeW5oDhIrI+lUvcE5H6SqniwP+AYcAcDC2jrSLyjDnwvy2Z8xXwnIicssdejQZ0jEKTcygO3DA7iVZAlYQVlFJVzHW+AL7CSAm5B3hMKWWJORRSStW2s80dQBfzOYUxho3+VEqVByJEZBkww9xOQqLNPZukWIkhxtYcQ8gO898hlnOUUrXNbSaJiNwBRgCjzecUB66YD/eNVzUUYwjOwnpguDJ3r5RSDZJrQ6OxoB2FJqewHGiklDqA0bs4mUSdlsBhpdTfGHGE2SIShPHg/E4pdRTDcbjZ06CIHMKIXezDiFl8KSJ/A57APvMQ0DvAh0mcvgg4aglmJ2ADRm7jTWKk7gQjl8hx4JBS6hiwkFR6/GZbjmDIak/D6N3sxIhfWNgK1LMEszF6HnnNth0zlzWaFNHTYzUajUaTIrpHodFoNJoU0Y5Co9FoNCmiHYVGo9FoUkQ7Co1Go9GkiHYUGo1Go0kR7Sg0Go1GkyLaUWg0Go0mRf4PBDOvdN5Cq+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_probs = lr.predict_proba(X_test)\n",
    "skplt.metrics.plot_roc(y_test, lr_probs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e156aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426879\n",
      "         Iterations 7\n",
      "                             Results: Logit\n",
      "========================================================================\n",
      "Model:                Logit              Pseudo R-squared:   0.183      \n",
      "Dependent Variable:   quality            AIC:                4205.7106  \n",
      "Date:                 2021-12-12 19:54   BIC:                4283.6696  \n",
      "No. Observations:     4898               Log-Likelihood:     -2090.9    \n",
      "Df Model:             11                 LL-Null:            -2558.4    \n",
      "Df Residuals:         4886               LLR p-value:        1.7927e-193\n",
      "Converged:            1.0000             Scale:              1.0000     \n",
      "No. Iterations:       7.0000                                            \n",
      "------------------------------------------------------------------------\n",
      "                      Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
      "------------------------------------------------------------------------\n",
      "fixed acidity          0.8514   0.5616   1.5160 0.1295  -0.2493   1.9521\n",
      "volatile acidity      -3.8472   0.4829  -7.9672 0.0000  -4.7937  -2.9008\n",
      "citric acid           -0.8634   0.3972  -2.1737 0.0297  -1.6419  -0.0849\n",
      "residual sugar         0.6405   0.1002   6.3901 0.0000   0.4441   0.8370\n",
      "chlorides             -1.8031   0.3876  -4.6518 0.0000  -2.5628  -1.0434\n",
      "free sulfur dioxide   -1.6855   0.9681  -1.7410 0.0817  -3.5829   0.2120\n",
      "total sulfur dioxide   0.4499   0.2714   1.6577 0.0974  -0.0820   0.9818\n",
      "density              -15.5507   1.3827 -11.2469 0.0000 -18.2607 -12.8408\n",
      "pH                    13.3286   2.9724   4.4841 0.0000   7.5028  19.1544\n",
      "sulphates              1.3033   0.3212   4.0582 0.0000   0.6739   1.9328\n",
      "alcohol                8.5090   0.4403  19.3277 0.0000   7.6462   9.3719\n",
      "Sratio                 4.3201   1.3083   3.3019 0.0010   1.7558   6.8844\n",
      "========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(y_original, X_original)\n",
    "result1 = logit_model.fit()\n",
    "print(result1.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0342a3d",
   "metadata": {},
   "source": [
    "Άρα βλέπω οτι  fixed acidity  &  total sulfur dioxide δεν δινουν επεξηγηματική δυναμη στο μοντελο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d2bce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['volatile acidity', 'citric acid', 'chlorides','residual sugar',\n",
    "        'Sratio','density','pH','sulphates','alcohol']\n",
    "X_feat = data[cols]\n",
    "y_feat = data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e04c6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train, X_new_test, y_new_train, y_new_test = train_test_split(\n",
    "    X_feat, y_feat, test_size=0.2, random_state=42, shuffle=True, stratify=y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46dbb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "lr = lr.fit(X_new_train, y_new_train)\n",
    "\n",
    "y_true_new, y_pred_new = y_new_test, lr.predict(X_new_test)\n",
    "\n",
    "scores = cross_validate(lr, X_feat, y_feat, cv=10,\n",
    "                        scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "results = records.append(\n",
    "    {\n",
    "        'Methodology': 'Logistic Stratified with specfic variables',\n",
    "        'Score': format(lr.score(X_new_test, y_new_test),'.2f'),\n",
    "        'Precision 0':format(precision_recall_fscore_support(y_true_new, y_pred_new, average=None)[0][0],'.2f'),\n",
    "        'Precision 1':format(precision_recall_fscore_support(y_true_new, y_pred_new, average=None)[0][1],'.2f'),\n",
    "        'precision 1': format(precision_score(y_true, y_pred,  pos_label=1 , average='binary'),'.2f'),\n",
    "        #\n",
    "        'Recal 0':format(precision_recall_fscore_support(y_true_new, y_pred_new, average=None)[1][0],'.2f'),\n",
    "        'Recal 1':format(precision_recall_fscore_support(y_true_new, y_pred_new, average=None)[1][1],'.2f'),\n",
    "        'F1 0':format(precision_recall_fscore_support(y_true_new, y_pred_new, average=None)[2][0],'.2f'),\n",
    "        'F1 1':format(precision_recall_fscore_support(y_true_new, y_pred_new, average=None)[2][1],'.2f'),\n",
    "        'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "        'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "        'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f'),\n",
    "    },\n",
    "    ignore_index=True)\n",
    "#results = records2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b538c682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0                         Logistic Stratified  0.80  0.88  0.31        0.81   \n",
       "1  Logistic Stratified with specfic variables  0.80  0.88  0.31        0.81   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.59    0.96    0.21        0.59                   0.54   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \n",
       "0                   0.59         0.79  \n",
       "1                   0.59         0.79  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "#αφαιρόντας τις μεταβλητές δεν ΄άλλαξαν τα αποτελέσματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b8847e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_probs = lr.predict_proba(X_new_test)\n",
    "skplt.metrics.plot_roc(y_new_test, lr_probs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6870ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#άρα έχουμε δει οτι θελουμε ολες τις μεταβλητές(βγαζοντας 2 μεταβλητές δεν άλλαξε το πορισμα) . Προσοχη αρχικό split test & train\n",
    "#Στο ΄ίδιο μοντέλο (logistic) θα παίξουμε με pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9093832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "scalers=[MinMaxScaler(),StandardScaler(),RobustScaler(),\n",
    "        Normalizer(),QuantileTransformer(),PowerTransformer()]\n",
    "\n",
    "for scaler in scalers:\n",
    "    pipe = Pipeline([\n",
    "                     ('scaler', scaler), \n",
    "                     ('classifier', LogisticRegression())\n",
    "                     ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test , pipe.predict(X_test)\n",
    "    \n",
    "    scores = cross_validate(pipe, X_original, y_original, cv=10,\n",
    "                        scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "    results = results.append(\n",
    "        {\n",
    "            'Methodology': 'Logistic Str '+str(scaler).split('(')[0],\n",
    "            'Score': format(pipe.score(X_test, y_test),'.2f'),\n",
    "            'Precision 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][0],'.2f'),\n",
    "            'Precision 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][1],'.2f'),\n",
    "            'precision 1': format(precision_score(y_true, y_pred,  pos_label=1 , average='binary'),'.2f'),\n",
    "        #\n",
    "            'Recal 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][0],'.2f'),\n",
    "            'Recal 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][1],'.2f'),\n",
    "            'F1 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][0],'.2f'),\n",
    "            'F1 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][1],'.2f'),\n",
    "            'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "            'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "            'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f'),\n",
    "        },\n",
    "        ignore_index=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a42e1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0                         Logistic Stratified  0.80  0.88  0.31        0.81   \n",
       "1  Logistic Stratified with specfic variables  0.80  0.88  0.31        0.81   \n",
       "2                   Logistic Str MinMaxScaler  0.80  0.88  0.33        0.82   \n",
       "3                 Logistic Str StandardScaler  0.80  0.88  0.38        0.83   \n",
       "4                   Logistic Str RobustScaler  0.80  0.88  0.36        0.82   \n",
       "5                     Logistic Str Normalizer  0.79  0.88  0.15        0.80   \n",
       "6            Logistic Str QuantileTransformer  0.80  0.88  0.36        0.82   \n",
       "7               Logistic Str PowerTransformer  0.80  0.88  0.37        0.82   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.59    0.96    0.21        0.59                   0.54   \n",
       "2        0.58    0.95    0.23        0.58                   0.54   \n",
       "3        0.59    0.95    0.28        0.59                   0.54   \n",
       "4        0.58    0.95    0.26        0.58                   0.54   \n",
       "5        0.58    0.98    0.08        0.58                   0.52   \n",
       "6        0.57    0.94    0.26        0.57                   0.54   \n",
       "7        0.58    0.95    0.27        0.58                   0.54   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \n",
       "0                   0.59         0.79  \n",
       "1                   0.59         0.79  \n",
       "2                   0.60         0.79  \n",
       "3                   0.61         0.80  \n",
       "4                   0.61         0.80  \n",
       "5                   0.54         0.78  \n",
       "6                   0.61         0.80  \n",
       "7                   0.61         0.80  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01eb9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ίσως ο Standard scaler βελτιωνει την προβλεπτική ικανότητα - οχι ομως για το precision-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7232d094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'Sratio', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c07a6",
   "metadata": {},
   "source": [
    "επόμενο βήμα να παιξουμε με τους classifiers\n",
    "\n",
    "μετα με grid search στο επικρατεστερο classifier\n",
    "\n",
    "μετα dimentionality reduction (pca, svdm, t-sne, outlier detection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d14757bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol', 'Sratio']\n",
    "ss = StandardScaler()\n",
    "'''fit scaler on numeric features'''\n",
    "ss.fit(data[cols1])\n",
    "'''scale numeric features now'''\n",
    "X1 = ss.transform(data[cols1])\n",
    "y1=data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4379e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "par={ \n",
    "    0:{'classifier__C':[0.1, 0.5, 1.0, 2.0, 4.0],\n",
    "               'classifier__solver':['newton-cg', 'lbfgs'],\n",
    "        \"pca__n_components\": [5,7,9,10,11]},\n",
    "            1:{'classifier__n_estimators':[50,100,300],\n",
    "               'classifier__criterion':['gini','entropy'],\n",
    "              \"pca__n_components\": [5,7,9,10,11]},\n",
    "            2:{'classifier__C':[0.1, 0.5, 0.8, 1 , 1.4, 2.0, 4.0],\n",
    "               'classifier__kernel':['linear', 'rbf'],\n",
    "               'classifier__gamma' :[0.1,1,1.4],\n",
    "               \"pca__n_components\": [5,7,9,10,11]}}\n",
    "\n",
    "clas=[\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    RandomForestClassifier(n_estimators=5),\n",
    "    SVC(class_weight='balanced')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "839ee661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "197e2475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=2.0, max_iter=1000, solver='newton-cg'))])\n",
      "         0         1        2         3         4         5        6   \\\n",
      "0 -1.013043 -1.073988  0.21328 -0.925047 -0.172682 -1.253019 -1.82052   \n",
      "\n",
      "         7         8         9        10        11  \n",
      "0 -0.865169  0.210175  0.439499  0.23221 -0.277356  \n",
      "         0         1         2         3         4        5         6   \\\n",
      "0 -0.538987  0.315117 -0.613115  1.342508  0.010421  1.27559  1.568216   \n",
      "\n",
      "         7         8        9         10        11  \n",
      "0  1.161179 -0.120983 -0.69971 -0.743008  0.239087  \n",
      "Pipeline(steps=[('pca', PCA(n_components=11)),\n",
      "                ('classifier', RandomForestClassifier(criterion='entropy'))])\n",
      "         0         1        2         3         4         5        6   \\\n",
      "0 -1.013043 -1.073988  0.21328 -0.925047 -0.172682 -1.253019 -1.82052   \n",
      "\n",
      "         7         8         9        10        11  \n",
      "0 -0.865169  0.210175  0.439499  0.23221 -0.277356  \n",
      "         0         1         2         3         4        5         6   \\\n",
      "0 -0.538987  0.315117 -0.613115  1.342508  0.010421  1.27559  1.568216   \n",
      "\n",
      "         7         8        9         10        11  \n",
      "0  1.161179 -0.120983 -0.69971 -0.743008  0.239087  \n",
      "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
      "                ('classifier', SVC(C=4.0, class_weight='balanced', gamma=0.1))])\n",
      "         0         1        2         3         4         5        6   \\\n",
      "0 -1.013043 -1.073988  0.21328 -0.925047 -0.172682 -1.253019 -1.82052   \n",
      "\n",
      "         7         8         9        10        11  \n",
      "0 -0.865169  0.210175  0.439499  0.23221 -0.277356  \n",
      "         0         1         2         3         4        5         6   \\\n",
      "0 -0.538987  0.315117 -0.613115  1.342508  0.010421  1.27559  1.568216   \n",
      "\n",
      "         7         8        9         10        11  \n",
      "0  1.161179 -0.120983 -0.69971 -0.743008  0.239087  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Methodology Score  F1 0  F1 1 Precision 0 Precision 1  \\\n",
       "0      PCA GrindLogisticRegression  0.80  0.88  0.36        0.82        0.57   \n",
       "1  PCA GrindRandomForestClassifier  0.89  0.93  0.72        0.90        0.84   \n",
       "2                     PCA GrindSVC  0.77  0.84  0.61        0.94        0.48   \n",
       "\n",
       "  Recal 0 Recal 1                                        best params  \\\n",
       "0    0.95    0.26  {'classifier__C': 2.0, 'classifier__solver': '...   \n",
       "1    0.97    0.63  {'classifier__criterion': 'entropy', 'classifi...   \n",
       "2    0.75    0.84  {'classifier__C': 4.0, 'classifier__gamma': 0....   \n",
       "\n",
       "  precision 1 test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0        0.57                   0.54                   0.60         0.79  \n",
       "1        0.84                   0.58                   0.63         0.82  \n",
       "2        0.48                   0.52                   0.74         0.81  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_models(clas,par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f8d6f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 4.0, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf', 'pca__n_components': 10}\n"
     ]
    }
   ],
   "source": [
    "print(results3['best params'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66de1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= results.append(results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28a18a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0                         Logistic Stratified  0.80  0.88  0.31        0.81   \n",
       "1  Logistic Stratified with specfic variables  0.80  0.88  0.31        0.81   \n",
       "2                   Logistic Str MinMaxScaler  0.80  0.88  0.33        0.82   \n",
       "3                 Logistic Str StandardScaler  0.80  0.88  0.38        0.83   \n",
       "4                   Logistic Str RobustScaler  0.80  0.88  0.36        0.82   \n",
       "5                     Logistic Str Normalizer  0.79  0.88  0.15        0.80   \n",
       "6            Logistic Str QuantileTransformer  0.80  0.88  0.36        0.82   \n",
       "7               Logistic Str PowerTransformer  0.80  0.88  0.37        0.82   \n",
       "0                 PCA GrindLogisticRegression  0.80  0.88  0.36        0.82   \n",
       "1             PCA GrindRandomForestClassifier  0.89  0.93  0.72        0.90   \n",
       "2                                PCA GrindSVC  0.77  0.84  0.61        0.94   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.59    0.96    0.21        0.59                   0.54   \n",
       "2        0.58    0.95    0.23        0.58                   0.54   \n",
       "3        0.59    0.95    0.28        0.59                   0.54   \n",
       "4        0.58    0.95    0.26        0.58                   0.54   \n",
       "5        0.58    0.98    0.08        0.58                   0.52   \n",
       "6        0.57    0.94    0.26        0.57                   0.54   \n",
       "7        0.58    0.95    0.27        0.58                   0.54   \n",
       "0        0.57    0.95    0.26        0.57                   0.54   \n",
       "1        0.84    0.97    0.63        0.84                   0.58   \n",
       "2        0.48    0.75    0.84        0.48                   0.52   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \\\n",
       "0                   0.59         0.79   \n",
       "1                   0.59         0.79   \n",
       "2                   0.60         0.79   \n",
       "3                   0.61         0.80   \n",
       "4                   0.61         0.80   \n",
       "5                   0.54         0.78   \n",
       "6                   0.61         0.80   \n",
       "7                   0.61         0.80   \n",
       "0                   0.60         0.79   \n",
       "1                   0.63         0.82   \n",
       "2                   0.74         0.81   \n",
       "\n",
       "                                         best params  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'entropy', 'classifi...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670356e",
   "metadata": {},
   "source": [
    "#Μετα θα δοκιμάσω και χωρις PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41df7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "par1={ \n",
    "    0:{'classifier__C':[0.1, 0.5, 1.0, 2.0, 4.0],\n",
    "               'classifier__solver':['newton-cg', 'lbfgs']},\n",
    "            1:{'classifier__n_estimators':[50, 100, 300],\n",
    "               'classifier__criterion':['gini','entropy']},\n",
    "            2:{'classifier__C':[0.1, 0.5, 0.8, 1 , 1.4, 2.0, 4.0],\n",
    "               'classifier__kernel':['linear', 'rbf'],\n",
    "               'classifier__gamma' :[0.1,1,1.4],}}\n",
    "\n",
    "clas=[\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    RandomForestClassifier(n_estimators=5),\n",
    "    SVC(class_weight='balanced')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a735f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3f5e5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier',\n",
      "                 LogisticRegression(C=2.0, max_iter=1000, solver='newton-cg'))])\n",
      "Pipeline(steps=[('classifier', RandomForestClassifier(n_estimators=300))])\n",
      "Pipeline(steps=[('classifier', SVC(C=4.0, class_weight='balanced', gamma=0.1))])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindRandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Methodology Score  F1 0  F1 1 Precision 0 Precision 1  \\\n",
       "0      GrindLogisticRegression  0.80  0.88  0.39        0.83        0.60   \n",
       "1  GrindRandomForestClassifier  0.90  0.94  0.73        0.91        0.86   \n",
       "2                     GrindSVC  0.77  0.84  0.61        0.95        0.48   \n",
       "\n",
       "  Recal 0 Recal 1                                        best params  \\\n",
       "0    0.95    0.29  {'classifier__C': 2.0, 'classifier__solver': '...   \n",
       "1    0.97    0.64  {'classifier__criterion': 'gini', 'classifier_...   \n",
       "2    0.75    0.84  {'classifier__C': 4.0, 'classifier__gamma': 0....   \n",
       "\n",
       "  precision 1 test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0        0.60                   0.54                   0.61         0.80  \n",
       "1        0.86                   0.59                   0.64         0.83  \n",
       "2        0.48                   0.53                   0.74         0.81  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_no_dim(clas,par1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0f6ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b6a4079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindRandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0                         Logistic Stratified  0.80  0.88  0.31        0.81   \n",
       "1  Logistic Stratified with specfic variables  0.80  0.88  0.31        0.81   \n",
       "2                   Logistic Str MinMaxScaler  0.80  0.88  0.33        0.82   \n",
       "3                 Logistic Str StandardScaler  0.80  0.88  0.38        0.83   \n",
       "4                   Logistic Str RobustScaler  0.80  0.88  0.36        0.82   \n",
       "5                     Logistic Str Normalizer  0.79  0.88  0.15        0.80   \n",
       "6            Logistic Str QuantileTransformer  0.80  0.88  0.36        0.82   \n",
       "7               Logistic Str PowerTransformer  0.80  0.88  0.37        0.82   \n",
       "0                 PCA GrindLogisticRegression  0.80  0.88  0.36        0.82   \n",
       "1             PCA GrindRandomForestClassifier  0.89  0.93  0.72        0.90   \n",
       "2                                PCA GrindSVC  0.77  0.84  0.61        0.94   \n",
       "0                     GrindLogisticRegression  0.80  0.88  0.39        0.83   \n",
       "1                 GrindRandomForestClassifier  0.90  0.94  0.73        0.91   \n",
       "2                                    GrindSVC  0.77  0.84  0.61        0.95   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.59    0.96    0.21        0.59                   0.54   \n",
       "2        0.58    0.95    0.23        0.58                   0.54   \n",
       "3        0.59    0.95    0.28        0.59                   0.54   \n",
       "4        0.58    0.95    0.26        0.58                   0.54   \n",
       "5        0.58    0.98    0.08        0.58                   0.52   \n",
       "6        0.57    0.94    0.26        0.57                   0.54   \n",
       "7        0.58    0.95    0.27        0.58                   0.54   \n",
       "0        0.57    0.95    0.26        0.57                   0.54   \n",
       "1        0.84    0.97    0.63        0.84                   0.58   \n",
       "2        0.48    0.75    0.84        0.48                   0.52   \n",
       "0        0.60    0.95    0.29        0.60                   0.54   \n",
       "1        0.86    0.97    0.64        0.86                   0.59   \n",
       "2        0.48    0.75    0.84        0.48                   0.53   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \\\n",
       "0                   0.59         0.79   \n",
       "1                   0.59         0.79   \n",
       "2                   0.60         0.79   \n",
       "3                   0.61         0.80   \n",
       "4                   0.61         0.80   \n",
       "5                   0.54         0.78   \n",
       "6                   0.61         0.80   \n",
       "7                   0.61         0.80   \n",
       "0                   0.60         0.79   \n",
       "1                   0.63         0.82   \n",
       "2                   0.74         0.81   \n",
       "0                   0.61         0.80   \n",
       "1                   0.64         0.83   \n",
       "2                   0.74         0.81   \n",
       "\n",
       "                                         best params  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'entropy', 'classifi...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65638edc",
   "metadata": {},
   "source": [
    "#Μετα θα δοκιμάσω και με τους κατωθι classifier\n",
    "LGBMClassifier\n",
    "XGBClassifier\n",
    "GradientBoostingClassifier\n",
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb41cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "par2={ \n",
    "    0:{'classifier__boosting_type':['gbdt','dart','goss'],\n",
    "               'classifier__learning_rate':[0.1,0.5,1],\n",
    "        \"pca__n_components\": [5,7,9,10,11]},\n",
    "            1:{'classifier__booster':['gbtree','gblinear','dart'],\n",
    "        \"pca__n_components\": [5,7,9,10,11]},\n",
    "            2:{'classifier__loss':['deviance', 'exponential'],\n",
    "               'classifier__learning_rate':[0.1,0.5,1],\n",
    "        \"pca__n_components\": [5,7,9,10,11]},\n",
    "            3:{'classifier__learning_rate':[0.1,0.5,1],\n",
    "               'classifier__algorithm':['SAMME', 'SAMME.R'],\n",
    "        \"pca__n_components\": [5,7,9,10,11]}\n",
    "}\n",
    "\n",
    "clas2=[\n",
    "    LGBMClassifier(),\n",
    "    XGBClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63abc2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
      "                ('classifier', LGBMClassifier(learning_rate=0.5))])\n",
      "         0         1        2         3         4         5        6   \\\n",
      "0 -1.013043 -1.073988  0.21328 -0.925047 -0.172682 -1.253019 -1.82052   \n",
      "\n",
      "         7         8         9        10        11  \n",
      "0 -0.865169  0.210175  0.439499  0.23221 -0.277356  \n",
      "         0         1         2         3         4        5         6   \\\n",
      "0 -0.538987  0.315117 -0.613115  1.342508  0.010421  1.27559  1.568216   \n",
      "\n",
      "         7         8        9         10        11  \n",
      "0  1.161179 -0.120983 -0.69971 -0.743008  0.239087  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Pipeline(steps=[('pca', PCA(n_components=11)),\n",
      "                ('classifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, enable_categorical=False,\n",
      "                               gamma=0, gpu_id=-1, importance_type=None,\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=6, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "                               scale_pos_weight=1, subsample=1,\n",
      "                               tree_method='exact', validate_parameters=1,\n",
      "                               verbosity=None))])\n",
      "[22:37:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1        2         3         4         5        6   \\\n",
      "0 -1.013043 -1.073988  0.21328 -0.925047 -0.172682 -1.253019 -1.82052   \n",
      "\n",
      "         7         8         9        10        11  \n",
      "0 -0.865169  0.210175  0.439499  0.23221 -0.277356  \n",
      "         0         1         2         3         4        5         6   \\\n",
      "0 -0.538987  0.315117 -0.613115  1.342508  0.010421  1.27559  1.568216   \n",
      "\n",
      "         7         8        9         10        11  \n",
      "0  1.161179 -0.120983 -0.69971 -0.743008  0.239087  \n",
      "[22:37:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Pipeline(steps=[('pca', PCA(n_components=11)),\n",
      "                ('classifier', GradientBoostingClassifier(learning_rate=1))])\n",
      "         0         1        2         3         4         5        6   \\\n",
      "0 -1.013043 -1.073988  0.21328 -0.925047 -0.172682 -1.253019 -1.82052   \n",
      "\n",
      "         7         8         9        10        11  \n",
      "0 -0.865169  0.210175  0.439499  0.23221 -0.277356  \n",
      "         0         1         2         3         4        5         6   \\\n",
      "0 -0.538987  0.315117 -0.613115  1.342508  0.010421  1.27559  1.568216   \n",
      "\n",
      "         7         8        9         10        11  \n",
      "0  1.161179 -0.120983 -0.69971 -0.743008  0.239087  \n",
      "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
      "                ('classifier', AdaBoostClassifier(learning_rate=1))])\n",
      "         0         1        2         3         4         5        6   \\\n",
      "0 -1.013043 -1.073988  0.21328 -0.925047 -0.172682 -1.253019 -1.82052   \n",
      "\n",
      "         7         8         9        10        11  \n",
      "0 -0.865169  0.210175  0.439499  0.23221 -0.277356  \n",
      "         0         1         2         3         4        5         6   \\\n",
      "0 -0.538987  0.315117 -0.613115  1.342508  0.010421  1.27559  1.568216   \n",
      "\n",
      "         7         8        9         10        11  \n",
      "0  1.161179 -0.120983 -0.69971 -0.743008  0.239087  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindGradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA GrindAdaBoostClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0              PCA GrindLGBMClassifier  0.88  0.93  0.71        0.91   \n",
       "1               PCA GrindXGBClassifier  0.88  0.92  0.70        0.91   \n",
       "2  PCA GrindGradientBoostingClassifier  0.86  0.91  0.67        0.91   \n",
       "3          PCA GrindAdaBoostClassifier  0.80  0.88  0.43        0.84   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1  \\\n",
       "0        0.75    0.94    0.68   \n",
       "1        0.76    0.94    0.65   \n",
       "2        0.68    0.91    0.66   \n",
       "3        0.57    0.93    0.34   \n",
       "\n",
       "                                         best params precision 1  \\\n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...        0.75   \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...        0.76   \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...        0.68   \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...        0.57   \n",
       "\n",
       "  test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0                   0.54                   0.65         0.80  \n",
       "1                   0.53                   0.64         0.79  \n",
       "2                   0.44                   0.62         0.74  \n",
       "3                   0.50                   0.62         0.77  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_models(clas2,par2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cc1e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= results.append(results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e36e48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindRandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindGradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA GrindAdaBoostClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0                         Logistic Stratified  0.80  0.88  0.31        0.81   \n",
       "1  Logistic Stratified with specfic variables  0.80  0.88  0.31        0.81   \n",
       "2                   Logistic Str MinMaxScaler  0.80  0.88  0.33        0.82   \n",
       "3                 Logistic Str StandardScaler  0.80  0.88  0.38        0.83   \n",
       "4                   Logistic Str RobustScaler  0.80  0.88  0.36        0.82   \n",
       "5                     Logistic Str Normalizer  0.79  0.88  0.15        0.80   \n",
       "6            Logistic Str QuantileTransformer  0.80  0.88  0.36        0.82   \n",
       "7               Logistic Str PowerTransformer  0.80  0.88  0.37        0.82   \n",
       "0                 PCA GrindLogisticRegression  0.80  0.88  0.36        0.82   \n",
       "1             PCA GrindRandomForestClassifier  0.89  0.93  0.72        0.90   \n",
       "2                                PCA GrindSVC  0.77  0.84  0.61        0.94   \n",
       "0                     GrindLogisticRegression  0.80  0.88  0.39        0.83   \n",
       "1                 GrindRandomForestClassifier  0.90  0.94  0.73        0.91   \n",
       "2                                    GrindSVC  0.77  0.84  0.61        0.95   \n",
       "0                     PCA GrindLGBMClassifier  0.88  0.93  0.71        0.91   \n",
       "1                      PCA GrindXGBClassifier  0.88  0.92  0.70        0.91   \n",
       "2         PCA GrindGradientBoostingClassifier  0.86  0.91  0.67        0.91   \n",
       "3                 PCA GrindAdaBoostClassifier  0.80  0.88  0.43        0.84   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.59    0.96    0.21        0.59                   0.54   \n",
       "2        0.58    0.95    0.23        0.58                   0.54   \n",
       "3        0.59    0.95    0.28        0.59                   0.54   \n",
       "4        0.58    0.95    0.26        0.58                   0.54   \n",
       "5        0.58    0.98    0.08        0.58                   0.52   \n",
       "6        0.57    0.94    0.26        0.57                   0.54   \n",
       "7        0.58    0.95    0.27        0.58                   0.54   \n",
       "0        0.57    0.95    0.26        0.57                   0.54   \n",
       "1        0.84    0.97    0.63        0.84                   0.58   \n",
       "2        0.48    0.75    0.84        0.48                   0.52   \n",
       "0        0.60    0.95    0.29        0.60                   0.54   \n",
       "1        0.86    0.97    0.64        0.86                   0.59   \n",
       "2        0.48    0.75    0.84        0.48                   0.53   \n",
       "0        0.75    0.94    0.68        0.75                   0.54   \n",
       "1        0.76    0.94    0.65        0.76                   0.53   \n",
       "2        0.68    0.91    0.66        0.68                   0.44   \n",
       "3        0.57    0.93    0.34        0.57                   0.50   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \\\n",
       "0                   0.59         0.79   \n",
       "1                   0.59         0.79   \n",
       "2                   0.60         0.79   \n",
       "3                   0.61         0.80   \n",
       "4                   0.61         0.80   \n",
       "5                   0.54         0.78   \n",
       "6                   0.61         0.80   \n",
       "7                   0.61         0.80   \n",
       "0                   0.60         0.79   \n",
       "1                   0.63         0.82   \n",
       "2                   0.74         0.81   \n",
       "0                   0.61         0.80   \n",
       "1                   0.64         0.83   \n",
       "2                   0.74         0.81   \n",
       "0                   0.65         0.80   \n",
       "1                   0.64         0.79   \n",
       "2                   0.62         0.74   \n",
       "3                   0.62         0.77   \n",
       "\n",
       "                                         best params  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'entropy', 'classifi...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24f68ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "par3={ \n",
    "    0:{'classifier__boosting_type':['gbdt','dart','goss'],\n",
    "               'classifier__learning_rate':[0.1,0.5,1]},\n",
    "            1:{'classifier__booster':['gbtree','gblinear','dart']},\n",
    "            2:{'classifier__loss':['deviance', 'exponential'],\n",
    "               'classifier__learning_rate':[0.1,0.5,1]},\n",
    "            3:{'classifier__learning_rate':[0.1,0.5,1],\n",
    "               'classifier__algorithm':['SAMME', 'SAMME.R']}\n",
    "}\n",
    "\n",
    "clas3=[\n",
    "    LGBMClassifier(),\n",
    "    XGBClassifier(use_label_encoder=False),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "743ecaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier', LGBMClassifier(learning_rate=0.5))])\n",
      "[22:40:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:40:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:40:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:40:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Pipeline(steps=[('classifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, enable_categorical=False,\n",
      "                               gamma=0, gpu_id=-1, importance_type=None,\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=6, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "                               scale_pos_weight=1, subsample=1,\n",
      "                               tree_method='exact', use_label_encoder=False,\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "[22:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Pipeline(steps=[('classifier',\n",
      "                 GradientBoostingClassifier(learning_rate=1,\n",
      "                                            loss='exponential'))])\n",
      "Pipeline(steps=[('classifier', AdaBoostClassifier(learning_rate=1))])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Methodology Score  F1 0  F1 1 Precision 0 Precision 1  \\\n",
       "0              GrindLGBMClassifier  0.88  0.92  0.71        0.91        0.75   \n",
       "1               GrindXGBClassifier  0.88  0.92  0.68        0.90        0.76   \n",
       "2  GrindGradientBoostingClassifier  0.85  0.91  0.62        0.88        0.71   \n",
       "3          GrindAdaBoostClassifier  0.82  0.89  0.47        0.85        0.62   \n",
       "\n",
       "  Recal 0 Recal 1                                        best params  \\\n",
       "0    0.94    0.67  {'classifier__boosting_type': 'gbdt', 'classif...   \n",
       "1    0.95    0.61                  {'classifier__booster': 'gbtree'}   \n",
       "2    0.94    0.56  {'classifier__learning_rate': 1, 'classifier__...   \n",
       "3    0.94    0.38  {'classifier__algorithm': 'SAMME.R', 'classifi...   \n",
       "\n",
       "  precision 1 test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0        0.75                   0.56                   0.66         0.81  \n",
       "1        0.76                   0.54                   0.65         0.81  \n",
       "2        0.71                   0.51                   0.65         0.79  \n",
       "3        0.62                   0.51                   0.64         0.80  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_no_dim(clas3,par3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d5fcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= results.append(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1faa6be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindRandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindGradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA GrindAdaBoostClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0                         Logistic Stratified  0.80  0.88  0.31        0.81   \n",
       "1  Logistic Stratified with specfic variables  0.80  0.88  0.31        0.81   \n",
       "2                   Logistic Str MinMaxScaler  0.80  0.88  0.33        0.82   \n",
       "3                 Logistic Str StandardScaler  0.80  0.88  0.38        0.83   \n",
       "4                   Logistic Str RobustScaler  0.80  0.88  0.36        0.82   \n",
       "5                     Logistic Str Normalizer  0.79  0.88  0.15        0.80   \n",
       "6            Logistic Str QuantileTransformer  0.80  0.88  0.36        0.82   \n",
       "7               Logistic Str PowerTransformer  0.80  0.88  0.37        0.82   \n",
       "0                 PCA GrindLogisticRegression  0.80  0.88  0.36        0.82   \n",
       "1             PCA GrindRandomForestClassifier  0.89  0.93  0.72        0.90   \n",
       "2                                PCA GrindSVC  0.77  0.84  0.61        0.94   \n",
       "0                     GrindLogisticRegression  0.80  0.88  0.39        0.83   \n",
       "1                 GrindRandomForestClassifier  0.90  0.94  0.73        0.91   \n",
       "2                                    GrindSVC  0.77  0.84  0.61        0.95   \n",
       "0                     PCA GrindLGBMClassifier  0.88  0.93  0.71        0.91   \n",
       "1                      PCA GrindXGBClassifier  0.88  0.92  0.70        0.91   \n",
       "2         PCA GrindGradientBoostingClassifier  0.86  0.91  0.67        0.91   \n",
       "3                 PCA GrindAdaBoostClassifier  0.80  0.88  0.43        0.84   \n",
       "0                         GrindLGBMClassifier  0.88  0.92  0.71        0.91   \n",
       "1                          GrindXGBClassifier  0.88  0.92  0.68        0.90   \n",
       "2             GrindGradientBoostingClassifier  0.85  0.91  0.62        0.88   \n",
       "3                     GrindAdaBoostClassifier  0.82  0.89  0.47        0.85   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.59    0.96    0.21        0.59                   0.54   \n",
       "2        0.58    0.95    0.23        0.58                   0.54   \n",
       "3        0.59    0.95    0.28        0.59                   0.54   \n",
       "4        0.58    0.95    0.26        0.58                   0.54   \n",
       "5        0.58    0.98    0.08        0.58                   0.52   \n",
       "6        0.57    0.94    0.26        0.57                   0.54   \n",
       "7        0.58    0.95    0.27        0.58                   0.54   \n",
       "0        0.57    0.95    0.26        0.57                   0.54   \n",
       "1        0.84    0.97    0.63        0.84                   0.58   \n",
       "2        0.48    0.75    0.84        0.48                   0.52   \n",
       "0        0.60    0.95    0.29        0.60                   0.54   \n",
       "1        0.86    0.97    0.64        0.86                   0.59   \n",
       "2        0.48    0.75    0.84        0.48                   0.53   \n",
       "0        0.75    0.94    0.68        0.75                   0.54   \n",
       "1        0.76    0.94    0.65        0.76                   0.53   \n",
       "2        0.68    0.91    0.66        0.68                   0.44   \n",
       "3        0.57    0.93    0.34        0.57                   0.50   \n",
       "0        0.75    0.94    0.67        0.75                   0.56   \n",
       "1        0.76    0.95    0.61        0.76                   0.54   \n",
       "2        0.71    0.94    0.56        0.71                   0.51   \n",
       "3        0.62    0.94    0.38        0.62                   0.51   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \\\n",
       "0                   0.59         0.79   \n",
       "1                   0.59         0.79   \n",
       "2                   0.60         0.79   \n",
       "3                   0.61         0.80   \n",
       "4                   0.61         0.80   \n",
       "5                   0.54         0.78   \n",
       "6                   0.61         0.80   \n",
       "7                   0.61         0.80   \n",
       "0                   0.60         0.79   \n",
       "1                   0.63         0.82   \n",
       "2                   0.74         0.81   \n",
       "0                   0.61         0.80   \n",
       "1                   0.64         0.83   \n",
       "2                   0.74         0.81   \n",
       "0                   0.65         0.80   \n",
       "1                   0.64         0.79   \n",
       "2                   0.62         0.74   \n",
       "3                   0.62         0.77   \n",
       "0                   0.66         0.81   \n",
       "1                   0.65         0.81   \n",
       "2                   0.65         0.79   \n",
       "3                   0.64         0.80   \n",
       "\n",
       "                                         best params  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'entropy', 'classifi...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "1                  {'classifier__booster': 'gbtree'}  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop_duplicates(subset=['Methodology'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fae74e",
   "metadata": {},
   "source": [
    "#outliers εππιρεάζουν το αποτέλεσμα\n",
    "\n",
    "#Upskalling (smote)\n",
    "\n",
    "#Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d507442",
   "metadata": {},
   "source": [
    "-----------Local Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a94bad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55e16b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'Sratio', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d04301a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol', 'Sratio']\n",
    "ss = StandardScaler()\n",
    "'''fit scaler on numeric features'''\n",
    "ss.fit(data[cols])\n",
    "'''scale numeric features now'''\n",
    "X_Standard= ss.transform(data[cols])\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=6)\n",
    "data['anomaly_label']=lof.fit_predict(X_Standard)\n",
    "data['original']=quality_complete\n",
    "#plot για να δω αν τα outlier έχουν καποια χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97484d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_out=pd.DataFrame(data.groupby(['original','anomaly_label'])['quality'].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71038917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f5122e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "original=%{x}<br>quality=%{y}<br>anomaly_label=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           -1,
           1,
           -1,
           1,
           -1,
           1,
           -1,
           1,
           -1,
           1,
           -1,
           1,
           1
          ],
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          3,
          3,
          4,
          4,
          5,
          5,
          6,
          6,
          7,
          7,
          8,
          8,
          9
         ],
         "xaxis": "x",
         "y": [
          4,
          16,
          6,
          157,
          58,
          1399,
          83,
          2115,
          17,
          863,
          6,
          169,
          5
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "anomaly_label"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "original"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "quality"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"51604634-6d73-44b0-b0ba-c4d39a6ea2af\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"51604634-6d73-44b0-b0ba-c4d39a6ea2af\")) {                    Plotly.newPlot(                        \"51604634-6d73-44b0-b0ba-c4d39a6ea2af\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"original=%{x}<br>quality=%{y}<br>anomaly_label=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,1],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"type\":\"bar\",\"x\":[3,3,4,4,5,5,6,6,7,7,8,8,9],\"xaxis\":\"x\",\"y\":[4,16,6,157,58,1399,83,2115,17,863,6,169,5],\"yaxis\":\"y\"}],                        {\"barmode\":\"relative\",\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"anomaly_label\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"original\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"quality\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('51604634-6d73-44b0-b0ba-c4d39a6ea2af');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.bar(check_out, x=check_out[\"original\"], y=\"quality\", color=\"anomaly_label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "216ffe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Πο΄'υ βαρύ-> θα χρησιμοποιησω sns\n",
    "#total_cols=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "#       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "#       'pH', 'sulphates', 'alcohol', 'Sratio']\n",
    "#for i in total_cols:\n",
    "#    fig = px.violin(data,x='original',y=i, color=\"anomaly_label\", box=True, points=\"all\", hover_data=data.columns)\n",
    "#    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d10f32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "#'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "#'pH', 'sulphates', 'alcohol', 'Sratio'\n",
    "def cont_out(column_nam):\n",
    "    ax = sns.violinplot(x='original',y=column_nam,data=data, hue=\"anomaly_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5fd5e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cont_out('density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ebae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_out(column_nam):\n",
    "    ax = sns.violinplot(x='original',y=column_nam,data=data, hue=\"anomaly_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9624698",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_out('chlorides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9badf115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a884dc",
   "metadata": {},
   "source": [
    "#Δεν παρατηρω ενιαιο pattern πχ να εξαιρεί τα χαρακτηριστικά που το κανουν πολύ κακό κρασί, άρα συνεχίζω με την αφαίρεση outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "114fdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['anomaly_label'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db2ac5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>Sratio</th>\n",
       "      <th>quality</th>\n",
       "      <th>anomaly_label</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           0.70              0.27         0.36            2.07       0.45   \n",
       "1           0.63              0.30         0.34            0.16       0.49   \n",
       "2           0.81              0.28         0.40            0.69       0.50   \n",
       "3           0.72              0.23         0.32            0.85       0.58   \n",
       "4           0.72              0.23         0.32            0.85       0.58   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
       "0                 0.45                  1.70   1.0010  0.300       0.45   \n",
       "1                 0.14                  1.32   0.9940  0.330       0.49   \n",
       "2                 0.30                  0.97   0.9951  0.326       0.44   \n",
       "3                 0.47                  1.86   0.9956  0.319       0.40   \n",
       "4                 0.47                  1.86   0.9956  0.319       0.40   \n",
       "\n",
       "   alcohol    Sratio  quality  anomaly_label  original  \n",
       "0     0.88  0.264706        0              1         6  \n",
       "1     0.95  0.106061        0              1         6  \n",
       "2     1.01  0.309278        0              1         6  \n",
       "3     0.99  0.252688        0              1         6  \n",
       "4     0.99  0.252688        0              1         6  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9608fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_locOut = data2.iloc[:,:-3]\n",
    "y_locOut= data2.iloc[:,-3]\n",
    "\n",
    "ss = StandardScaler()\n",
    "'''fit scaler on numeric features'''\n",
    "ss.fit(X_locOut)\n",
    "'''scale numeric features now'''\n",
    "X1= ss.transform(X_locOut)\n",
    "y1=data2.iloc[:,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a38e800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "271b839e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLogisticR...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__solver': '...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerRandomFor...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.56</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerSVC</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Methodology Score  F1 0  F1 1  \\\n",
       "0  PCA Grind LocalOutlier StandardScalerLogisticR...  0.79  0.88  0.35   \n",
       "1  PCA Grind LocalOutlier StandardScalerRandomFor...  0.88  0.92  0.66   \n",
       "2           PCA Grind LocalOutlier StandardScalerSVC  0.78  0.84  0.62   \n",
       "\n",
       "  Precision 0 Precision 1 Recal 0 Recal 1  \\\n",
       "0        0.82        0.55    0.94    0.26   \n",
       "1        0.89        0.82    0.96    0.56   \n",
       "2        0.94        0.49    0.76    0.83   \n",
       "\n",
       "                                         best params precision 1  \\\n",
       "0  {'classifier__C': 1.0, 'classifier__solver': '...        0.55   \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...        0.82   \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....        0.49   \n",
       "\n",
       "  test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0                   0.55                   0.61         0.79  \n",
       "1                   0.58                   0.62         0.81  \n",
       "2                   0.52                   0.74         0.81  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_models_method(clas,par,' LocalOutlier StandardScaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3ec9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= results.append(results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aaeb5f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:56:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c.logaras\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLGBMClass...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.62</td>\n",
       "      <td>{'classifier__boosting_type': 'goss', 'classif...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerXGBClassi...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.60</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerGradientB...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.58</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerAdaBoostC...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.36</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Methodology Score  F1 0  F1 1  \\\n",
       "0  PCA Grind LocalOutlier StandardScalerLGBMClass...  0.87  0.92  0.67   \n",
       "1  PCA Grind LocalOutlier StandardScalerXGBClassi...  0.86  0.91  0.66   \n",
       "2  PCA Grind LocalOutlier StandardScalerGradientB...  0.84  0.90  0.61   \n",
       "3  PCA Grind LocalOutlier StandardScalerAdaBoostC...  0.78  0.86  0.41   \n",
       "\n",
       "  Precision 0 Precision 1 Recal 0 Recal 1  \\\n",
       "0        0.90        0.74    0.94    0.62   \n",
       "1        0.89        0.73    0.94    0.60   \n",
       "2        0.89        0.64    0.91    0.58   \n",
       "3        0.83        0.48    0.89    0.36   \n",
       "\n",
       "                                         best params precision 1  \\\n",
       "0  {'classifier__boosting_type': 'goss', 'classif...        0.74   \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...        0.73   \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...        0.64   \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...        0.48   \n",
       "\n",
       "  test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0                   0.57                   0.65         0.81  \n",
       "1                   0.54                   0.63         0.80  \n",
       "2                   0.45                   0.64         0.75  \n",
       "3                   0.50                   0.63         0.76  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_models_method(clas2,par2,' LocalOutlier StandardScaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fba2c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= results.append(results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbd975c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindRandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindGradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA GrindAdaBoostClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLogisticR...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerRandomFor...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerSVC</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLGBMClass...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'goss', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerXGBClassi...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerGradientB...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerAdaBoostC...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Methodology Score  F1 0  F1 1  \\\n",
       "0                                Logistic Stratified  0.80  0.88  0.31   \n",
       "1         Logistic Stratified with specfic variables  0.80  0.88  0.31   \n",
       "2                          Logistic Str MinMaxScaler  0.80  0.88  0.33   \n",
       "3                        Logistic Str StandardScaler  0.80  0.88  0.38   \n",
       "4                          Logistic Str RobustScaler  0.80  0.88  0.36   \n",
       "5                            Logistic Str Normalizer  0.79  0.88  0.15   \n",
       "6                   Logistic Str QuantileTransformer  0.80  0.88  0.36   \n",
       "7                      Logistic Str PowerTransformer  0.80  0.88  0.37   \n",
       "0                        PCA GrindLogisticRegression  0.80  0.88  0.36   \n",
       "1                    PCA GrindRandomForestClassifier  0.89  0.93  0.72   \n",
       "2                                       PCA GrindSVC  0.77  0.84  0.61   \n",
       "0                            GrindLogisticRegression  0.80  0.88  0.39   \n",
       "1                        GrindRandomForestClassifier  0.90  0.94  0.73   \n",
       "2                                           GrindSVC  0.77  0.84  0.61   \n",
       "0                            PCA GrindLGBMClassifier  0.88  0.93  0.71   \n",
       "1                             PCA GrindXGBClassifier  0.88  0.92  0.70   \n",
       "2                PCA GrindGradientBoostingClassifier  0.86  0.91  0.67   \n",
       "3                        PCA GrindAdaBoostClassifier  0.80  0.88  0.43   \n",
       "0                                GrindLGBMClassifier  0.88  0.92  0.71   \n",
       "1                                 GrindXGBClassifier  0.88  0.92  0.68   \n",
       "2                    GrindGradientBoostingClassifier  0.85  0.91  0.62   \n",
       "3                            GrindAdaBoostClassifier  0.82  0.89  0.47   \n",
       "0  PCA Grind LocalOutlier StandardScalerLogisticR...  0.79  0.88  0.35   \n",
       "1  PCA Grind LocalOutlier StandardScalerRandomFor...  0.88  0.92  0.66   \n",
       "2           PCA Grind LocalOutlier StandardScalerSVC  0.78  0.84  0.62   \n",
       "0  PCA Grind LocalOutlier StandardScalerLGBMClass...  0.87  0.92  0.67   \n",
       "1  PCA Grind LocalOutlier StandardScalerXGBClassi...  0.86  0.91  0.66   \n",
       "2  PCA Grind LocalOutlier StandardScalerGradientB...  0.84  0.90  0.61   \n",
       "3  PCA Grind LocalOutlier StandardScalerAdaBoostC...  0.78  0.86  0.41   \n",
       "\n",
       "  Precision 0 Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.81        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.81        0.59    0.96    0.21        0.59                   0.54   \n",
       "2        0.82        0.58    0.95    0.23        0.58                   0.54   \n",
       "3        0.83        0.59    0.95    0.28        0.59                   0.54   \n",
       "4        0.82        0.58    0.95    0.26        0.58                   0.54   \n",
       "5        0.80        0.58    0.98    0.08        0.58                   0.52   \n",
       "6        0.82        0.57    0.94    0.26        0.57                   0.54   \n",
       "7        0.82        0.58    0.95    0.27        0.58                   0.54   \n",
       "0        0.82        0.57    0.95    0.26        0.57                   0.54   \n",
       "1        0.90        0.84    0.97    0.63        0.84                   0.58   \n",
       "2        0.94        0.48    0.75    0.84        0.48                   0.52   \n",
       "0        0.83        0.60    0.95    0.29        0.60                   0.54   \n",
       "1        0.91        0.86    0.97    0.64        0.86                   0.59   \n",
       "2        0.95        0.48    0.75    0.84        0.48                   0.53   \n",
       "0        0.91        0.75    0.94    0.68        0.75                   0.54   \n",
       "1        0.91        0.76    0.94    0.65        0.76                   0.53   \n",
       "2        0.91        0.68    0.91    0.66        0.68                   0.44   \n",
       "3        0.84        0.57    0.93    0.34        0.57                   0.50   \n",
       "0        0.91        0.75    0.94    0.67        0.75                   0.56   \n",
       "1        0.90        0.76    0.95    0.61        0.76                   0.54   \n",
       "2        0.88        0.71    0.94    0.56        0.71                   0.51   \n",
       "3        0.85        0.62    0.94    0.38        0.62                   0.51   \n",
       "0        0.82        0.55    0.94    0.26        0.55                   0.55   \n",
       "1        0.89        0.82    0.96    0.56        0.82                   0.58   \n",
       "2        0.94        0.49    0.76    0.83        0.49                   0.52   \n",
       "0        0.90        0.74    0.94    0.62        0.74                   0.57   \n",
       "1        0.89        0.73    0.94    0.60        0.73                   0.54   \n",
       "2        0.89        0.64    0.91    0.58        0.64                   0.45   \n",
       "3        0.83        0.48    0.89    0.36        0.48                   0.50   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \\\n",
       "0                   0.59         0.79   \n",
       "1                   0.59         0.79   \n",
       "2                   0.60         0.79   \n",
       "3                   0.61         0.80   \n",
       "4                   0.61         0.80   \n",
       "5                   0.54         0.78   \n",
       "6                   0.61         0.80   \n",
       "7                   0.61         0.80   \n",
       "0                   0.60         0.79   \n",
       "1                   0.63         0.82   \n",
       "2                   0.74         0.81   \n",
       "0                   0.61         0.80   \n",
       "1                   0.64         0.83   \n",
       "2                   0.74         0.81   \n",
       "0                   0.65         0.80   \n",
       "1                   0.64         0.79   \n",
       "2                   0.62         0.74   \n",
       "3                   0.62         0.77   \n",
       "0                   0.66         0.81   \n",
       "1                   0.65         0.81   \n",
       "2                   0.65         0.79   \n",
       "3                   0.64         0.80   \n",
       "0                   0.61         0.79   \n",
       "1                   0.62         0.81   \n",
       "2                   0.74         0.81   \n",
       "0                   0.65         0.81   \n",
       "1                   0.63         0.80   \n",
       "2                   0.64         0.75   \n",
       "3                   0.63         0.76   \n",
       "\n",
       "                                         best params  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'entropy', 'classifi...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "1                  {'classifier__booster': 'gbtree'}  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "0  {'classifier__C': 1.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__boosting_type': 'goss', 'classif...  \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop_duplicates(subset=['Methodology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "be018b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abb8eb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier',\n",
      "                 LogisticRegression(C=4.0, max_iter=1000, solver='newton-cg'))])\n",
      "Pipeline(steps=[('classifier',\n",
      "                 RandomForestClassifier(criterion='entropy',\n",
      "                                        n_estimators=300))])\n",
      "Pipeline(steps=[('classifier', SVC(C=4.0, class_weight='balanced', gamma=0.1))])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grind LocalOutlier StandardSVC</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Methodology Score  F1 0  F1 1 Precision 0 Precision 1  \\\n",
       "0              GrindLGBMClassifier  0.88  0.92  0.71        0.91        0.75   \n",
       "1               GrindXGBClassifier  0.88  0.92  0.68        0.90        0.76   \n",
       "2  GrindGradientBoostingClassifier  0.85  0.91  0.62        0.88        0.71   \n",
       "3          GrindAdaBoostClassifier  0.82  0.89  0.47        0.85        0.62   \n",
       "4   Grind LocalOutlier StandardSVC  0.78  0.84  0.62        0.94        0.50   \n",
       "\n",
       "  Recal 0 Recal 1                                        best params  \\\n",
       "0    0.94    0.67  {'classifier__boosting_type': 'gbdt', 'classif...   \n",
       "1    0.95    0.61                  {'classifier__booster': 'gbtree'}   \n",
       "2    0.94    0.56  {'classifier__learning_rate': 1, 'classifier__...   \n",
       "3    0.94    0.38  {'classifier__algorithm': 'SAMME.R', 'classifi...   \n",
       "4    0.77    0.81  {'classifier__C': 4.0, 'classifier__gamma': 0....   \n",
       "\n",
       "  precision 1 test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0        0.75                   0.56                   0.66         0.81  \n",
       "1        0.76                   0.54                   0.65         0.81  \n",
       "2        0.71                   0.51                   0.65         0.79  \n",
       "3        0.62                   0.51                   0.64         0.80  \n",
       "4        0.50                   0.53                   0.75         0.81  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_no_dim_method(clas,par1,' LocalOutlier Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "460cd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(results6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3acea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier', LGBMClassifier(learning_rate=1))])\n",
      "[23:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"interaction_constraints\", \"max_delta_step\", \"max_depth\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:03:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:03:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Pipeline(steps=[('classifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, enable_categorical=False,\n",
      "                               gamma=0, gpu_id=-1, importance_type=None,\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=6, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=100,\n",
      "                               n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "                               scale_pos_weight=1, subsample=1,\n",
      "                               tree_method='exact', use_label_encoder=False,\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "[23:03:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:03:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Pipeline(steps=[('classifier', GradientBoostingClassifier(learning_rate=1))])\n",
      "Pipeline(steps=[('classifier', AdaBoostClassifier(learning_rate=1))])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>best params</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grind LocalOutlier StandardAdaBoostClassifier</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.42</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Methodology Score  F1 0  F1 1  \\\n",
       "0                            GrindLGBMClassifier  0.88  0.92  0.71   \n",
       "1                             GrindXGBClassifier  0.88  0.92  0.68   \n",
       "2                GrindGradientBoostingClassifier  0.85  0.91  0.62   \n",
       "3                        GrindAdaBoostClassifier  0.82  0.89  0.47   \n",
       "4  Grind LocalOutlier StandardAdaBoostClassifier  0.81  0.88  0.49   \n",
       "\n",
       "  Precision 0 Precision 1 Recal 0 Recal 1  \\\n",
       "0        0.91        0.75    0.94    0.67   \n",
       "1        0.90        0.76    0.95    0.61   \n",
       "2        0.88        0.71    0.94    0.56   \n",
       "3        0.85        0.62    0.94    0.38   \n",
       "4        0.85        0.60    0.92    0.42   \n",
       "\n",
       "                                         best params precision 1  \\\n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...        0.75   \n",
       "1                  {'classifier__booster': 'gbtree'}        0.76   \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...        0.71   \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...        0.62   \n",
       "4  {'classifier__algorithm': 'SAMME.R', 'classifi...        0.60   \n",
       "\n",
       "  test_average_precision test_balanced_accuracy test_roc_auc  \n",
       "0                   0.56                   0.66         0.81  \n",
       "1                   0.54                   0.65         0.81  \n",
       "2                   0.51                   0.65         0.79  \n",
       "3                   0.51                   0.64         0.80  \n",
       "4                   0.51                   0.64         0.79  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_no_dim_method(clas3,par3,' LocalOutlier Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "706aa19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(results6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0a59e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindRandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA GrindGradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA GrindAdaBoostClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLogisticR...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerRandomFor...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerSVC</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLGBMClass...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'goss', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerXGBClassi...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerGradientB...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerAdaBoostC...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grind LocalOutlier StandardSVC</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grind LocalOutlier StandardAdaBoostClassifier</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Methodology Score  F1 0  F1 1  \\\n",
       "0                                Logistic Stratified  0.80  0.88  0.31   \n",
       "1         Logistic Stratified with specfic variables  0.80  0.88  0.31   \n",
       "2                          Logistic Str MinMaxScaler  0.80  0.88  0.33   \n",
       "3                        Logistic Str StandardScaler  0.80  0.88  0.38   \n",
       "4                          Logistic Str RobustScaler  0.80  0.88  0.36   \n",
       "5                            Logistic Str Normalizer  0.79  0.88  0.15   \n",
       "6                   Logistic Str QuantileTransformer  0.80  0.88  0.36   \n",
       "7                      Logistic Str PowerTransformer  0.80  0.88  0.37   \n",
       "0                        PCA GrindLogisticRegression  0.80  0.88  0.36   \n",
       "1                    PCA GrindRandomForestClassifier  0.89  0.93  0.72   \n",
       "2                                       PCA GrindSVC  0.77  0.84  0.61   \n",
       "0                            GrindLogisticRegression  0.80  0.88  0.39   \n",
       "1                        GrindRandomForestClassifier  0.90  0.94  0.73   \n",
       "2                                           GrindSVC  0.77  0.84  0.61   \n",
       "0                            PCA GrindLGBMClassifier  0.88  0.93  0.71   \n",
       "1                             PCA GrindXGBClassifier  0.88  0.92  0.70   \n",
       "2                PCA GrindGradientBoostingClassifier  0.86  0.91  0.67   \n",
       "3                        PCA GrindAdaBoostClassifier  0.80  0.88  0.43   \n",
       "0                                GrindLGBMClassifier  0.88  0.92  0.71   \n",
       "1                                 GrindXGBClassifier  0.88  0.92  0.68   \n",
       "2                    GrindGradientBoostingClassifier  0.85  0.91  0.62   \n",
       "3                            GrindAdaBoostClassifier  0.82  0.89  0.47   \n",
       "0  PCA Grind LocalOutlier StandardScalerLogisticR...  0.79  0.88  0.35   \n",
       "1  PCA Grind LocalOutlier StandardScalerRandomFor...  0.88  0.92  0.66   \n",
       "2           PCA Grind LocalOutlier StandardScalerSVC  0.78  0.84  0.62   \n",
       "0  PCA Grind LocalOutlier StandardScalerLGBMClass...  0.87  0.92  0.67   \n",
       "1  PCA Grind LocalOutlier StandardScalerXGBClassi...  0.86  0.91  0.66   \n",
       "2  PCA Grind LocalOutlier StandardScalerGradientB...  0.84  0.90  0.61   \n",
       "3  PCA Grind LocalOutlier StandardScalerAdaBoostC...  0.78  0.86  0.41   \n",
       "4                     Grind LocalOutlier StandardSVC  0.78  0.84  0.62   \n",
       "4      Grind LocalOutlier StandardAdaBoostClassifier  0.81  0.88  0.49   \n",
       "\n",
       "  Precision 0 Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.81        0.59    0.96    0.21        0.59                   0.54   \n",
       "1        0.81        0.59    0.96    0.21        0.59                   0.54   \n",
       "2        0.82        0.58    0.95    0.23        0.58                   0.54   \n",
       "3        0.83        0.59    0.95    0.28        0.59                   0.54   \n",
       "4        0.82        0.58    0.95    0.26        0.58                   0.54   \n",
       "5        0.80        0.58    0.98    0.08        0.58                   0.52   \n",
       "6        0.82        0.57    0.94    0.26        0.57                   0.54   \n",
       "7        0.82        0.58    0.95    0.27        0.58                   0.54   \n",
       "0        0.82        0.57    0.95    0.26        0.57                   0.54   \n",
       "1        0.90        0.84    0.97    0.63        0.84                   0.58   \n",
       "2        0.94        0.48    0.75    0.84        0.48                   0.52   \n",
       "0        0.83        0.60    0.95    0.29        0.60                   0.54   \n",
       "1        0.91        0.86    0.97    0.64        0.86                   0.59   \n",
       "2        0.95        0.48    0.75    0.84        0.48                   0.53   \n",
       "0        0.91        0.75    0.94    0.68        0.75                   0.54   \n",
       "1        0.91        0.76    0.94    0.65        0.76                   0.53   \n",
       "2        0.91        0.68    0.91    0.66        0.68                   0.44   \n",
       "3        0.84        0.57    0.93    0.34        0.57                   0.50   \n",
       "0        0.91        0.75    0.94    0.67        0.75                   0.56   \n",
       "1        0.90        0.76    0.95    0.61        0.76                   0.54   \n",
       "2        0.88        0.71    0.94    0.56        0.71                   0.51   \n",
       "3        0.85        0.62    0.94    0.38        0.62                   0.51   \n",
       "0        0.82        0.55    0.94    0.26        0.55                   0.55   \n",
       "1        0.89        0.82    0.96    0.56        0.82                   0.58   \n",
       "2        0.94        0.49    0.76    0.83        0.49                   0.52   \n",
       "0        0.90        0.74    0.94    0.62        0.74                   0.57   \n",
       "1        0.89        0.73    0.94    0.60        0.73                   0.54   \n",
       "2        0.89        0.64    0.91    0.58        0.64                   0.45   \n",
       "3        0.83        0.48    0.89    0.36        0.48                   0.50   \n",
       "4        0.94        0.50    0.77    0.81        0.50                   0.53   \n",
       "4        0.85        0.60    0.92    0.42        0.60                   0.51   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \\\n",
       "0                   0.59         0.79   \n",
       "1                   0.59         0.79   \n",
       "2                   0.60         0.79   \n",
       "3                   0.61         0.80   \n",
       "4                   0.61         0.80   \n",
       "5                   0.54         0.78   \n",
       "6                   0.61         0.80   \n",
       "7                   0.61         0.80   \n",
       "0                   0.60         0.79   \n",
       "1                   0.63         0.82   \n",
       "2                   0.74         0.81   \n",
       "0                   0.61         0.80   \n",
       "1                   0.64         0.83   \n",
       "2                   0.74         0.81   \n",
       "0                   0.65         0.80   \n",
       "1                   0.64         0.79   \n",
       "2                   0.62         0.74   \n",
       "3                   0.62         0.77   \n",
       "0                   0.66         0.81   \n",
       "1                   0.65         0.81   \n",
       "2                   0.65         0.79   \n",
       "3                   0.64         0.80   \n",
       "0                   0.61         0.79   \n",
       "1                   0.62         0.81   \n",
       "2                   0.74         0.81   \n",
       "0                   0.65         0.81   \n",
       "1                   0.63         0.80   \n",
       "2                   0.64         0.75   \n",
       "3                   0.63         0.76   \n",
       "4                   0.75         0.81   \n",
       "4                   0.64         0.79   \n",
       "\n",
       "                                         best params  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'entropy', 'classifi...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "0  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "1                  {'classifier__booster': 'gbtree'}  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "0  {'classifier__C': 1.0, 'classifier__solver': '...  \n",
       "1  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "2  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "0  {'classifier__boosting_type': 'goss', 'classif...  \n",
       "1  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "2  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "3  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "4  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "4  {'classifier__algorithm': 'SAMME.R', 'classifi...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop_duplicates(subset=['Methodology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "339d15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel(\"wine_no_over_sampling.xlsx\",sheet_name='white_wine')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5d041",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=12,)\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train, y_train)\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(x_train_res, y_train_res)\n",
    "preds = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "fis_df = pd.DataFrame(fis)\n",
    "fis_df.sort_values(by =0, ascending = False ).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed44a950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc2062f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=0.35, random_state=12)\n",
    "X_1=data.iloc[:,:-3]\n",
    "Y_1=data.iloc[:,-3]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, Y_1, test_size=0.2, random_state=42, \n",
    "                                                            shuffle=True,stratify=Y_1)\n",
    "x_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "70038a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"scaler\",StandardScaler()), ('classifier', RandomForestClassifier(criterion='gini', n_estimators= 300)) ])\n",
    "pipe.fit(x_train_res, y_train_res)\n",
    "y_true, y_pred = y_test , pipe.predict(X_test)\n",
    "\n",
    "scores = cross_validate(pipe, X_1, Y_1, cv=10,\n",
    "                    scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                    return_train_score=True)\n",
    "results = results.append({\n",
    "                'Methodology': 'Random Forest - Smote - Best estimator',\n",
    "                'Score': format(pipe.score(X_test, y_test),'.2f'),\n",
    "                'precision 1': format(precision_score(y_true, y_pred,  pos_label=1 , average='binary'),'.2f'),\n",
    "                'Precision 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][0],'.2f'),\n",
    "                'Precision 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][1],'.2f'),\n",
    "                'F1 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][0],'.2f'),\n",
    "                'F1 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][1],'.2f'),\n",
    "                'Recal 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][0],'.2f'),\n",
    "                'Recal 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][1],'.2f'),\n",
    "                'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "                'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "                'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f')\n",
    "                \n",
    "                },ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c0268de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Stratified</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Stratified with specfic variables</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Str MinMaxScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Str StandardScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Str RobustScaler</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Str Normalizer</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Str QuantileTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Str PowerTransformer</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCA GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PCA GrindRandomForestClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PCA GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GrindLogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__C': 2.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GrindRandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GrindSVC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PCA GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PCA GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PCA GrindGradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PCA GrindAdaBoostClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLogisticR...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__solver': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerRandomFor...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerSVC</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerLGBMClass...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'goss', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerXGBClassi...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'pca__n_comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerGradientB...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PCA Grind LocalOutlier StandardScalerAdaBoostC...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Grind LocalOutlier StandardSVC</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__C': 4.0, 'classifier__gamma': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GrindLGBMClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__boosting_type': 'gbdt', 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GrindXGBClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__booster': 'gbtree'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GrindGradientBoostingClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__learning_rate': 1, 'classifier__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GrindAdaBoostClassifier</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Grind LocalOutlier StandardAdaBoostClassifier</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>{'classifier__algorithm': 'SAMME.R', 'classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest - Smote - Best estimator</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Random Forest - Smote - Best estimator</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Random Forest - Smote - Best estimator</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Methodology Score  F1 0  F1 1  \\\n",
       "0                                 Logistic Stratified  0.80  0.88  0.31   \n",
       "1          Logistic Stratified with specfic variables  0.80  0.88  0.31   \n",
       "2                           Logistic Str MinMaxScaler  0.80  0.88  0.33   \n",
       "3                         Logistic Str StandardScaler  0.80  0.88  0.38   \n",
       "4                           Logistic Str RobustScaler  0.80  0.88  0.36   \n",
       "5                             Logistic Str Normalizer  0.79  0.88  0.15   \n",
       "6                    Logistic Str QuantileTransformer  0.80  0.88  0.36   \n",
       "7                       Logistic Str PowerTransformer  0.80  0.88  0.37   \n",
       "8                         PCA GrindLogisticRegression  0.80  0.88  0.36   \n",
       "9                     PCA GrindRandomForestClassifier  0.89  0.93  0.72   \n",
       "10                                       PCA GrindSVC  0.77  0.84  0.61   \n",
       "11                            GrindLogisticRegression  0.80  0.88  0.39   \n",
       "12                        GrindRandomForestClassifier  0.90  0.94  0.73   \n",
       "13                                           GrindSVC  0.77  0.84  0.61   \n",
       "14                            PCA GrindLGBMClassifier  0.88  0.93  0.71   \n",
       "15                             PCA GrindXGBClassifier  0.88  0.92  0.70   \n",
       "16                PCA GrindGradientBoostingClassifier  0.86  0.91  0.67   \n",
       "17                        PCA GrindAdaBoostClassifier  0.80  0.88  0.43   \n",
       "18                                GrindLGBMClassifier  0.88  0.92  0.71   \n",
       "19                                 GrindXGBClassifier  0.88  0.92  0.68   \n",
       "20                    GrindGradientBoostingClassifier  0.85  0.91  0.62   \n",
       "21                            GrindAdaBoostClassifier  0.82  0.89  0.47   \n",
       "22  PCA Grind LocalOutlier StandardScalerLogisticR...  0.79  0.88  0.35   \n",
       "23  PCA Grind LocalOutlier StandardScalerRandomFor...  0.88  0.92  0.66   \n",
       "24           PCA Grind LocalOutlier StandardScalerSVC  0.78  0.84  0.62   \n",
       "25  PCA Grind LocalOutlier StandardScalerLGBMClass...  0.87  0.92  0.67   \n",
       "26  PCA Grind LocalOutlier StandardScalerXGBClassi...  0.86  0.91  0.66   \n",
       "27  PCA Grind LocalOutlier StandardScalerGradientB...  0.84  0.90  0.61   \n",
       "28  PCA Grind LocalOutlier StandardScalerAdaBoostC...  0.78  0.86  0.41   \n",
       "29                                GrindLGBMClassifier  0.88  0.92  0.71   \n",
       "30                                 GrindXGBClassifier  0.88  0.92  0.68   \n",
       "31                    GrindGradientBoostingClassifier  0.85  0.91  0.62   \n",
       "32                            GrindAdaBoostClassifier  0.82  0.89  0.47   \n",
       "33                     Grind LocalOutlier StandardSVC  0.78  0.84  0.62   \n",
       "34                                GrindLGBMClassifier  0.88  0.92  0.71   \n",
       "35                                 GrindXGBClassifier  0.88  0.92  0.68   \n",
       "36                    GrindGradientBoostingClassifier  0.85  0.91  0.62   \n",
       "37                            GrindAdaBoostClassifier  0.82  0.89  0.47   \n",
       "38      Grind LocalOutlier StandardAdaBoostClassifier  0.81  0.88  0.49   \n",
       "39             Random Forest - Smote - Best estimator  0.89  0.93  0.73   \n",
       "40             Random Forest - Smote - Best estimator  0.88  0.92  0.75   \n",
       "41             Random Forest - Smote - Best estimator  0.90  0.94  0.74   \n",
       "\n",
       "   Precision 0 Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0         0.81        0.59    0.96    0.21        0.59                   0.54   \n",
       "1         0.81        0.59    0.96    0.21        0.59                   0.54   \n",
       "2         0.82        0.58    0.95    0.23        0.58                   0.54   \n",
       "3         0.83        0.59    0.95    0.28        0.59                   0.54   \n",
       "4         0.82        0.58    0.95    0.26        0.58                   0.54   \n",
       "5         0.80        0.58    0.98    0.08        0.58                   0.52   \n",
       "6         0.82        0.57    0.94    0.26        0.57                   0.54   \n",
       "7         0.82        0.58    0.95    0.27        0.58                   0.54   \n",
       "8         0.82        0.57    0.95    0.26        0.57                   0.54   \n",
       "9         0.90        0.84    0.97    0.63        0.84                   0.58   \n",
       "10        0.94        0.48    0.75    0.84        0.48                   0.52   \n",
       "11        0.83        0.60    0.95    0.29        0.60                   0.54   \n",
       "12        0.91        0.86    0.97    0.64        0.86                   0.59   \n",
       "13        0.95        0.48    0.75    0.84        0.48                   0.53   \n",
       "14        0.91        0.75    0.94    0.68        0.75                   0.54   \n",
       "15        0.91        0.76    0.94    0.65        0.76                   0.53   \n",
       "16        0.91        0.68    0.91    0.66        0.68                   0.44   \n",
       "17        0.84        0.57    0.93    0.34        0.57                   0.50   \n",
       "18        0.91        0.75    0.94    0.67        0.75                   0.56   \n",
       "19        0.90        0.76    0.95    0.61        0.76                   0.54   \n",
       "20        0.88        0.71    0.94    0.56        0.71                   0.51   \n",
       "21        0.85        0.62    0.94    0.38        0.62                   0.51   \n",
       "22        0.82        0.55    0.94    0.26        0.55                   0.55   \n",
       "23        0.89        0.82    0.96    0.56        0.82                   0.58   \n",
       "24        0.94        0.49    0.76    0.83        0.49                   0.52   \n",
       "25        0.90        0.74    0.94    0.62        0.74                   0.57   \n",
       "26        0.89        0.73    0.94    0.60        0.73                   0.54   \n",
       "27        0.89        0.64    0.91    0.58        0.64                   0.45   \n",
       "28        0.83        0.48    0.89    0.36        0.48                   0.50   \n",
       "29        0.91        0.75    0.94    0.67        0.75                   0.56   \n",
       "30        0.90        0.76    0.95    0.61        0.76                   0.54   \n",
       "31        0.88        0.71    0.94    0.56        0.71                   0.51   \n",
       "32        0.85        0.62    0.94    0.38        0.62                   0.51   \n",
       "33        0.94        0.50    0.77    0.81        0.50                   0.53   \n",
       "34        0.91        0.75    0.94    0.67        0.75                   0.56   \n",
       "35        0.90        0.76    0.95    0.61        0.76                   0.54   \n",
       "36        0.88        0.71    0.94    0.56        0.71                   0.51   \n",
       "37        0.85        0.62    0.94    0.38        0.62                   0.51   \n",
       "38        0.85        0.60    0.92    0.42        0.60                   0.51   \n",
       "39        0.92        0.77    0.94    0.70        0.77                   0.60   \n",
       "40        0.94        0.69    0.90    0.81        0.69                   0.60   \n",
       "41        0.91        0.82    0.96    0.67        0.82                   0.59   \n",
       "\n",
       "   test_balanced_accuracy test_roc_auc  \\\n",
       "0                    0.59         0.79   \n",
       "1                    0.59         0.79   \n",
       "2                    0.60         0.79   \n",
       "3                    0.61         0.80   \n",
       "4                    0.61         0.80   \n",
       "5                    0.54         0.78   \n",
       "6                    0.61         0.80   \n",
       "7                    0.61         0.80   \n",
       "8                    0.60         0.79   \n",
       "9                    0.63         0.82   \n",
       "10                   0.74         0.81   \n",
       "11                   0.61         0.80   \n",
       "12                   0.64         0.83   \n",
       "13                   0.74         0.81   \n",
       "14                   0.65         0.80   \n",
       "15                   0.64         0.79   \n",
       "16                   0.62         0.74   \n",
       "17                   0.62         0.77   \n",
       "18                   0.66         0.81   \n",
       "19                   0.65         0.81   \n",
       "20                   0.65         0.79   \n",
       "21                   0.64         0.80   \n",
       "22                   0.61         0.79   \n",
       "23                   0.62         0.81   \n",
       "24                   0.74         0.81   \n",
       "25                   0.65         0.81   \n",
       "26                   0.63         0.80   \n",
       "27                   0.64         0.75   \n",
       "28                   0.63         0.76   \n",
       "29                   0.66         0.81   \n",
       "30                   0.65         0.81   \n",
       "31                   0.65         0.79   \n",
       "32                   0.64         0.80   \n",
       "33                   0.75         0.81   \n",
       "34                   0.66         0.81   \n",
       "35                   0.65         0.81   \n",
       "36                   0.65         0.79   \n",
       "37                   0.64         0.80   \n",
       "38                   0.64         0.79   \n",
       "39                   0.65         0.83   \n",
       "40                   0.65         0.84   \n",
       "41                   0.64         0.83   \n",
       "\n",
       "                                          best params  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8   {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "9   {'classifier__criterion': 'entropy', 'classifi...  \n",
       "10  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "11  {'classifier__C': 2.0, 'classifier__solver': '...  \n",
       "12  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "13  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "14  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "15  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "16  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "17  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "18  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "19                  {'classifier__booster': 'gbtree'}  \n",
       "20  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "21  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "22  {'classifier__C': 1.0, 'classifier__solver': '...  \n",
       "23  {'classifier__criterion': 'gini', 'classifier_...  \n",
       "24  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "25  {'classifier__boosting_type': 'goss', 'classif...  \n",
       "26  {'classifier__booster': 'gbtree', 'pca__n_comp...  \n",
       "27  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "28  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "29  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "30                  {'classifier__booster': 'gbtree'}  \n",
       "31  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "32  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "33  {'classifier__C': 4.0, 'classifier__gamma': 0....  \n",
       "34  {'classifier__boosting_type': 'gbdt', 'classif...  \n",
       "35                  {'classifier__booster': 'gbtree'}  \n",
       "36  {'classifier__learning_rate': 1, 'classifier__...  \n",
       "37  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "38  {'classifier__algorithm': 'SAMME.R', 'classifi...  \n",
       "39                                                NaN  \n",
       "40                                                NaN  \n",
       "41                                                NaN  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a9254deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel(\"wine.xlsx\",sheet_name='white_wine')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9c085b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>Sratio</th>\n",
       "      <th>quality</th>\n",
       "      <th>anomaly_label</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0              0.70              0.27         0.36            2.07       0.45   \n",
       "1              0.63              0.30         0.34            0.16       0.49   \n",
       "2              0.81              0.28         0.40            0.69       0.50   \n",
       "3              0.72              0.23         0.32            0.85       0.58   \n",
       "4              0.72              0.23         0.32            0.85       0.58   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893           0.62              0.21         0.29            0.16       0.39   \n",
       "4894           0.66              0.32         0.36            0.80       0.47   \n",
       "4895           0.65              0.24         0.19            0.12       0.41   \n",
       "4896           0.55              0.29         0.30            0.11       0.22   \n",
       "4897           0.60              0.21         0.38            0.08       0.20   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
       "0                    0.45                  1.70  1.00100  0.300       0.45   \n",
       "1                    0.14                  1.32  0.99400  0.330       0.49   \n",
       "2                    0.30                  0.97  0.99510  0.326       0.44   \n",
       "3                    0.47                  1.86  0.99560  0.319       0.40   \n",
       "4                    0.47                  1.86  0.99560  0.319       0.40   \n",
       "...                   ...                   ...      ...    ...        ...   \n",
       "4893                 0.24                  0.92  0.99114  0.327       0.50   \n",
       "4894                 0.57                  1.68  0.99490  0.315       0.46   \n",
       "4895                 0.30                  1.11  0.99254  0.299       0.46   \n",
       "4896                 0.20                  1.10  0.98869  0.334       0.38   \n",
       "4897                 0.22                  0.98  0.98941  0.326       0.32   \n",
       "\n",
       "      alcohol    Sratio  quality  anomaly_label  original  \n",
       "0        0.88  0.264706        0              1         6  \n",
       "1        0.95  0.106061        0              1         6  \n",
       "2        1.01  0.309278        0              1         6  \n",
       "3        0.99  0.252688        0              1         6  \n",
       "4        0.99  0.252688        0              1         6  \n",
       "...       ...       ...      ...            ...       ...  \n",
       "4893     1.12  0.260870        0              1         6  \n",
       "4894     0.96  0.339286        0              1         5  \n",
       "4895     0.94  0.270270        0              1         6  \n",
       "4896     1.28  0.181818        1              1         7  \n",
       "4897     1.18  0.224490        0              1         6  \n",
       "\n",
       "[4898 rows x 15 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c34d80bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4139    1\n",
       "4140    1\n",
       "4141    1\n",
       "4142    1\n",
       "4143    1\n",
       "Name: quality, Length: 4144, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d515eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Πάμε τώρα να παίξουμε με outlier + smote ταυτοχρονα\n",
    "cols=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol', 'Sratio']\n",
    "ss = StandardScaler()\n",
    "'''fit scaler on numeric features'''\n",
    "ss.fit(data[cols])\n",
    "'''scale numeric features now'''\n",
    "X_Standard= ss.transform(data[cols])\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=6)\n",
    "data['anomaly_label']=lof.fit_predict(X_Standard)\n",
    "data['original']=quality_complete\n",
    "#plot για να δω αν τα outlier έχουν καποια χαρακτηριστικά\n",
    "data2 = data[data['anomaly_label'] >0]\n",
    "X_locOut = data2.iloc[:,:-3]\n",
    "y_locOut= data2.iloc[:,-3]\n",
    "\n",
    "ss = StandardScaler()\n",
    "'''fit scaler on numeric features'''\n",
    "ss.fit(X_locOut)\n",
    "'''scale numeric features now'''\n",
    "X1= ss.transform(X_locOut)\n",
    "y1=data2.iloc[:,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76adb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>Sratio</th>\n",
       "      <th>quality</th>\n",
       "      <th>anomaly_label</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0              0.70              0.27         0.36            2.07       0.45   \n",
       "1              0.63              0.30         0.34            0.16       0.49   \n",
       "2              0.81              0.28         0.40            0.69       0.50   \n",
       "3              0.72              0.23         0.32            0.85       0.58   \n",
       "4              0.72              0.23         0.32            0.85       0.58   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893           0.62              0.21         0.29            0.16       0.39   \n",
       "4894           0.66              0.32         0.36            0.80       0.47   \n",
       "4895           0.65              0.24         0.19            0.12       0.41   \n",
       "4896           0.55              0.29         0.30            0.11       0.22   \n",
       "4897           0.60              0.21         0.38            0.08       0.20   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
       "0                    0.45                  1.70  1.00100  0.300       0.45   \n",
       "1                    0.14                  1.32  0.99400  0.330       0.49   \n",
       "2                    0.30                  0.97  0.99510  0.326       0.44   \n",
       "3                    0.47                  1.86  0.99560  0.319       0.40   \n",
       "4                    0.47                  1.86  0.99560  0.319       0.40   \n",
       "...                   ...                   ...      ...    ...        ...   \n",
       "4893                 0.24                  0.92  0.99114  0.327       0.50   \n",
       "4894                 0.57                  1.68  0.99490  0.315       0.46   \n",
       "4895                 0.30                  1.11  0.99254  0.299       0.46   \n",
       "4896                 0.20                  1.10  0.98869  0.334       0.38   \n",
       "4897                 0.22                  0.98  0.98941  0.326       0.32   \n",
       "\n",
       "      alcohol    Sratio  quality  anomaly_label  original  \n",
       "0        0.88  0.264706        0              1         6  \n",
       "1        0.95  0.106061        0              1         6  \n",
       "2        1.01  0.309278        0              1         6  \n",
       "3        0.99  0.252688        0              1         6  \n",
       "4        0.99  0.252688        0              1         6  \n",
       "...       ...       ...      ...            ...       ...  \n",
       "4893     1.12  0.260870        0              1         6  \n",
       "4894     0.96  0.339286        0              1         5  \n",
       "4895     0.94  0.270270        0              1         6  \n",
       "4896     1.28  0.181818        1              1         7  \n",
       "4897     1.18  0.224490        0              1         6  \n",
       "\n",
       "[4898 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6eae88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>Sratio</th>\n",
       "      <th>quality</th>\n",
       "      <th>anomaly_label</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4724 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0              0.70              0.27         0.36            2.07       0.45   \n",
       "1              0.63              0.30         0.34            0.16       0.49   \n",
       "2              0.81              0.28         0.40            0.69       0.50   \n",
       "3              0.72              0.23         0.32            0.85       0.58   \n",
       "4              0.72              0.23         0.32            0.85       0.58   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893           0.62              0.21         0.29            0.16       0.39   \n",
       "4894           0.66              0.32         0.36            0.80       0.47   \n",
       "4895           0.65              0.24         0.19            0.12       0.41   \n",
       "4896           0.55              0.29         0.30            0.11       0.22   \n",
       "4897           0.60              0.21         0.38            0.08       0.20   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density     pH  sulphates  \\\n",
       "0                    0.45                  1.70  1.00100  0.300       0.45   \n",
       "1                    0.14                  1.32  0.99400  0.330       0.49   \n",
       "2                    0.30                  0.97  0.99510  0.326       0.44   \n",
       "3                    0.47                  1.86  0.99560  0.319       0.40   \n",
       "4                    0.47                  1.86  0.99560  0.319       0.40   \n",
       "...                   ...                   ...      ...    ...        ...   \n",
       "4893                 0.24                  0.92  0.99114  0.327       0.50   \n",
       "4894                 0.57                  1.68  0.99490  0.315       0.46   \n",
       "4895                 0.30                  1.11  0.99254  0.299       0.46   \n",
       "4896                 0.20                  1.10  0.98869  0.334       0.38   \n",
       "4897                 0.22                  0.98  0.98941  0.326       0.32   \n",
       "\n",
       "      alcohol    Sratio  quality  anomaly_label  original  \n",
       "0        0.88  0.264706        0              1         6  \n",
       "1        0.95  0.106061        0              1         6  \n",
       "2        1.01  0.309278        0              1         6  \n",
       "3        0.99  0.252688        0              1         6  \n",
       "4        0.99  0.252688        0              1         6  \n",
       "...       ...       ...      ...            ...       ...  \n",
       "4893     1.12  0.260870        0              1         6  \n",
       "4894     0.96  0.339286        0              1         5  \n",
       "4895     0.94  0.270270        0              1         6  \n",
       "4896     1.28  0.181818        1              1         7  \n",
       "4897     1.18  0.224490        0              1         6  \n",
       "\n",
       "[4724 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a295d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=0.5, random_state=12)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1,y1, test_size=0.2, random_state=42, \n",
    "                                                            shuffle=True,stratify=y1)\n",
    "x_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b2153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"scaler\",StandardScaler()), ('classifier', RandomForestClassifier(criterion='gini', n_estimators= 300)) ])\n",
    "pipe.fit(x_train_res, y_train_res)\n",
    "y_true, y_pred = y_test , pipe.predict(X_test)\n",
    "\n",
    "final=pd.DataFrame(columns=[\"Methodology\",\"Score\",])\n",
    "scores = cross_validate(pipe, X1, y1, cv=10,\n",
    "                    scoring=('average_precision', 'balanced_accuracy','roc_auc'),\n",
    "                    return_train_score=True)\n",
    "final = final.append({\n",
    "                'Methodology': 'Random Forest - Smote - Best estimator',\n",
    "                'Score': format(pipe.score(X_test, y_test),'.2f'),\n",
    "                'precision 1': format(precision_score(y_true, y_pred,  pos_label=1 , average='binary'),'.2f'),\n",
    "                'Precision 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][0],'.2f'),\n",
    "                'Precision 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[0][1],'.2f'),\n",
    "                'F1 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][0],'.2f'),\n",
    "                'F1 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[2][1],'.2f'),\n",
    "                'Recal 0':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][0],'.2f'),\n",
    "                'Recal 1':format(precision_recall_fscore_support(y_true, y_pred, average=None)[1][1],'.2f'),\n",
    "                'test_balanced_accuracy':format(scores['test_balanced_accuracy'].mean(),'.2f'),\n",
    "                'test_average_precision':format(scores['test_average_precision'].mean(),'.2f'),\n",
    "                'test_roc_auc':format(scores['test_roc_auc'].mean(),'.2f')\n",
    "                \n",
    "                },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f661b4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Score</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>Precision 0</th>\n",
       "      <th>Precision 1</th>\n",
       "      <th>Recal 0</th>\n",
       "      <th>Recal 1</th>\n",
       "      <th>precision 1</th>\n",
       "      <th>test_average_precision</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest - Smote - Best estimator</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Methodology Score  F1 0  F1 1 Precision 0  \\\n",
       "0  Random Forest - Smote - Best estimator  0.87  0.92  0.69        0.91   \n",
       "\n",
       "  Precision 1 Recal 0 Recal 1 precision 1 test_average_precision  \\\n",
       "0        0.71    0.92    0.67        0.71                   0.59   \n",
       "\n",
       "  test_balanced_accuracy test_roc_auc  \n",
       "0                   0.64         0.83  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82ccc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
